[package]
name = "autonomous-agent"
version = "1.0.0"
edition = "2021"
authors = ["elizaOS Team <team@elizaos.ai>"]
description = "Autonomous self-looping agent with local AI, shell access, and in-memory storage"
license = "MIT"
repository = "https://github.com/elizaos/eliza"

[[bin]]
name = "autonomous-agent"
path = "src/main.rs"

[features]
default = ["llm"]
# Enable actual LLM inference (requires llama.cpp)
llm = ["elizaos-plugin-local-ai/llm"]
# GPU acceleration
cuda = ["llm", "elizaos-plugin-local-ai/cuda"]
metal = ["llm", "elizaos-plugin-local-ai/metal"]

[dependencies]
# Local AI plugin
elizaos-plugin-local-ai = { path = "../../../plugins/plugin-local-ai/rust", features = ["native"] }
elizaos-plugin-shell = { path = "../../../plugins/plugin-shell/rust" }

# Async runtime
tokio = { version = "1.42", features = ["full", "signal"] }
futures = "0.3"
async-trait = "0.1"

# Serialization
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"

# Error handling
anyhow = "1.0"
thiserror = "2.0"

# Logging
tracing = "0.1"
tracing-subscriber = { version = "0.3", features = ["env-filter"] }

# Utilities
uuid = { version = "1.11", features = ["v4"] }
chrono = "0.4"
regex = "1.10"
directories = "5.0"

[profile.release]
lto = true
opt-level = "z"
