This file is a merged representation of a subset of the codebase, containing specifically included files and files not matching ignore patterns, combined into a single document by Repomix.
The content has been processed where comments have been removed, empty lines have been removed, content has been compressed (code blocks are separated by ⋮---- delimiter).

# File Summary

## Purpose
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

## File Format
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Multiple file entries, each consisting of:
  a. A header with the file path (## File: path/to/file)
  b. The full contents of the file in a code block

## Usage Guidelines
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
- Pay special attention to the Repository Description. These contain important context and guidelines specific to this project.
- Pay special attention to the Repository Instruction. These contain important context and guidelines specific to this project.

## Notes
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Only files matching these patterns are included: packages/docs/docs/intro.md, packages/docs/docs/quickstart.md, packages/docs/docs/core/overview.md, packages/docs/docs/core/actions.md, packages/docs/docs/core/agents.md, packages/docs/docs/core/clients.md, packages/docs/docs/core/database.md, packages/docs/docs/core/evaluators.md, packages/docs/docs/core/knowledge.md, packages/docs/docs/core/plugins.md, packages/docs/docs/core/providers.md, packages/docs/docs/guides/configuration.md, packages/core/src/types.ts, packages/core/src/index.ts, packages/cli/src/index.ts, README.md, package.json, .env.example
- Files matching these patterns are excluded: **/*.test.ts, **/__tests__/**, **/node_modules/**, packages/docs/community/**, packages/docs/news/**, packages/plugin-*/**, **/*.ico, **/*.png, **/*.jpg, **/*.svg
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Code comments have been removed from supported file types
- Empty lines have been removed from all files
- Content has been compressed - code blocks are separated by ⋮---- delimiter

## Additional Info
### User Provided Header
ElizaOS Developer Context - Documentation and essential code

# Directory Structure
```
packages/
  cli/
    src/
      index.ts
  core/
    src/
      index.ts
      types.ts
  docs/
    docs/
      core/
        actions.md
        agents.md
        clients.md
        database.md
        evaluators.md
        knowledge.md
        overview.md
        plugins.md
        providers.md
      guides/
        configuration.md
      intro.md
      quickstart.md
.env.example
package.json
README.md
```

# Files

## File: packages/cli/src/index.ts
````typescript
import fs from "node:fs";
import path from "node:path";
import { dirname } from "node:path";
import { fileURLToPath } from "node:url";
import { logger } from "@elizaos/core";
import { Command } from "commander";
import { agent } from "./commands/agent.js";
import { create } from "./commands/create.js";
import devCommand from "./commands/dev.js";
import envCommand from "./commands/env.js";
import { plugin } from "./commands/plugin.js";
import { project } from "./commands/project.js";
import { start } from "./commands/start.js";
import { teeCommand as tee } from "./commands/tee.js";
import { test } from "./commands/test.js";
import updateCommand, { update } from "./commands/update.js";
import { loadEnvironment } from "./utils/get-config.js";
⋮----
async function main()
````

## File: packages/core/src/index.ts
````typescript

````

## File: packages/core/src/types.ts
````typescript
import type { Readable } from "node:stream";
export type UUID = `${string}-${string}-${string}-${string}-${string}`;
export function asUUID(id: string): UUID
export interface Content {
  thought?: string;
  plan?: string;
  text?: string;
  actions?: string[];
  providers?: string[];
  source?: string;
  url?: string;
  inReplyTo?: UUID;
  attachments?: Media[];
  [key: string]: unknown;
}
export interface ActionExample {
  name: string;
  content: Content;
}
export type ModelType = (typeof ModelTypes)[keyof typeof ModelTypes] | string;
⋮----
export type ServiceType = (typeof ServiceTypes)[keyof typeof ServiceTypes];
⋮----
export interface State {
  [key: string]: any;
  values: {
    [key: string]: any;
  };
  data: {
    [key: string]: any;
  };
  text: string;
}
export type MemoryTypeAlias = string;
export enum MemoryType {
  DOCUMENT = "document",
  FRAGMENT = "fragment",
  MESSAGE = "message",
  DESCRIPTION = "description",
  CUSTOM = "custom",
}
export type MemoryScope = "shared" | "private" | "room";
export interface BaseMetadata {
  type: MemoryTypeAlias;
  source?: string;
  sourceId?: UUID;
  scope?: MemoryScope;
  timestamp?: number;
  tags?: string[];
}
export interface DocumentMetadata extends BaseMetadata {
  type: MemoryType.DOCUMENT;
}
export interface FragmentMetadata extends BaseMetadata {
  type: MemoryType.FRAGMENT;
  documentId: UUID;
  position: number;
}
export interface MessageMetadata extends BaseMetadata {
  type: MemoryType.MESSAGE;
}
export interface DescriptionMetadata extends BaseMetadata {
  type: MemoryType.DESCRIPTION;
}
export interface CustomMetadata extends BaseMetadata {
  type: MemoryTypeAlias;
  [key: string]: unknown;
}
export type MemoryMetadata =
  | DocumentMetadata
  | FragmentMetadata
  | MessageMetadata
  | DescriptionMetadata
  | CustomMetadata;
export interface Memory {
  id?: UUID;
  entityId: UUID;
  agentId?: UUID;
  createdAt?: number;
  content: Content;
  embedding?: number[];
  roomId: UUID;
  unique?: boolean;
  similarity?: number;
  metadata?: MemoryMetadata;
}
export interface Log {
  id?: UUID;
  entityId: UUID;
  roomId?: UUID;
  body: { [key: string]: unknown };
  type: string;
  createdAt: Date;
}
export interface MessageExample {
  name: string;
  content: Content;
}
export type Handler = (
  runtime: IAgentRuntime,
  message: Memory,
  state?: State,
  options?: { [key: string]: unknown },
  callback?: HandlerCallback,
  responses?: Memory[]
) => Promise<unknown>;
export type HandlerCallback = (
  response: Content,
  files?: any
) => Promise<Memory[]>;
export type Validator = (
  runtime: IAgentRuntime,
  message: Memory,
  state?: State
) => Promise<boolean>;
export interface Action {
  similes?: string[];
  description: string;
  examples?: ActionExample[][];
  handler: Handler;
  name: string;
  validate: Validator;
}
export interface EvaluationExample {
  prompt: string;
  messages: Array<ActionExample>;
  outcome: string;
}
export interface Evaluator {
  alwaysRun?: boolean;
  description: string;
  similes?: string[];
  examples: EvaluationExample[];
  handler: Handler;
  name: string;
  validate: Validator;
}
export interface ProviderResult {
  values?: {
    [key: string]: any;
  };
  data?: {
    [key: string]: any;
  };
  text?: string;
}
export interface Provider {
  name: string;
  description?: string;
  dynamic?: boolean;
  position?: number;
  private?: boolean;
  get: (
    runtime: IAgentRuntime,
    message: Memory,
    state: State
  ) => Promise<ProviderResult>;
}
export interface Relationship {
  id: UUID;
  sourceEntityId: UUID;
  targetEntityId: UUID;
  agentId: UUID;
  tags: string[];
  metadata: {
    [key: string]: any;
  };
  createdAt?: string;
}
export interface Component {
  id: UUID;
  entityId: UUID;
  agentId: UUID;
  roomId: UUID;
  worldId: UUID;
  sourceEntityId: UUID;
  type: string;
  data: {
    [key: string]: any;
  };
}
export interface Entity {
  id?: UUID;
  names: string[];
  metadata?: { [key: string]: any };
  agentId: UUID;
  components?: Component[];
}
export type World = {
  id: UUID;
  name?: string;
  agentId: UUID;
  serverId: string;
  metadata?: {
    ownership?: {
      ownerId: string;
    };
    roles?: {
      [entityId: UUID]: Role;
    };
    [key: string]: unknown;
  };
};
export type Room = {
  id: UUID;
  name?: string;
  agentId?: UUID;
  source: string;
  type: ChannelType;
  channelId?: string;
  serverId?: string;
  worldId?: UUID;
  metadata?: Record<string, unknown>;
};
export interface Participant {
  id: UUID;
  entity: Entity;
}
export type Media = {
  id: string;
  url: string;
  title: string;
  source: string;
  description: string;
  text: string;
  contentType?: string;
};
export enum ChannelType {
  SELF = "SELF",
  DM = "DM",
  GROUP = "GROUP",
  VOICE_DM = "VOICE_DM",
  VOICE_GROUP = "VOICE_GROUP",
  FEED = "FEED",
  THREAD = "THREAD",
  WORLD = "WORLD",
  API = "API",
  FORUM = "FORUM",
}
export abstract class Service
⋮----
constructor(runtime?: IAgentRuntime)
abstract stop(): Promise<void>;
⋮----
static async start(_runtime: IAgentRuntime): Promise<Service>
static async stop(_runtime: IAgentRuntime): Promise<unknown>
⋮----
export type Route = {
  type: "GET" | "POST" | "PUT" | "DELETE" | "STATIC";
  path: string;
  filePath?: string;
  handler?: (req: any, res: any, runtime: IAgentRuntime) => Promise<void>;
};
export interface Plugin {
  name: string;
  description: string;
  init?: (
    config: Record<string, string>,
    runtime: IAgentRuntime
  ) => Promise<void>;
  config?: { [key: string]: any };
  memoryManagers?: IMemoryManager[];
  services?: (typeof Service)[];
  componentTypes?: {
    name: string;
    schema: Record<string, unknown>;
    validator?: (data: any) => boolean;
  }[];
  actions?: Action[];
  providers?: Provider[];
  evaluators?: Evaluator[];
  adapter?: IDatabaseAdapter;
  models?: {
    [key: string]: (...args: any[]) => Promise<any>;
  };
  events?: {
    [K in keyof EventPayloadMap]?: EventHandler<K>[];
  } & {
    [key: string]: ((params: EventPayload) => Promise<any>)[];
  };
  routes?: Route[];
  tests?: TestSuite[];
}
export interface ProjectAgent {
  character: Character;
  init?: (runtime: IAgentRuntime) => Promise<void>;
  plugins?: Plugin[];
  tests?: TestSuite | TestSuite[];
}
export interface Project {
  agents: ProjectAgent[];
}
export type TemplateType =
  | string
  | ((options: { state: State | { [key: string]: string } }) => string);
export interface Character {
  id?: UUID;
  name: string;
  username?: string;
  system?: string;
  templates?: {
    [key: string]: TemplateType;
  };
  bio: string | string[];
  messageExamples?: MessageExample[][];
  postExamples?: string[];
  topics?: string[];
  adjectives?: string[];
  knowledge?: (string | { path: string; shared?: boolean })[];
  plugins?: string[];
  settings?: {
    [key: string]: any | string | boolean | number;
  };
  secrets?: {
    [key: string]: string | boolean | number;
  };
  style?: {
    all?: string[];
    chat?: string[];
    post?: string[];
  };
}
export interface Agent extends Character {
  createdAt: number;
  updatedAt: number;
}
export interface IDatabaseAdapter {
  db: any;
  init(): Promise<void>;
  close(): Promise<void>;
  getAgent(agentId: UUID): Promise<Agent | null>;
  getAgents(): Promise<Agent[]>;
  createAgent(agent: Partial<Agent>): Promise<boolean>;
  updateAgent(agentId: UUID, agent: Partial<Agent>): Promise<boolean>;
  deleteAgent(agentId: UUID): Promise<boolean>;
  ensureAgentExists(agent: Partial<Agent>): Promise<void>;
  ensureEmbeddingDimension(dimension: number): Promise<void>;
  getEntityById(entityId: UUID): Promise<Entity | null>;
  getEntitiesForRoom(
    roomId: UUID,
    includeComponents?: boolean
  ): Promise<Entity[]>;
  createEntity(entity: Entity): Promise<boolean>;
  updateEntity(entity: Entity): Promise<void>;
  getComponent(
    entityId: UUID,
    type: string,
    worldId?: UUID,
    sourceEntityId?: UUID
  ): Promise<Component | null>;
  getComponents(
    entityId: UUID,
    worldId?: UUID,
    sourceEntityId?: UUID
  ): Promise<Component[]>;
  createComponent(component: Component): Promise<boolean>;
  updateComponent(component: Component): Promise<void>;
  deleteComponent(componentId: UUID): Promise<void>;
  getMemories(params: {
    roomId: UUID;
    count?: number;
    unique?: boolean;
    tableName: string;
    start?: number;
    end?: number;
  }): Promise<Memory[]>;
  getMemoryById(id: UUID): Promise<Memory | null>;
  getMemoriesByIds(ids: UUID[], tableName?: string): Promise<Memory[]>;
  getMemoriesByRoomIds(params: {
    tableName: string;
    roomIds: UUID[];
    limit?: number;
  }): Promise<Memory[]>;
  getCachedEmbeddings(params: {
    query_table_name: string;
    query_threshold: number;
    query_input: string;
    query_field_name: string;
    query_field_sub_name: string;
    query_match_count: number;
  }): Promise<{ embedding: number[]; levenshtein_score: number }[]>;
  log(params: {
    body: { [key: string]: unknown };
    entityId: UUID;
    roomId: UUID;
    type: string;
  }): Promise<void>;
  getLogs(params: {
    entityId: UUID;
    roomId?: UUID;
    type?: string;
    count?: number;
    offset?: number;
  }): Promise<Log[]>;
  deleteLog(logId: UUID): Promise<void>;
  searchMemories(params: {
    embedding: number[];
    match_threshold?: number;
    count?: number;
    roomId?: UUID;
    unique?: boolean;
    tableName: string;
  }): Promise<Memory[]>;
  createMemory(
    memory: Memory,
    tableName: string,
    unique?: boolean
  ): Promise<UUID>;
  removeMemory(memoryId: UUID, tableName: string): Promise<void>;
  removeAllMemories(roomId: UUID, tableName: string): Promise<void>;
  countMemories(
    roomId: UUID,
    unique?: boolean,
    tableName?: string
  ): Promise<number>;
  createWorld(world: World): Promise<UUID>;
  getWorld(id: UUID): Promise<World | null>;
  getAllWorlds(): Promise<World[]>;
  updateWorld(world: World): Promise<void>;
  getRoom(roomId: UUID): Promise<Room | null>;
  createRoom({
    id,
    name,
    source,
    type,
    channelId,
    serverId,
    worldId,
  }: Room): Promise<UUID>;
  deleteRoom(roomId: UUID): Promise<void>;
  updateRoom(room: Room): Promise<void>;
  getRoomsForParticipant(entityId: UUID): Promise<UUID[]>;
  getRoomsForParticipants(userIds: UUID[]): Promise<UUID[]>;
  getRooms(worldId: UUID): Promise<Room[]>;
  addParticipant(entityId: UUID, roomId: UUID): Promise<boolean>;
  removeParticipant(entityId: UUID, roomId: UUID): Promise<boolean>;
  getParticipantsForEntity(entityId: UUID): Promise<Participant[]>;
  getParticipantsForRoom(roomId: UUID): Promise<UUID[]>;
  getParticipantUserState(
    roomId: UUID,
    entityId: UUID
  ): Promise<"FOLLOWED" | "MUTED" | null>;
  setParticipantUserState(
    roomId: UUID,
    entityId: UUID,
    state: "FOLLOWED" | "MUTED" | null
  ): Promise<void>;
  createRelationship(params: {
    sourceEntityId: UUID;
    targetEntityId: UUID;
    tags?: string[];
    metadata?: { [key: string]: any };
  }): Promise<boolean>;
  updateRelationship(relationship: Relationship): Promise<void>;
  getRelationship(params: {
    sourceEntityId: UUID;
    targetEntityId: UUID;
  }): Promise<Relationship | null>;
  getRelationships(params: {
    entityId: UUID;
    tags?: string[];
  }): Promise<Relationship[]>;
  ensureEmbeddingDimension(dimension: number): Promise<void>;
  getCache<T>(key: string): Promise<T | undefined>;
  setCache<T>(key: string, value: T): Promise<boolean>;
  deleteCache(key: string): Promise<boolean>;
  createTask(task: Task): Promise<UUID>;
  getTasks(params: { roomId?: UUID; tags?: string[] }): Promise<Task[]>;
  getTask(id: UUID): Promise<Task | null>;
  getTasksByName(name: string): Promise<Task[]>;
  updateTask(id: UUID, task: Partial<Task>): Promise<void>;
  deleteTask(id: UUID): Promise<void>;
  getMemoryManager<T extends Memory = Memory>(
    tableName: string
  ): IMemoryManager<T> | null;
}
⋮----
init(): Promise<void>;
close(): Promise<void>;
getAgent(agentId: UUID): Promise<Agent | null>;
getAgents(): Promise<Agent[]>;
createAgent(agent: Partial<Agent>): Promise<boolean>;
updateAgent(agentId: UUID, agent: Partial<Agent>): Promise<boolean>;
deleteAgent(agentId: UUID): Promise<boolean>;
ensureAgentExists(agent: Partial<Agent>): Promise<void>;
ensureEmbeddingDimension(dimension: number): Promise<void>;
getEntityById(entityId: UUID): Promise<Entity | null>;
getEntitiesForRoom(
    roomId: UUID,
    includeComponents?: boolean
  ): Promise<Entity[]>;
createEntity(entity: Entity): Promise<boolean>;
updateEntity(entity: Entity): Promise<void>;
getComponent(
    entityId: UUID,
    type: string,
    worldId?: UUID,
    sourceEntityId?: UUID
  ): Promise<Component | null>;
getComponents(
    entityId: UUID,
    worldId?: UUID,
    sourceEntityId?: UUID
  ): Promise<Component[]>;
createComponent(component: Component): Promise<boolean>;
updateComponent(component: Component): Promise<void>;
deleteComponent(componentId: UUID): Promise<void>;
getMemories(params: {
    roomId: UUID;
    count?: number;
    unique?: boolean;
    tableName: string;
    start?: number;
    end?: number;
  }): Promise<Memory[]>;
getMemoryById(id: UUID): Promise<Memory | null>;
getMemoriesByIds(ids: UUID[], tableName?: string): Promise<Memory[]>;
getMemoriesByRoomIds(params: {
    tableName: string;
    roomIds: UUID[];
    limit?: number;
  }): Promise<Memory[]>;
getCachedEmbeddings(params: {
    query_table_name: string;
    query_threshold: number;
    query_input: string;
    query_field_name: string;
    query_field_sub_name: string;
    query_match_count: number;
}): Promise<
log(params: {
    body: { [key: string]: unknown };
    entityId: UUID;
    roomId: UUID;
    type: string;
  }): Promise<void>;
getLogs(params: {
    entityId: UUID;
    roomId?: UUID;
    type?: string;
    count?: number;
    offset?: number;
  }): Promise<Log[]>;
deleteLog(logId: UUID): Promise<void>;
searchMemories(params: {
    embedding: number[];
    match_threshold?: number;
    count?: number;
    roomId?: UUID;
    unique?: boolean;
    tableName: string;
  }): Promise<Memory[]>;
createMemory(
    memory: Memory,
    tableName: string,
    unique?: boolean
  ): Promise<UUID>;
removeMemory(memoryId: UUID, tableName: string): Promise<void>;
removeAllMemories(roomId: UUID, tableName: string): Promise<void>;
countMemories(
    roomId: UUID,
    unique?: boolean,
    tableName?: string
  ): Promise<number>;
createWorld(world: World): Promise<UUID>;
getWorld(id: UUID): Promise<World | null>;
getAllWorlds(): Promise<World[]>;
updateWorld(world: World): Promise<void>;
getRoom(roomId: UUID): Promise<Room | null>;
createRoom({
    id,
    name,
    source,
    type,
    channelId,
    serverId,
    worldId,
  }: Room): Promise<UUID>;
deleteRoom(roomId: UUID): Promise<void>;
updateRoom(room: Room): Promise<void>;
getRoomsForParticipant(entityId: UUID): Promise<UUID[]>;
getRoomsForParticipants(userIds: UUID[]): Promise<UUID[]>;
getRooms(worldId: UUID): Promise<Room[]>;
addParticipant(entityId: UUID, roomId: UUID): Promise<boolean>;
removeParticipant(entityId: UUID, roomId: UUID): Promise<boolean>;
getParticipantsForEntity(entityId: UUID): Promise<Participant[]>;
getParticipantsForRoom(roomId: UUID): Promise<UUID[]>;
getParticipantUserState(
    roomId: UUID,
    entityId: UUID
  ): Promise<"FOLLOWED" | "MUTED" | null>;
setParticipantUserState(
    roomId: UUID,
    entityId: UUID,
    state: "FOLLOWED" | "MUTED" | null
  ): Promise<void>;
createRelationship(params: {
    sourceEntityId: UUID;
    targetEntityId: UUID;
    tags?: string[];
    metadata?: { [key: string]: any };
  }): Promise<boolean>;
updateRelationship(relationship: Relationship): Promise<void>;
getRelationship(params: {
    sourceEntityId: UUID;
    targetEntityId: UUID;
  }): Promise<Relationship | null>;
getRelationships(params: {
    entityId: UUID;
    tags?: string[];
  }): Promise<Relationship[]>;
⋮----
getCache<T>(key: string): Promise<T | undefined>;
setCache<T>(key: string, value: T): Promise<boolean>;
deleteCache(key: string): Promise<boolean>;
createTask(task: Task): Promise<UUID>;
getTasks(params:
getTask(id: UUID): Promise<Task | null>;
getTasksByName(name: string): Promise<Task[]>;
updateTask(id: UUID, task: Partial<Task>): Promise<void>;
deleteTask(id: UUID): Promise<void>;
getMemoryManager<T extends Memory = Memory>(
    tableName: string
  ): IMemoryManager<T> | null;
⋮----
export interface EmbeddingSearchResult {
  embedding: number[];
  levenshtein_score: number;
}
export interface MemoryRetrievalOptions {
  roomId: UUID;
  count?: number;
  unique?: boolean;
  start?: number;
  end?: number;
  agentId?: UUID;
}
export interface MemorySearchOptions {
  embedding: number[];
  match_threshold?: number;
  count?: number;
  roomId: UUID;
  agentId?: UUID;
  unique?: boolean;
  metadata?: Partial<MemoryMetadata>;
}
export interface MultiRoomMemoryOptions {
  roomIds: UUID[];
  limit?: number;
  agentId?: UUID;
}
export interface UnifiedMemoryOptions {
  roomId: UUID;
  limit?: number;
  agentId?: UUID;
  unique?: boolean;
  start?: number;
  end?: number;
}
export interface UnifiedSearchOptions extends UnifiedMemoryOptions {
  embedding: number[];
  similarity?: number;
}
export interface IMemoryManager<T extends Memory = Memory> {
  readonly runtime: IAgentRuntime;
  readonly tableName: string;
  addEmbeddingToMemory(memory: T): Promise<T>;
  getMemories(
    opts: MemoryRetrievalOptions | UnifiedMemoryOptions
  ): Promise<T[]>;
  searchMemories(
    params: MemorySearchOptions | UnifiedSearchOptions
  ): Promise<T[]>;
  getCachedEmbeddings(content: string): Promise<EmbeddingSearchResult[]>;
  getMemoryById(id: UUID): Promise<T | null>;
  getMemoriesByRoomIds(params: MultiRoomMemoryOptions): Promise<T[]>;
  createMemory(memory: T, unique?: boolean): Promise<UUID>;
  removeMemory(memoryId: UUID): Promise<void>;
  removeAllMemories(roomId: UUID): Promise<void>;
  countMemories(roomId: UUID, unique?: boolean): Promise<number>;
}
⋮----
addEmbeddingToMemory(memory: T): Promise<T>;
getMemories(
    opts: MemoryRetrievalOptions | UnifiedMemoryOptions
  ): Promise<T[]>;
searchMemories(
    params: MemorySearchOptions | UnifiedSearchOptions
  ): Promise<T[]>;
getCachedEmbeddings(content: string): Promise<EmbeddingSearchResult[]>;
getMemoryById(id: UUID): Promise<T | null>;
getMemoriesByRoomIds(params: MultiRoomMemoryOptions): Promise<T[]>;
createMemory(memory: T, unique?: boolean): Promise<UUID>;
removeMemory(memoryId: UUID): Promise<void>;
removeAllMemories(roomId: UUID): Promise<void>;
countMemories(roomId: UUID, unique?: boolean): Promise<number>;
⋮----
export type CacheOptions = {
  expires?: number;
};
export interface IAgentRuntime extends IDatabaseAdapter {
  agentId: UUID;
  character: Character;
  providers: Provider[];
  actions: Action[];
  evaluators: Evaluator[];
  plugins: Plugin[];
  services: Map<ServiceType, Service>;
  events: Map<string, ((params: any) => Promise<void>)[]>;
  fetch?: typeof fetch | null;
  routes: Route[];
  registerPlugin(plugin: Plugin): Promise<void>;
  initialize(): Promise<void>;
  getKnowledge(message: Memory): Promise<KnowledgeItem[]>;
  addKnowledge(
    item: KnowledgeItem,
    options: {
      targetTokens: number;
      overlap: number;
      modelContextSize: number;
    }
  ): Promise<void>;
  getMemoryManager<T extends Memory = Memory>(
    tableName: string
  ): IMemoryManager<T> | null;
  getService<T extends Service>(service: ServiceType | string): T | null;
  getAllServices(): Map<ServiceType, Service>;
  registerService(service: typeof Service): void;
  registerDatabaseAdapter(adapter: IDatabaseAdapter): void;
  setSetting(
    key: string,
    value: string | boolean | null | any,
    secret: boolean
  ): void;
  getSetting(key: string): string | boolean | null | any;
  getConversationLength(): number;
  processActions(
    message: Memory,
    responses: Memory[],
    state?: State,
    callback?: HandlerCallback
  ): Promise<void>;
  evaluate(
    message: Memory,
    state?: State,
    didRespond?: boolean,
    callback?: HandlerCallback,
    responses?: Memory[]
  ): Promise<Evaluator[] | null>;
  registerProvider(provider: Provider): void;
  registerAction(action: Action): void;
  registerEvaluator(evaluator: Evaluator): void;
  ensureConnection({
    entityId,
    roomId,
    userName,
    name,
    source,
    channelId,
    serverId,
    type,
    worldId,
  }: {
    entityId: UUID;
    roomId: UUID;
    userName?: string;
    name?: string;
    source?: string;
    channelId?: string;
    serverId?: string;
    type: ChannelType;
    worldId?: UUID;
  }): Promise<void>;
  ensureParticipantInRoom(entityId: UUID, roomId: UUID): Promise<void>;
  ensureWorldExists(world: World): Promise<void>;
  ensureRoomExists(room: Room): Promise<void>;
  composeState(
    message: Memory,
    filterList?: string[],
    includeList?: string[]
  ): Promise<State>;
  useModel<T extends ModelType, R = ModelResultMap[T]>(
    modelType: T,
    params: Omit<ModelParamsMap[T], "runtime"> | any
  ): Promise<R>;
  registerModel(
    modelType: ModelType | string,
    handler: (params: any) => Promise<any>
  ): void;
  getModel(
    modelType: ModelType | string
  ): ((runtime: IAgentRuntime, params: any) => Promise<any>) | undefined;
  registerEvent(event: string, handler: (params: any) => Promise<void>): void;
  getEvent(event: string): ((params: any) => Promise<void>)[] | undefined;
  emitEvent(event: string | string[], params: any): Promise<void>;
  registerTaskWorker(taskHandler: TaskWorker): void;
  getTaskWorker(name: string): TaskWorker | undefined;
  stop(): Promise<void>;
}
⋮----
registerPlugin(plugin: Plugin): Promise<void>;
initialize(): Promise<void>;
getKnowledge(message: Memory): Promise<KnowledgeItem[]>;
addKnowledge(
    item: KnowledgeItem,
    options: {
      targetTokens: number;
      overlap: number;
      modelContextSize: number;
    }
  ): Promise<void>;
⋮----
getService<T extends Service>(service: ServiceType | string): T | null;
getAllServices(): Map<ServiceType, Service>;
registerService(service: typeof Service): void;
registerDatabaseAdapter(adapter: IDatabaseAdapter): void;
setSetting(
    key: string,
    value: string | boolean | null | any,
    secret: boolean
  ): void;
getSetting(key: string): string | boolean | null | any;
getConversationLength(): number;
processActions(
    message: Memory,
    responses: Memory[],
    state?: State,
    callback?: HandlerCallback
  ): Promise<void>;
evaluate(
    message: Memory,
    state?: State,
    didRespond?: boolean,
    callback?: HandlerCallback,
    responses?: Memory[]
  ): Promise<Evaluator[] | null>;
registerProvider(provider: Provider): void;
registerAction(action: Action): void;
registerEvaluator(evaluator: Evaluator): void;
ensureConnection({
    entityId,
    roomId,
    userName,
    name,
    source,
    channelId,
    serverId,
    type,
    worldId,
  }: {
    entityId: UUID;
    roomId: UUID;
    userName?: string;
    name?: string;
    source?: string;
    channelId?: string;
    serverId?: string;
    type: ChannelType;
    worldId?: UUID;
  }): Promise<void>;
ensureParticipantInRoom(entityId: UUID, roomId: UUID): Promise<void>;
ensureWorldExists(world: World): Promise<void>;
ensureRoomExists(room: Room): Promise<void>;
composeState(
    message: Memory,
    filterList?: string[],
    includeList?: string[]
  ): Promise<State>;
useModel<T extends ModelType, R = ModelResultMap[T]>(
    modelType: T,
    params: Omit<ModelParamsMap[T], "runtime"> | any
  ): Promise<R>;
registerModel(
    modelType: ModelType | string,
    handler: (params: any) => Promise<any>
  ): void;
getModel(
    modelType: ModelType | string
): ((runtime: IAgentRuntime, params: any)
registerEvent(event: string, handler: (params: any)
getEvent(event: string): ((params: any)
emitEvent(event: string | string[], params: any): Promise<void>;
registerTaskWorker(taskHandler: TaskWorker): void;
getTaskWorker(name: string): TaskWorker | undefined;
stop(): Promise<void>;
⋮----
export type KnowledgeItem = {
  id: UUID;
  content: Content;
};
export enum KnowledgeScope {
  SHARED = "shared",
  PRIVATE = "private",
}
export enum CacheKeyPrefix {
  KNOWLEDGE = "knowledge",
}
export interface DirectoryItem {
  directory: string;
  shared?: boolean;
}
export interface ChunkRow {
  id: string;
}
export type GenerateTextParams = {
  runtime: IAgentRuntime;
  prompt: string;
  modelType: ModelType;
  maxTokens?: number;
  temperature?: number;
  frequencyPenalty?: number;
  presencePenalty?: number;
  stopSequences?: string[];
};
export interface TokenizeTextParams {
  prompt: string;
  modelType: ModelType;
}
export interface DetokenizeTextParams {
  tokens: number[];
  modelType: ModelType;
}
export interface IVideoService extends Service {
  isVideoUrl(url: string): boolean;
  fetchVideoInfo(url: string): Promise<Media>;
  downloadVideo(videoInfo: Media): Promise<string>;
  processVideo(url: string, runtime: IAgentRuntime): Promise<Media>;
}
⋮----
isVideoUrl(url: string): boolean;
fetchVideoInfo(url: string): Promise<Media>;
downloadVideo(videoInfo: Media): Promise<string>;
processVideo(url: string, runtime: IAgentRuntime): Promise<Media>;
⋮----
export interface IBrowserService extends Service {
  getPageContent(
    url: string,
    runtime: IAgentRuntime
  ): Promise<{ title: string; description: string; bodyContent: string }>;
}
⋮----
getPageContent(
    url: string,
    runtime: IAgentRuntime
): Promise<
⋮----
export interface IPdfService extends Service {
  convertPdfToText(pdfBuffer: Buffer): Promise<string>;
}
⋮----
convertPdfToText(pdfBuffer: Buffer): Promise<string>;
⋮----
export interface IFileService extends Service {
  uploadFile(
    imagePath: string,
    subDirectory: string,
    useSignedUrl: boolean,
    expiresIn: number
  ): Promise<{
    success: boolean;
    url?: string;
    error?: string;
  }>;
  generateSignedUrl(fileName: string, expiresIn: number): Promise<string>;
}
⋮----
uploadFile(
    imagePath: string,
    subDirectory: string,
    useSignedUrl: boolean,
    expiresIn: number
): Promise<
generateSignedUrl(fileName: string, expiresIn: number): Promise<string>;
⋮----
export interface ITeeLogService extends Service {
  log(
    agentId: string,
    roomId: string,
    entityId: string,
    type: string,
    content: string
  ): Promise<boolean>;
  generateAttestation<T>(
    reportData: string,
    hashAlgorithm?: T | any
  ): Promise<string>;
  getAllAgents(): Promise<TeeAgent[]>;
  getAgent(agentId: string): Promise<TeeAgent | null>;
  getLogs(
    query: TeeLogQuery,
    page: number,
    pageSize: number
  ): Promise<TeePageQuery<TeeLog[]>>;
}
⋮----
log(
    agentId: string,
    roomId: string,
    entityId: string,
    type: string,
    content: string
  ): Promise<boolean>;
generateAttestation<T>(
    reportData: string,
    hashAlgorithm?: T | any
  ): Promise<string>;
getAllAgents(): Promise<TeeAgent[]>;
getAgent(agentId: string): Promise<TeeAgent | null>;
getLogs(
    query: TeeLogQuery,
    page: number,
    pageSize: number
  ): Promise<TeePageQuery<TeeLog[]>>;
⋮----
export interface TestCase {
  name: string;
  fn: (runtime: IAgentRuntime) => Promise<void> | void;
}
export interface TestSuite {
  name: string;
  tests: TestCase[];
}
export interface TeeLog {
  id: string;
  agentId: string;
  roomId: string;
  entityId: string;
  type: string;
  content: string;
  timestamp: number;
  signature: string;
}
export interface TeeLogQuery {
  agentId?: string;
  roomId?: string;
  entityId?: string;
  type?: string;
  containsContent?: string;
  startTimestamp?: number;
  endTimestamp?: number;
}
export interface TeeAgent {
  id: string;
  agentId: string;
  agentName: string;
  createdAt: number;
  publicKey: string;
  attestation: string;
}
export interface TeePageQuery<Result = any> {
  page: number;
  pageSize: number;
  total?: number;
  data?: Result;
}
export abstract class TeeLogDAO<DB = any>
⋮----
abstract initialize(): Promise<void>;
abstract addLog(log: TeeLog): Promise<boolean>;
abstract getPagedLogs(
    query: TeeLogQuery,
    page: number,
    pageSize: number
  ): Promise<TeePageQuery<TeeLog[]>>;
abstract addAgent(agent: TeeAgent): Promise<boolean>;
abstract getAgent(agentId: string): Promise<TeeAgent>;
abstract getAllAgents(): Promise<TeeAgent[]>;
⋮----
export enum TEEMode {
  OFF = "OFF",
  LOCAL = "LOCAL",
  DOCKER = "DOCKER",
  PRODUCTION = "PRODUCTION",
}
export interface RemoteAttestationQuote {
  quote: string;
  timestamp: number;
}
export interface DeriveKeyAttestationData {
  agentId: string;
  publicKey: string;
  subject?: string;
}
export interface RemoteAttestationMessage {
  agentId: string;
  timestamp: number;
  message: {
    entityId: string;
    roomId: string;
    content: string;
  };
}
export interface SgxAttestation {
  quote: string;
  timestamp: number;
}
export enum TeeType {
  SGX_GRAMINE = "sgx_gramine",
  TDX_DSTACK = "tdx_dstack",
}
export interface TeeVendorConfig {
  [key: string]: unknown;
}
export interface TeePluginConfig {
  vendor?: string;
  vendorConfig?: TeeVendorConfig;
}
export interface TaskWorker {
  name: string;
  execute: (
    runtime: IAgentRuntime,
    options: { [key: string]: unknown },
    task: Task
  ) => Promise<void>;
  validate?: (
    runtime: IAgentRuntime,
    message: Memory,
    state: State
  ) => Promise<boolean>;
}
export interface Task {
  id?: UUID;
  name: string;
  updatedAt?: number;
  metadata?: {
    updateInterval?: number;
    options?: {
      name: string;
      description: string;
    }[];
    [key: string]: unknown;
  };
  description: string;
  roomId?: UUID;
  worldId?: UUID;
  tags: string[];
}
export enum Role {
  OWNER = "OWNER",
  ADMIN = "ADMIN",
  NONE = "NONE",
}
export interface Setting {
  name: string;
  description: string;
  usageDescription: string;
  value: string | boolean | null;
  required: boolean;
  public?: boolean;
  secret?: boolean;
  validation?: (value: any) => boolean;
  dependsOn?: string[];
  onSetAction?: (value: any) => string;
  visibleIf?: (settings: { [key: string]: Setting }) => boolean;
}
export interface WorldSettings {
  [key: string]: Setting;
}
export interface OnboardingConfig {
  settings: {
    [key: string]: Omit<Setting, "value">;
  };
}
export interface BaseModelParams {
  runtime: IAgentRuntime;
}
export interface TextGenerationParams extends BaseModelParams {
  prompt: string;
  temperature?: number;
  maxTokens?: number;
  stopSequences?: string[];
  frequencyPenalty?: number;
  presencePenalty?: number;
}
export interface TextEmbeddingParams extends BaseModelParams {
  text: string;
}
export interface TokenizeTextParams extends BaseModelParams {
  prompt: string;
  modelType: ModelType;
}
export interface DetokenizeTextParams extends BaseModelParams {
  tokens: number[];
  modelType: ModelType;
}
export interface ImageGenerationParams extends BaseModelParams {
  prompt: string;
  size?: string;
  count?: number;
}
export interface ImageDescriptionParams extends BaseModelParams {
  imageUrl: string;
  prompt?: string;
}
export interface TranscriptionParams extends BaseModelParams {
  audioUrl: string;
  prompt?: string;
}
export interface TextToSpeechParams extends BaseModelParams {
  text: string;
  voice?: string;
  speed?: number;
}
export interface AudioProcessingParams extends BaseModelParams {
  audioUrl: string;
  processingType: string;
}
export interface VideoProcessingParams extends BaseModelParams {
  videoUrl: string;
  processingType: string;
}
export type JSONSchema = {
  type: string;
  properties?: Record<string, any>;
  required?: string[];
  items?: JSONSchema;
  [key: string]: any;
};
export interface ObjectGenerationParams<T = any> extends BaseModelParams {
  prompt: string;
  schema?: JSONSchema;
  output?: "object" | "array" | "enum";
  enumValues?: string[];
  modelType?: ModelType;
  temperature?: number;
  stopSequences?: string[];
}
export interface ModelParamsMap {
  [ModelTypes.TEXT_SMALL]: TextGenerationParams;
  [ModelTypes.TEXT_LARGE]: TextGenerationParams;
  [ModelTypes.TEXT_EMBEDDING]: TextEmbeddingParams | string | null;
  [ModelTypes.TEXT_TOKENIZER_ENCODE]: TokenizeTextParams;
  [ModelTypes.TEXT_TOKENIZER_DECODE]: DetokenizeTextParams;
  [ModelTypes.TEXT_REASONING_SMALL]: TextGenerationParams;
  [ModelTypes.TEXT_REASONING_LARGE]: TextGenerationParams;
  [ModelTypes.IMAGE]: ImageGenerationParams;
  [ModelTypes.IMAGE_DESCRIPTION]: ImageDescriptionParams | string;
  [ModelTypes.TRANSCRIPTION]: TranscriptionParams | Buffer | string;
  [ModelTypes.TEXT_TO_SPEECH]: TextToSpeechParams | string;
  [ModelTypes.AUDIO]: AudioProcessingParams;
  [ModelTypes.VIDEO]: VideoProcessingParams;
  [ModelTypes.OBJECT_SMALL]: ObjectGenerationParams<any>;
  [ModelTypes.OBJECT_LARGE]: ObjectGenerationParams<any>;
  [key: string]: BaseModelParams | any;
}
export interface ModelResultMap {
  [ModelTypes.TEXT_SMALL]: string;
  [ModelTypes.TEXT_LARGE]: string;
  [ModelTypes.TEXT_EMBEDDING]: number[];
  [ModelTypes.TEXT_TOKENIZER_ENCODE]: number[];
  [ModelTypes.TEXT_TOKENIZER_DECODE]: string;
  [ModelTypes.TEXT_REASONING_SMALL]: string;
  [ModelTypes.TEXT_REASONING_LARGE]: string;
  [ModelTypes.IMAGE]: { url: string }[];
  [ModelTypes.IMAGE_DESCRIPTION]: { title: string; description: string };
  [ModelTypes.TRANSCRIPTION]: string;
  [ModelTypes.TEXT_TO_SPEECH]: Readable | Buffer;
  [ModelTypes.AUDIO]: any;
  [ModelTypes.VIDEO]: any;
  [ModelTypes.OBJECT_SMALL]: any;
  [ModelTypes.OBJECT_LARGE]: any;
  [key: string]: any;
}
export enum EventTypes {
  WORLD_JOINED = "WORLD_JOINED",
  WORLD_CONNECTED = "WORLD_CONNECTED",
  WORLD_LEFT = "WORLD_LEFT",
  ENTITY_JOINED = "ENTITY_JOINED",
  ENTITY_LEFT = "ENTITY_LEFT",
  ENTITY_UPDATED = "ENTITY_UPDATED",
  ROOM_JOINED = "ROOM_JOINED",
  ROOM_LEFT = "ROOM_LEFT",
  MESSAGE_RECEIVED = "MESSAGE_RECEIVED",
  MESSAGE_SENT = "MESSAGE_SENT",
  VOICE_MESSAGE_RECEIVED = "VOICE_MESSAGE_RECEIVED",
  VOICE_MESSAGE_SENT = "VOICE_MESSAGE_SENT",
  REACTION_RECEIVED = "REACTION_RECEIVED",
  POST_GENERATED = "POST_GENERATED",
  INTERACTION_RECEIVED = "INTERACTION_RECEIVED",
  RUN_STARTED = "RUN_STARTED",
  RUN_ENDED = "RUN_ENDED",
  RUN_TIMEOUT = "RUN_TIMEOUT",
  ACTION_STARTED = "ACTION_STARTED",
  ACTION_COMPLETED = "ACTION_COMPLETED",
  EVALUATOR_STARTED = "EVALUATOR_STARTED",
  EVALUATOR_COMPLETED = "EVALUATOR_COMPLETED",
}
export enum PlatformPrefix {
  DISCORD = "DISCORD",
  TELEGRAM = "TELEGRAM",
  TWITTER = "TWITTER",
}
export interface EventPayload {
  runtime: IAgentRuntime;
  source: string;
}
export interface WorldPayload extends EventPayload {
  world: World;
  rooms: Room[];
  entities: Entity[];
}
export interface EntityPayload extends EventPayload {
  entityId: UUID;
  worldId?: UUID;
  roomId?: UUID;
  metadata?: {
    orginalId: string;
    username: string;
    displayName?: string;
    [key: string]: any;
  };
}
export interface MessagePayload extends EventPayload {
  message: Memory;
  callback?: HandlerCallback;
}
export interface RunEventPayload extends EventPayload {
  runId: UUID;
  messageId: UUID;
  roomId: UUID;
  entityId: UUID;
  startTime: number;
  status: "started" | "completed" | "timeout";
  endTime?: number;
  duration?: number;
  error?: string;
}
export interface ActionEventPayload extends EventPayload {
  actionId: UUID;
  actionName: string;
  startTime?: number;
  completed?: boolean;
  error?: Error;
}
export interface EvaluatorEventPayload extends EventPayload {
  evaluatorId: UUID;
  evaluatorName: string;
  startTime?: number;
  completed?: boolean;
  error?: Error;
}
export interface EventPayloadMap {
  [EventTypes.WORLD_JOINED]: WorldPayload;
  [EventTypes.WORLD_CONNECTED]: WorldPayload;
  [EventTypes.WORLD_LEFT]: WorldPayload;
  [EventTypes.ENTITY_JOINED]: EntityPayload;
  [EventTypes.ENTITY_LEFT]: EntityPayload;
  [EventTypes.ENTITY_UPDATED]: EntityPayload;
  [EventTypes.MESSAGE_RECEIVED]: MessagePayload;
  [EventTypes.MESSAGE_SENT]: MessagePayload;
  [EventTypes.REACTION_RECEIVED]: MessagePayload;
  [EventTypes.POST_GENERATED]: MessagePayload;
  [EventTypes.INTERACTION_RECEIVED]: MessagePayload;
  [EventTypes.RUN_STARTED]: RunEventPayload;
  [EventTypes.RUN_ENDED]: RunEventPayload;
  [EventTypes.RUN_TIMEOUT]: RunEventPayload;
  [EventTypes.ACTION_STARTED]: ActionEventPayload;
  [EventTypes.ACTION_COMPLETED]: ActionEventPayload;
  [EventTypes.EVALUATOR_STARTED]: EvaluatorEventPayload;
  [EventTypes.EVALUATOR_COMPLETED]: EvaluatorEventPayload;
}
export type EventHandler<T extends keyof EventPayloadMap> = (
  payload: EventPayloadMap[T]
) => Promise<void>;
export enum SOCKET_MESSAGE_TYPE {
  ROOM_JOINING = 1,
  SEND_MESSAGE = 2,
}
export interface MessageMemory extends Memory {
  metadata: MessageMetadata;
  content: Content & {
    text: string;
  };
}
export function createMessageMemory(params: {
  id?: UUID;
  entityId: UUID;
  agentId?: UUID;
  roomId: UUID;
  content: Content & { text: string };
  embedding?: number[];
}): MessageMemory
export interface TypedService<ConfigType = unknown, ResultType = unknown>
  extends Service {
  config: ConfigType;
  process(input: unknown): Promise<ResultType>;
}
⋮----
process(input: unknown): Promise<ResultType>;
⋮----
export function getTypedService<T extends TypedService<any, any>>(
  runtime: IAgentRuntime,
  serviceType: ServiceType
): T | null
export type Result<T, E = Error> = Success<T> | Failure<E>;
export class Success<T>
⋮----
constructor(value: T)
map<U>(fn: (value: T) => U): Success<U>
unwrapOr(_defaultValue: T): T
⋮----
export class Failure<E = Error>
⋮----
constructor(error: E)
mapError<F>(fn: (error: E) => F): Failure<F>
unwrapOr<T>(defaultValue: T): T
⋮----
export function success<T>(value: T): Success<T>
export function failure<E = Error>(error: E): Failure<E>
export function isDocumentMetadata(
  metadata: MemoryMetadata
): metadata is DocumentMetadata
export function isFragmentMetadata(
  metadata: MemoryMetadata
): metadata is FragmentMetadata
export function isMessageMetadata(
  metadata: MemoryMetadata
): metadata is MessageMetadata
export function isDescriptionMetadata(
  metadata: MemoryMetadata
): metadata is DescriptionMetadata
export function isCustomMetadata(
  metadata: MemoryMetadata
): metadata is CustomMetadata
export interface ServiceError {
  code: string;
  message: string;
  details?: unknown;
  cause?: Error;
}
export function getVideoService(runtime: IAgentRuntime): IVideoService | null
export function getBrowserService(
  runtime: IAgentRuntime
): IBrowserService | null
export function getPdfService(runtime: IAgentRuntime): IPdfService | null
export function getFileService(runtime: IAgentRuntime): IFileService | null
export function isDocumentMemory(
  memory: Memory
): memory is Memory &
export function isFragmentMemory(
  memory: Memory
): memory is Memory &
export function getMemoryText(memory: Memory, defaultValue = ""): string
/**
 * Safely create a ServiceError from any caught error
 */
export function createServiceError(
  error: unknown,
  code = "UNKNOWN_ERROR"
): ServiceError
export type StateValue =
  | string
  | number
  | boolean
  | null
  | StateObject
  | StateArray;
export interface StateObject {
  [key: string]: StateValue;
}
export type StateArray = StateValue[];
export interface EnhancedState {
  values: StateObject;
  data: StateObject;
  text: string;
  [key: string]: StateValue;
}
export type ComponentData = Record<string, unknown>;
export type EventDataObject = Record<string, unknown>;
export type TypedEventHandler = (data: EventDataObject) => Promise<void> | void;
export type DbConnection = unknown;
export type MetadataObject = Record<string, unknown>;
export type ModelHandler = (
  runtime: IAgentRuntime,
  params: Record<string, unknown>
) => Promise<unknown>;
export type ServiceConfig = Record<string, unknown>;
export type MessageMemoryManager = IMemoryManager<MessageMemory>;
export type DocumentMemoryManager = IMemoryManager<
  Memory & { metadata: DocumentMetadata }
>;
export type FragmentMemoryManager = IMemoryManager<
  Memory & { metadata: FragmentMetadata }
>;
````

## File: packages/docs/docs/core/actions.md
````markdown
---
sidebar_position: 6
---

# ⚡ Actions

Actions define how agents respond to and interact with messages. They enable agents to perform tasks beyond simple message responses by integrating with external systems and modifying behavior.

## Overview

1. Structure:

An Action consists of:

- `name`: Unique identifier 
- `similes`: Alternative names/triggers
- `description`: Purpose and usage explanation
- `validate`: Function to check if action is appropriate
- `handler`: Core implementation logic
- `examples`: Sample usage patterns
- `suppressInitialMessage`: Optional flag to suppress initial response


2. Validation:

- Checks if the action can be executed
- Consider conversation state
- Validate required 

---

## Implementation

```typescript
interface Action {
    name: string;
    similes: string[];
    description: string;
    examples: ActionExample[][];
    handler: Handler;
    validate: Validator;
    suppressInitialMessage?: boolean;
}
```

Source: https://github.com/elizaOS/eliza/blob/main/packages/core/src/types.ts


### Basic Action Template

```typescript
const customAction: Action = {
    name: "CUSTOM_ACTION",
    similes: ["ALTERNATE_NAME", "OTHER_TRIGGER"],
    description: "Detailed description of when and how to use this action",
    validate: async (runtime: IAgentRuntime, message: Memory) => {
        // Validation logic
        return true;
    },
    handler: async (runtime: IAgentRuntime, message: Memory) => {
        // Implementation logic
        return true;
    },
    examples: [
        [
            {
                user: "{{user1}}",
                content: { text: "Trigger message" },
            },
            {
                user: "{{user2}}",
                content: { text: "Response", action: "CUSTOM_ACTION" },
            },
        ],
    ],
};
```

#### Character File Example

Actions can be used in character files as well. Here's an example from: https://github.com/elizaOS/characters/blob/main/sbf.character.json

```json
    "messageExamples": [
        [
            {
                "user": "{{user1}}",
                "content": {
                    "text": "Can you help transfer some SOL?"
                }
            },
            {
                "user": "SBF",
                "content": {
                    "text": "yeah yeah for sure, sending SOL is pretty straightforward. just need the recipient and amount. everything else is basically fine, trust me.",
                    "action": "SEND_SOL"
                }
            }
        ],
```

---

## Example Implementations

Actions can be found across various plugins in the Eliza ecosystem, with a comprehensive collection available at https://github.com/elizaos-plugins. Here are some notable examples:

### Blockchain and Token Actions
- Transfers: `SEND_TOKEN`, `SEND_SOL`, `SEND_NEAR`, `SEND_AVAIL`, `SEND_TON`, `SEND_TOKENS`, `COSMOS_TRANSFER`, `CROSS_CHAIN_TRANSFER`
- Token Management: `CREATE_TOKEN`, `GET_TOKEN_INFO`, `GET_BALANCE`, `GET_TOKEN_PRICE`, `TOKEN_SWAP`, `SWAP_TOKEN`, `EXECUTE_SPOT_TRADE`
- Blockchain Interactions: `READ_CONTRACT`, `WRITE_CONTRACT`, `DEPLOY_CONTRACT`, `DEPLOY_TOKEN`, `GET_TRANSACTION`, `GET_CURRENT_NONCE`, `GET_CONTRACT_SCHEMA`

### Cryptographic and Security Actions
- Signature and Authentication: `ECDSA_SIGN`, `LIT_ACTION`, `REMOTE_ATTESTATION`, `AUTHENTICATE`
- Wallet and Key Management: `ERC20_TRANSFER`, `WALLET_TRANSFER`, `BRIDGE_OPERATIONS`

### Staking and Governance
- Staking Actions: `STAKE`, `DELEGATE_TOKEN`, `UNDELEGATE_TOKEN`, `GET_STAKE_BALANCE`, `TOKENS_REDELEGATE`
- Governance Actions: `VOTE_ON_PROPOSAL`, `PROPOSE`, `EXECUTE_PROPOSAL`, `QUEUE_PROPOSAL`

### AI and Agent Management
- Agent Creation: `LAUNCH_AGENT`, `START_SESSION`, `CREATE_AND_REGISTER_AGENT`
- AI-Specific Actions: `GENERATE_IMAGE`, `DESCRIBE_IMAGE`, `GENERATE_VIDEO`, `GENERATE_MUSIC`, `GET_INFERENCE`, `GENERATE_MEME`

### Media and Content Generation
- Image and Multimedia: `SEND_GIF`, `GENERATE_3D`, `GENERATE_COLLECTION`, `MINT_NFT`, `LIST_NFT`, `SWEEP_FLOOR_NFT`
- Audio and Voice: `EXTEND_AUDIO`, `CREATE_TTS`

### Decentralized Infrastructure (DePIN)
- Project Interactions: `DEPIN_TOKENS`, `DEPIN_ON_CHAIN`, `ANALYZE_DEPIN_PROJECTS`

### Search and Information Retrieval
- Data Search: `WEB_SEARCH`, `GET_TOKEN_PRICE_BY_ADDRESS`, `GET_TRENDING_POOLS`, `GET_NEW_COINS`, `GET_MARKETS`

### Blockchain and Trading
- Specialized Actions: `GET_QUOTE_0X`, `EXECUTE_SWAP_0X`, `CANCEL_ORDERS`, `GET_INDICATIVE_PRICE`

### Social and Communication
- Platform Interactions: `TWEET`, `POST_TWEET`, `QUOTE`, `JOIN_VOICE`, `LEAVE_VOICE`, `TRANSCRIBE_MEDIA`, `SUMMARIZE_CONVERSATION`

### Utility Actions
- General Utilities: `FAUCET`, `SUBMIT_DATA`, `PRICE_CHECK`, `WEATHER`, `NEWS`

Check out the [ElizaOS Plugins org](https://github.com/elizaos-plugins) on GitHub if interested in studying or using any of these.

### Image Generation Action

Here's a comprehensive example of an image generation action:

```typescript
import { Action, IAgentRuntime, Memory, State } from "@elizaos/core";

// Example image generation action
const generateImageAction: Action = {
    name: "GENERATE_IMAGE", 
    similes: ["CREATE_IMAGE", "MAKE_IMAGE", "DRAW"],
    description: "Generates an image based on the user's description",
    suppressInitialMessage: true, // Suppress initial response since we'll generate our own

    // Validate if this action should be used
    validate: async (runtime: IAgentRuntime, message: Memory) => {
        const text = message.content.text.toLowerCase();
        // Check if message contains image generation triggers
        return (
            text.includes("generate") ||
            text.includes("create") ||
            text.includes("draw") ||
            text.includes("make an image")
        );
    },

    // Handle the action execution
    handler: async (runtime: IAgentRuntime, message: Memory, state?: State) => {
        try {
            // Get image service
            const imageService = runtime.getService(ServiceType.IMAGE_GENERATION);
            
            // Generate image
            const imageUrl = await imageService.generateImage(message.content.text);

            // Create response with generated image
            await runtime.messageManager.createMemory({
                id: generateId(),
                content: {
                    text: "Here's the image I generated:",
                    attachments: [{
                        type: "image",
                        url: imageUrl
                    }]
                },
                userId: runtime.agentId,
                roomId: message.roomId,
            });

            return true;
        } catch (error) {
            console.error("Image generation failed:", error);
            return false;
        }
    },

    // Example usage patterns
    examples: [
        [
            {
                user: "{{user1}}",
                content: { 
                    text: "Can you generate an image of a sunset?" 
                }
            },
            {
                user: "{{user2}}",
                content: {
                    text: "I'll create that image for you",
                    action: "GENERATE_IMAGE"
                }
            }
        ]
    ]
};
```

### Basic Conversation Actions

You can find these samples in the plugin-bootstrap package: https://github.com/elizaOS/eliza/tree/main/packages/plugin-bootstrap/src/actions

#### CONTINUE

For continuing conversations:

```typescript
const continueAction: Action = {
    name: "CONTINUE",
    similes: ["ELABORATE", "GO_ON"],
    description: "Continues the conversation when appropriate",

    validate: async (runtime: IAgentRuntime, message: Memory) => {
        // Check if message warrants continuation
        const text = message.content.text.toLowerCase();
        return (
            text.includes("tell me more") ||
            text.includes("what else") ||
            text.includes("continue") ||
            text.endsWith("?")
        );
    },

    handler: async (runtime: IAgentRuntime, message: Memory, state?: State) => {
        // Get recent conversation context
        const recentMessages = await runtime.messageManager.getMemories({
            roomId: message.roomId,
            count: 5
        });

        // Generate contextual response
        const response = await runtime.generateResponse(
            message,
            recentMessages,
            state
        );

        // Store response
        await runtime.messageManager.createMemory({
            id: generateId(),
            content: response,
            userId: runtime.agentId,
            roomId: message.roomId
        });

        return true;
    },

    examples: [
        [
            {
                user: "{{user1}}",
                content: { text: "Tell me more about that" }
            },
            {
                user: "{{user2}}",
                content: {
                    text: "I'll continue explaining...",
                    action: "CONTINUE"
                }
            }
        ]
    ]
};
```

#### IGNORE 

For ending conversations:

```typescript
const ignoreAction: Action = {
    name: "IGNORE",
    similes: ["STOP_TALKING", "END_CONVERSATION"],
    description: "Stops responding when conversation is complete or irrelevant",

    validate: async (runtime: IAgentRuntime, message: Memory) => {
        const text = message.content.text.toLowerCase();
        return (
            text.includes("goodbye") ||
            text.includes("bye") ||
            text.includes("thanks") ||
            text.length < 2
        );
    },

    handler: async (runtime: IAgentRuntime, message: Memory) => {
        // No response needed
        return true;
    },

    examples: [
        [
            {
                user: "{{user1}}",
                content: { text: "Thanks, goodbye!" }
            },
            {
                user: "{{user2}}",
                content: {
                    text: "",
                    action: "IGNORE"
                }
            }
        ]
    ]
};
```

---

## FAQ

### What are Actions in Eliza?
Actions are core building blocks that define how agents interact with messages and perform tasks beyond simple text responses.

### How do Actions work?
Actions consist of a name, description, validation function, and handler function that determine when and how an agent can perform a specific task.

### What can Actions do?
Actions enable agents to interact with external systems, modify behavior, process complex workflows, and extend capabilities beyond conversational responses.

### What are some example Actions?
Common actions include CONTINUE (extend dialogue), IGNORE (end conversation), GENERATE_IMAGE (create images), TRANSFER (move tokens), and READ_CONTRACT (retrieve blockchain data).

### How do I create a custom Action?
Define an action with a unique name, validation function to check eligibility, handler function to implement the logic, and provide usage examples.

### What makes a good Action?
A good action has a clear, single purpose, robust input validation, comprehensive error handling, and provides meaningful interactions.

### Can Actions be chained together?
Yes, actions can be composed and chained to create complex workflows and multi-step interactions.

### How are Actions different from tools?
Actions are more comprehensive, ensuring the entire process happens, while tools are typically more focused on specific, discrete operations.

### Where are Actions defined?
Actions can be defined in character files, plugins, or directly in agent configurations.

## Further Reading

- [characterfile](./characterfile.md)
- [providers](./providers.md)
````

## File: packages/docs/docs/core/agents.md
````markdown
# 🤖 Agent Runtime

The `AgentRuntime` is the core runtime environment for Eliza agents. It handles message processing, state management, plugin integration, and interaction with external services. You can think of it as the brains that provide the high-level orchestration layer for Eliza agents.

![](/img/eliza-architecture.jpg)

The runtime follows this general flow:
1. Agent loads character config, plugins, and services
	- Processes knowledge sources (e.g., documents, directories)
2. Receives a message, composes the state
3. Processes actions and then evaluates
	- Retrieves relevant knowledge fragments using RAG
4. Generates and executes responses, then evaluates
5. Updates memory and state


---

## Overview

The [AgentRuntime](/api/classes/AgentRuntime) class is the primary implementation of the [IAgentRuntime](/api/interfaces/IAgentRuntime) interface, which manages the agent's core functions, including:


| Component | Description | API Reference | Related Files |
|---------|-------------|---------------|---------------|
| **Clients** | Supports multiple communication platforms for seamless interaction. | [Clients API](/api/interfaces/IAgentRuntime/#clients) | [`clients.ts`](https://github.com/elizaos-plugins/client-discord/blob/main/__tests__/discord-client.test.ts), [`Discord`](https://github.com/elizaos-plugins/client-discord), [`Telegram`](https://github.com/elizaos-plugins/client-telegram), [`Twitter`](https://github.com/elizaos-plugins/client-twitter), [`Farcaster`](https://github.com/elizaos-plugins/client-farcaster), [`Lens`](https://github.com/elizaos-plugins/client-lens), [`Slack`](https://github.com/elizaos-plugins/client-slack), [`Auto`](https://github.com/elizaos-plugins/client-auto), [`GitHub`](https://github.com/elizaos-plugins/client-github) |
| **State** | Maintains context for coherent cross-platform interactions, updates dynamically. Also tracks goals, knowledge, and recent interactions | [State API](/api/interfaces/State) | [`state.ts`](https://github.com/elizaos/runtime/state.ts) |
| **Plugins** | Dynamic extensions of agent functionalities using custom actions, evaluators, providers, and adapters | [Plugins API](/api/type-aliases/Plugin/) | [`plugins.ts`](https://github.com/elizaos/runtime/plugins.ts), [actions](../actions), [evaluators](../evaluators), [providers](../providers) |
| **Services** | Connects with external services for `IMAGE_DESCRIPTION`, `TRANSCRIPTION`, `TEXT_GENERATION`, `SPEECH_GENERATION`, `VIDEO`, `PDF`, `BROWSER`, `WEB_SEARCH`, `EMAIL_AUTOMATION`, and more | [Services API](/api/interfaces/IAgentRuntime/#services) | [`services.ts`](https://github.com/elizaos/runtime/services.ts) |
| **Memory Systems** | Creates, retrieves, and embeds memories and manages conversation history. | [Memory API](/api/interfaces/IMemoryManager) | [`memory.ts`](https://github.com/elizaos/runtime/memory.ts) |
| **Database Adapters** | Persistent storage and retrieval for memories and knowledge | [databaseAdapter](api/interfaces/IAgentRuntime/#databaseAdapter) | [`MongoDB`](https://github.com/elizaos-plugins/adapter-mongodb), [`PostgreSQL`](https://github.com/elizaos-plugins/adapter-postgres), [`SQLite`](https://github.com/elizaos-plugins/adapter-sqlite), [`Supabase`](https://github.com/elizaos-plugins/adapter-supabase), [`PGLite`](https://github.com/elizaos-plugins/adapter-pglite), [`Qdrant`](https://github.com/elizaos-plugins/adapter-qdrant), [`SQL.js`](https://github.com/elizaos-plugins/adapter-sqljs) |
| **Cache Management** | Provides flexible storage and retrieval via various caching methods. | [Cache API](/api/interfaces/ICacheManager) | [`cache.ts`](https://github.com/elizaos/runtime/cache.ts) |



<details>
<summary>Advanced: IAgentRuntime Interface</summary>
```typescript
interface IAgentRuntime {
    // Core identification
    agentId: UUID;
    token: string;
    serverUrl: string;

    // Configuration
    character: Character;                          // Personality and behavior settings
    modelProvider: ModelProviderName;              // AI model to use
    imageModelProvider: ModelProviderName;
    imageVisionModelProvider: ModelProviderName;
    
    // Components
    plugins: Plugin[];                             // Additional capabilities
    clients: Record<string, Client>;               // Platform connections
    providers: Provider[];                         // Real-time data sources
    actions: Action[];                             // Available behaviors
    evaluators: Evaluator[];                       // Analysis & learning
    
    // Memory Management
    messageManager: IMemoryManager;                // Conversation history
    descriptionManager: IMemoryManager;
    documentsManager: IMemoryManager;              // Large documents
    knowledgeManager: IMemoryManager;              // Search & retrieval
    ragKnowledgeManager: IRAGKnowledgeManager;     // RAG integration
    loreManager: IMemoryManager;                   // Character background
    
    // Storage & Caching
    databaseAdapter: IDatabaseAdapter;            // Data persistence
    cacheManager: ICacheManager;                  // Performance optimization
    
    // Services
    services: Map<ServiceType, Service>;          // External integrations
    
    // Networking
    fetch: (url: string, options: any) => Promise<Response>;
}
```
Source: [/api/interfaces/IAgentRuntime/](/api/interfaces/IAgentRuntime/)

</details>


---

### **Key Methods**
- **`initialize()`**: Sets up the agent's runtime environment, including services, plugins, and knowledge processing.
- **`processActions()`**: Executes actions based on message content and state.
- **`evaluate()`**: Assesses messages and state using registered evaluators.
- **`composeState()`**: Constructs the agent's state object for response generation.
- **`updateRecentMessageState()`**: Updates the state with recent messages and attachments.
- **`registerService()`**: Adds a service to the runtime.
- **`registerMemoryManager()`**: Registers a memory manager for specific types of memories.
- **`ensureRoomExists()` / `ensureUserExists()`**: Ensures the existence of rooms and users in the database.

WIP


---

## Service System

Services provide specialized functionality with standardized interfaces that can be accessed cross-platform:

<details>
<summary>See Example</summary>

```typescript
// Speech Generation
const speechService = runtime.getService<ISpeechService>(
    ServiceType.SPEECH_GENERATION
);
const audioStream = await speechService.generate(runtime, text);

// PDF Processing
const pdfService = runtime.getService<IPdfService>(ServiceType.PDF);
const textContent = await pdfService.convertPdfToText(pdfBuffer);
```
</details>


---

## State Management

The runtime maintains comprehensive state through the State interface:

```typescript
interface State {
    // Core identifiers
    userId?: UUID;
    agentId?: UUID;
    roomId: UUID;

    // Character information
    bio: string;
    lore: string;
    messageDirections: string;
    postDirections: string;

    // Conversation context
    actors: string;
    actorsData?: Actor[];
    recentMessages: string;
    recentMessagesData: Memory[];

    // Goals and knowledge
    goals?: string;
    goalsData?: Goal[];
    knowledge?: string;
    knowledgeData?: KnowledgeItem[];
    ragKnowledgeData?: RAGKnowledgeItem[];
}

// State management methods
async function manageState() {
    // Initial state composition
    const state = await runtime.composeState(message, {
        additionalContext: "custom context"
    });

    // Update state with new messages
    const updatedState = await runtime.updateRecentMessageState(state);
}
```

---

## Plugin System

Plugins extend agent functionality through a modular interface. The runtime supports various types of plugins including clients, services, adapters, and more:

```typescript
interface Plugin {
    name: string;
    description: string;
    actions?: Action[];        // Custom behaviors
    providers?: Provider[];    // Data providers
    evaluators?: Evaluator[]; // Response assessment
    services?: Service[];     // Background processes
    clients?: Client[];       // Platform integrations
    adapters?: Adapter[];    // Database/cache adapters
}
```

Plugins can be configured through [characterfile](./characterfile) settings:

```json
{
  "name": "MyAgent",
  "plugins": [
    "@elizaos/plugin-solana",
    "@elizaos/plugin-twitter"
  ]
}
```

For detailed information about plugin development and usage, see the [ElizaOS Registry](https://github.com/elizaos-plugins).

---

## Running Multiple Agents

To run multiple agents:

```bash
pnpm start --characters="characters/agent1.json,characters/agent2.json"
```

Or use environment variables:
```
REMOTE_CHARACTER_URLS=https://example.com/characters.json
```

---

## FAQ

### What's the difference between an agent and a character?

A character defines personality and knowledge, while an agent provides the runtime environment and capabilities to bring that character to life.

### How do I choose the right database adapter?

Choose based on your needs:
- MongoDB: For scalable, document-based storage
- PostgreSQL: For relational data with complex queries
- SQLite: For simple, file-based storage
- Qdrant: For vector search capabilities

### How do I implement custom plugins?

Create a plugin that follows the plugin interface and register it with the runtime. See the plugin documentation for detailed examples.

### Do agents share memory across platforms?
By default, agents maintain separate memory contexts for different platforms to avoid mixing conversations. Use the memory management system and database adapters to persist and retrieve state information.

### How do I handle multiple authentication methods?

Use the character configuration to specify different authentication methods for different services. The runtime will handle the appropriate authentication flow.

### How do I manage environment variables?

Use a combination of:
- `.env` files for local development
- Character-specific settings for per-agent configuration
- Environment variables for production deployment

### Can agents communicate with each other?

Yes, through the message system and shared memory spaces when configured appropriately.
````

## File: packages/docs/docs/core/clients.md
````markdown
---
sidebar_position: 3
---

# 🔌 Clients

Clients are core components in Eliza that enable AI agents to interact with external platforms and services. Each client provides a specialized interface for communication while maintaining consistent agent behavior across different platforms.

---

## Supported Clients

| Client | Type | Key Features | Use Cases |
|--------|------|--------------|------------|
| [Discord](https://github.com/elizaos-plugins/client-discord) | Communication | • Voice channels • Server management • Moderation tools • Channel management | • Community management • Gaming servers • Event coordination |
| [Twitter](https://github.com/elizaos-plugins/client-twitter) | Social Media | • Post scheduling • Timeline monitoring • Engagement analytics • Content automation | • Brand management • Content creation • Social engagement |
| [Telegram](https://github.com/elizaos-plugins/client-telegram) | Messaging | • Bot API • Group chat • Media handling • Command system | • Customer support • Community engagement • Broadcast messaging |
| [Direct](https://github.com/elizaOS/eliza/tree/develop/packages/client-direct/src) | API | • REST endpoints • Web integration • Custom applications • Real-time communication | • Backend integration • Web apps • Custom interfaces |
| [GitHub](https://github.com/elizaos-plugins/client-github) | Development | • Repository management • Issue tracking • Pull requests • Code review | • Development workflow • Project management • Team collaboration |
| [Slack](https://github.com/elizaos-plugins/client-slack) | Enterprise | • Channel management • Conversation analysis • Workspace tools • Integration hooks | • Team collaboration • Process automation • Internal tools |
| [Lens](https://github.com/elizaos-plugins/client-lens) | Web3 | • Decentralized networking • Content publishing • Memory management • Web3 integration | • Web3 social networking • Content distribution • Decentralized apps |
| [Farcaster](https://github.com/elizaos-plugins/client-farcaster) | Web3 | • Decentralized social • Content publishing • Community engagement | • Web3 communities • Content creation • Social networking |
| [Auto](https://github.com/elizaos-plugins/client-auto) | Automation | • Workload management • Task scheduling • Process automation | • Background jobs • Automated tasks • System maintenance |

***Additional clients**:
- Instagram: Social media content and engagement
- XMTP: Web3 messaging and communications
- Alexa: Voice interface and smart device control
- Home Assistant: Home automation OS 
- Devai.me: AI first social client
- Simsai: Jeeter / Social media platform for AI

---

## System Overview

Clients serve as bridges between Eliza agents and various platforms, providing core capabilities:

1. **Message Processing**
   - Platform-specific message formatting and delivery
   - Media handling and attachments via [`Memory`](/api/interfaces/Memory) objects
   - Reply threading and context management
   - Support for different content types

2. **State & Memory Management**
   - Each client maintains independent state to prevent cross-platform contamination
   - Integrates with runtime memory managers for different types of content:
   - Messages processed by one client don't automatically appear in other clients' contexts
   - [`State`](/api/interfaces/State) persists across agent restarts through the database adapter

3. **Platform Integration** 
   - Authentication and API compliance
   - Event processing and webhooks
   - Rate limiting and cache management
   - Platform-specific feature support



## Client Configuration

Clients are configured through the [`Character`](/api/type-aliases/Character) configuration's [`clientConfig`](/api/type-aliases/Character/#clientconfig) property:

```typescript
export type Character = {
    // ... other properties ...
    clientConfig?: {
        discord?: {
            shouldIgnoreBotMessages?: boolean;
            shouldIgnoreDirectMessages?: boolean;
            shouldRespondOnlyToMentions?: boolean;
            messageSimilarityThreshold?: number;
            isPartOfTeam?: boolean;
            teamAgentIds?: string[];
            teamLeaderId?: string;
            teamMemberInterestKeywords?: string[];
            allowedChannelIds?: string[];
            autoPost?: {
                enabled?: boolean;
                monitorTime?: number;
                inactivityThreshold?: number;
                mainChannelId?: string;
                announcementChannelIds?: string[];
                minTimeBetweenPosts?: number;
            };
        };
        telegram?: {
            shouldIgnoreBotMessages?: boolean;
            shouldIgnoreDirectMessages?: boolean;
            shouldRespondOnlyToMentions?: boolean;
            shouldOnlyJoinInAllowedGroups?: boolean;
            allowedGroupIds?: string[];
            messageSimilarityThreshold?: number;
            // ... other telegram-specific settings
        };
        slack?: {
            shouldIgnoreBotMessages?: boolean;
            shouldIgnoreDirectMessages?: boolean;
        };
        // ... other client configs
    };
};
```

## Client Implementation

Each client manages its own:
- Platform-specific message formatting and delivery
- Event processing and webhooks
- Authentication and API integration
- Message queueing and rate limiting
- Media handling and attachments
- State management and persistence

Example of a basic client implementation:

```typescript
import { Client, IAgentRuntime, ClientInstance } from "@elizaos/core";

export class CustomClient implements Client {
    name = "custom";
    
    async start(runtime: IAgentRuntime): Promise<ClientInstance> {
        // Initialize platform connection
        // Set up event handlers
        // Configure message processing

        return {
            stop: async () => {
                // Cleanup resources
                // Close connections
            }
        };
    }
}
```

### Runtime Integration

Clients interact with the agent runtime through the [`IAgentRuntime`](api/interfaces/IAgentRuntime/) interface, which provides:

- Memory managers for different types of data storage
- Service access for capabilities like transcription or image generation
- State management and composition
- Message processing and action handling


### Memory System Integration

Clients use the runtime's memory managers to persist conversation data (source: [`memory.ts`](/api/interfaces/Memory)).

- `messageManager` Chat messages
- `documentsManager` File attachments  
- `descriptionManager` Media descriptions

<details>
<summary>See example</summary>
```typescript
// Store a new message
await runtime.messageManager.createMemory({
    id: messageId,
    content: { text: message.content },
    userId: userId,
    roomId: roomId,
    agentId: runtime.agentId
});

// Retrieve recent messages
const recentMessages = await runtime.messageManager.getMemories({
    roomId: roomId,
    count: 10
});
```
</details>

---

## Direct Client Example

The [Direct client](https://github.com/elizaOS/eliza/tree/develop/packages/client-direct) provides message processing, webhook integration, and a REST API interface for Eliza agents. It's the primary client used for testing and development.


Key features of the Direct client:
- Express.js server for HTTP endpoints
- Agent runtime management
- File upload handling
- Memory system integration
- WebSocket support for real-time communication


### Direct Client API Endpoints

| Endpoint                                | Method | Description                                     | Params                       | Input                                  | Response                                |
|-----------------------------------------|--------|-------------------------------------------------|------------------------------|-----------------------------------------|------------------------------------------|
| `/:agentId/whisper`                     | POST   | Audio transcription (Whisper)                   | `agentId`                     | Audio file                              | Transcription                            |
| `/:agentId/message`                     | POST   | Main message handler                            | `agentId`                     | Text, optional file                     | Agent response                           |
| `/agents/:agentIdOrName/hyperfi/v1`     | POST   | Hyperfi game integration                        | `agentIdOrName`               | Objects, emotes, history                | JSON (`lookAt`, `emote`, `say`, actions) |
| `/:agentId/image`                       | POST   | Image generation                               | `agentId`                     | Generation params                        | Image(s) with captions                   |
| `/fine-tune`                            | POST   | Proxy for BagelDB fine-tuning                  | None                          | Fine-tuning data                         | BagelDB API response                     |
| `/fine-tune/:assetId`                   | GET    | Download fine-tuned assets                     | `assetId`                     | None                                    | File download                            |
| `/:agentId/speak`                       | POST   | Text-to-speech (ElevenLabs)                    | `agentId`                     | Text                                    | Audio stream                             |
| `/:agentId/tts`                         | POST   | Direct text-to-speech                          | `agentId`                     | Text                                    | Audio stream                             |

### Static Routes
| Endpoint                | Method | Description              |
|-------------------------|--------|--------------------------|
| `/media/uploads/`      | GET    | Serves uploaded files    |
| `/media/generated/`    | GET    | Serves generated images  |

### Common Parameters
Most endpoints accept:
- `roomId` (defaults to agent-specific room)
- `userId` (defaults to `"user"`)
- `userName` (for identity management)

---

## FAQ

### What can clients actually do?

Clients handle platform-specific communication (like Discord messages or Twitter posts), manage memories and state, and execute actions like processing media or handling commands. Each client adapts these capabilities to its platform while maintaining consistent agent behavior.

### Can multiple clients be used simultaneously?
Yes, Eliza supports running multiple clients concurrently while maintaining consistent agent behavior across platforms.

### How are client-specific features handled?
Each client implements platform-specific features through its capabilities system, while maintaining a consistent interface for the agent.

### How co clients handle rate limits?
Clients implement platform-specific rate limiting with backoff strategies and queue management.

### How is client state managed?
Clients maintain their own connection state while integrating with the agent's runtime database adapter and memory / state management system.

### How do clients handle messages?

Clients translate platform messages into Eliza's internal format, process any attachments (images, audio, etc.), maintain conversation context, and manage response queuing and rate limits.

### How are messages processed across clients?
Each client processes messages independently in its platform-specific format, while maintaining conversation context through the shared memory system. V2 improves upon this architecture.

### How is state managed between clients?
Each client maintains separate state to prevent cross-contamination, but can access shared agent state through the runtime.


### How do clients integrate with platforms?

Each client implements platform-specific authentication, API compliance, webhook handling, and follows the platform's rules for rate limiting and content formatting.

### How do clients manage memory?

Clients use Eliza's memory system to track conversations, user relationships, and state, enabling context-aware responses and persistent interactions across sessions.
````

## File: packages/docs/docs/core/database.md
````markdown
---
sidebar_position: 7
---

# 💾 Database Adapters

Database adapters provide persistent storage capabilities for ElizaOS agents. They handle memory storage, relationship tracking, and knowledge management across different database backends.

## Overview

Database adapters implement the [`IDatabaseAdapter`](/api/interfaces/IDatabaseAdapter) interface to provide consistent data access across different storage solutions. Each adapter optimizes for specific use cases:

| Adapter | Best For | Key Features |
|---------|----------|--------------|
| [MongoDB](https://github.com/elizaos-plugins/adapter-mongodb) | Production deployments | Sharding, vector search, real-time participant management |
| [PostgreSQL](https://github.com/elizaos-plugins/adapter-postgres) | Enterprise & vector search | Dynamic vector dimensions, fuzzy matching, comprehensive logging |
| [SQLite](https://github.com/elizaos-plugins/adapter-sqlite) | Development & embedded | Lightweight, file-based, vector BLOB support |
| [Supabase](https://github.com/elizaos-plugins/adapter-supabase) | Cloud-hosted vector DB | Multiple embedding sizes, real-time subscriptions, row-level security |
| [PGLite](https://github.com/elizaos-plugins/adapter-pglite) | Browser environments | Lightweight PostgreSQL implementation, HNSW indexing |
| [Qdrant](https://github.com/elizaos-plugins/adapter-qdrant) | Vector-focused deployments | Optimized for RAG applications, sophisticated preprocessing |
| [SQL.js](https://github.com/elizaos-plugins/adapter-sqljs) | Browser environments | Full SQLite functionality in browser, complex queries |

## Core Functionality

All adapters extend the [`DatabaseAdapter`](/api/classes/DatabaseAdapter) base class and implement the [`IDatabaseAdapter`](/api/interfaces/IDatabaseAdapter) interface. Here's a comprehensive overview of available methods:

| Category | Method | Description | Parameters |
|----------|---------|-------------|------------|
| **Database Lifecycle** |
| | `init()` | Initialize database connection | - |
| | `close()` | Close database connection | - |
| **Memory Management** |
| | `createMemory()` | Store new memory | `memory: Memory, tableName: string, unique?: boolean` |
| | `getMemoryById()` | Retrieve specific memory | `id: UUID` |
| | `getMemories()` | Get memories matching criteria | `{ roomId: UUID, count?: number, unique?: boolean, tableName: string, agentId: UUID, start?: number, end?: number }` |
| | `getMemoriesByIds()` | Get multiple memories by IDs | `memoryIds: UUID[], tableName?: string` |
| | `getMemoriesByRoomIds()` | Get memories from multiple rooms | `{ agentId: UUID, roomIds: UUID[], tableName: string, limit?: number }` |
| | `searchMemories()` | Search with vector similarity | `{ tableName: string, agentId: UUID, roomId: UUID, embedding: number[], match_threshold: number, match_count: number, unique: boolean }` |
| | `searchMemoriesByEmbedding()` | Search memories by embedding vector | `embedding: number[], { match_threshold?: number, count?: number, roomId?: UUID, agentId?: UUID, unique?: boolean, tableName: string }` |
| | `removeMemory()` | Remove specific memory | `memoryId: UUID, tableName: string` |
| | `removeAllMemories()` | Remove all memories in room | `roomId: UUID, tableName: string` |
| | `countMemories()` | Count memories in room | `roomId: UUID, unique?: boolean, tableName?: string` |
| **Knowledge Management** |
| | `createKnowledge()` | Store new knowledge item | `knowledge: RAGKnowledgeItem` |
| | `getKnowledge()` | Retrieve knowledge | `{ id?: UUID, agentId: UUID, limit?: number, query?: string, conversationContext?: string }` |
| | `searchKnowledge()` | Semantic knowledge search | `{ agentId: UUID, embedding: Float32Array, match_threshold: number, match_count: number, searchText?: string }` |
| | `removeKnowledge()` | Remove knowledge item | `id: UUID` |
| | `clearKnowledge()` | Remove all knowledge | `agentId: UUID, shared?: boolean` |
| **Room & Participants** |
| | `createRoom()` | Create new conversation room | `roomId?: UUID` |
| | `getRoom()` | Get room by ID | `roomId: UUID` |
| | `removeRoom()` | Remove room | `roomId: UUID` |
| | `addParticipant()` | Add user to room | `userId: UUID, roomId: UUID` |
| | `removeParticipant()` | Remove user from room | `userId: UUID, roomId: UUID` |
| | `getParticipantsForRoom()` | List room participants | `roomId: UUID` |
| | `getParticipantsForAccount()` | Get user's room participations | `userId: UUID` |
| | `getRoomsForParticipant()` | Get rooms for user | `userId: UUID` |
| | `getRoomsForParticipants()` | Get shared rooms for users | `userIds: UUID[]` |
| | `getParticipantUserState()` | Get participant's state | `roomId: UUID, userId: UUID` |
| | `setParticipantUserState()` | Update participant state | `roomId: UUID, userId: UUID, state: "FOLLOWED"|"MUTED"|null` |
| **Account Management** |
| | `createAccount()` | Create new user account | `account: Account` |
| | `getAccountById()` | Retrieve user account | `userId: UUID` |
| | `getActorDetails()` | Get actor information | `{ roomId: UUID }` |
| **Relationships** |
| | `createRelationship()` | Create user connection | `{ userA: UUID, userB: UUID }` |
| | `getRelationship()` | Get relationship details | `{ userA: UUID, userB: UUID }` |
| | `getRelationships()` | Get all relationships | `{ userId: UUID }` |
| **Goals** |
| | `createGoal()` | Create new goal | `goal: Goal` |
| | `updateGoal()` | Update goal | `goal: Goal` |
| | `updateGoalStatus()` | Update goal status | `{ goalId: UUID, status: GoalStatus }` |
| | `getGoals()` | Get goals matching criteria | `{ agentId: UUID, roomId: UUID, userId?: UUID, onlyInProgress?: boolean, count?: number }` |
| | `removeGoal()` | Remove specific goal | `goalId: UUID` |
| | `removeAllGoals()` | Remove all goals in room | `roomId: UUID` |
| **Caching & Embedding** |
| | `getCachedEmbeddings()` | Retrieve cached embeddings | `{ query_table_name: string, query_threshold: number, query_input: string, query_field_name: string, query_field_sub_name: string, query_match_count: number }` |
| **Logging** |
| | `log()` | Log event or action | `{ body: { [key: string]: unknown }, userId: UUID, roomId: UUID, type: string }` |

### Implementation Notes

Each adapter optimizes these methods for their specific database backend:

- **MongoDB**: Uses aggregation pipelines for vector operations
- **PostgreSQL**: Leverages pgvector extension
- **SQLite**: Implements BLOB storage for vectors
- **Qdrant**: Optimizes with HNSW indexing
- **Supabase**: Adds real-time capabilities

> Note: For detailed implementation examples, see each adapter's source repository (https://github.com/elizaos-plugins)

All adapters provide:

```typescript
interface IDatabaseAdapter {
    // Memory Management
    createMemory(memory: Memory, tableName: string): Promise<void>;
    getMemories(params: { roomId: UUID; count?: number }): Promise<Memory[]>;
    searchMemories(params: SearchParams): Promise<Memory[]>;
    removeMemory(memoryId: UUID): Promise<void>;
    
    // Account & Room Management
    createAccount(account: Account): Promise<boolean>;
    getAccountById(userId: UUID): Promise<Account>;
    createRoom(roomId?: UUID): Promise<UUID>;
    getRoom(roomId: UUID): Promise<UUID>;
    
    // Participant Management
    addParticipant(userId: UUID, roomId: UUID): Promise<boolean>;
    getParticipantsForRoom(roomId: UUID): Promise<UUID[]>;
    
    // Knowledge Management
    createKnowledge(knowledge: RAGKnowledgeItem): Promise<void>;
    searchKnowledge(params: SearchParams): Promise<RAGKnowledgeItem[]>;
    
    // Goal Management
    createGoal(goal: Goal): Promise<void>;
    updateGoalStatus(params: { goalId: UUID; status: GoalStatus }): Promise<void>;
}
```

<details>
<summary>Relationship Management</summary>
```typescript
interface IDatabaseAdapter {
    // Room Management
    createRoom(roomId?: UUID): Promise<UUID>;
    getRoom(roomId: UUID): Promise<UUID | null>;
    getRoomsForParticipant(userId: UUID): Promise<UUID[]>;
    
    // Participant Management
    addParticipant(userId: UUID, roomId: UUID): Promise<boolean>;
    getParticipantsForRoom(roomId: UUID): Promise<UUID[]>;
    getParticipantUserState(roomId: UUID, userId: UUID): Promise<"FOLLOWED" | "MUTED" | null>;
    
    // Relationship Tracking
    createRelationship(params: { userA: UUID; userB: UUID }): Promise<boolean>;
    getRelationship(params: { userA: UUID; userB: UUID }): Promise<Relationship | null>;
}
```
</details>

<details>
<summary>Cache & Goal Management</summary>
```typescript
interface IDatabaseCacheAdapter {
    getCache(params: {
        agentId: UUID;
        key: string;
    }): Promise<string | undefined>;
    
    setCache(params: {
        agentId: UUID;
        key: string;
        value: string;
    }): Promise<boolean>;
}

interface IDatabaseAdapter {
    // Goal Management
    createGoal(goal: Goal): Promise<void>;
    updateGoal(goal: Goal): Promise<void>;
    getGoals(params: {
        agentId: UUID;
        roomId: UUID;
        userId?: UUID | null;
        onlyInProgress?: boolean;
        count?: number;
    }): Promise<Goal[]>;
}
```
</details>

---

## Adapter Implementations

### Quick Start

```typescript
// MongoDB
import { MongoDBAdapter } from '@elizaos/adapter-mongodb';
const mongoAdapter = new MongoDBAdapter({
    uri: process.env.MONGODB_URI,
    dbName: process.env.MONGODB_DB_NAME
});

// PostgreSQL
import { PostgresAdapter } from '@elizaos/adapter-postgres';
const pgAdapter = new PostgresAdapter({
    connectionString: process.env.POSTGRES_URI
});

// SQLite
import { SqliteDatabaseAdapter } from '@elizaos/adapter-sqlite';
const sqliteAdapter = new SqliteDatabaseAdapter('path/to/database.db');

// Supabase
import { SupabaseAdapter } from '@elizaos/adapter-supabase';
const supabaseAdapter = new SupabaseAdapter({
    url: process.env.SUPABASE_URL,
    apiKey: process.env.SUPABASE_API_KEY
});
```

## Adapter Comparison

| Feature | MongoDB | PostgreSQL | SQLite | Supabase |
|---------|---------|------------|---------|-----------|
| **Best For** | Production deployments | Enterprise & vector search | Development & embedded | Cloud-hosted vector DB |
| **Vector Support** | Native sharding | Multiple dimensions (384d-1536d) | BLOB storage | Multi-dimension tables |
| **Key Features** | Auto-sharding, Real-time tracking, Auto-reconnection | Fuzzy matching, UUID keys, Comprehensive logging | JSON validation, FK constraints, Built-in caching | Real-time subs, Row-level security, Type-safe queries |
| **Setup Requirements** | None | pgvector extension | None | None |
| **Collections/Tables** | rooms, participants, accounts, memories, knowledge | Same as MongoDB + vector extensions | Same as MongoDB + metadata JSON | Same as PostgreSQL + dimension-specific tables |

## Implementation Details

### PostgreSQL Requirements
```sql
CREATE EXTENSION IF NOT EXISTS vector;
CREATE EXTENSION IF NOT EXISTS fuzzystrmatch;
```

### SQLite Schema
```sql
CREATE TABLE memories (
    id TEXT PRIMARY KEY,
    type TEXT,
    content TEXT,
    embedding BLOB,
    userId TEXT FK,
    roomId TEXT FK,
    agentId TEXT FK
);

CREATE TABLE knowledge (
    id TEXT PRIMARY KEY,
    content TEXT NOT NULL,
    embedding BLOB,
    metadata JSON
);
```

### Supabase Vector Tables
```sql
CREATE TABLE memories_1536 (id UUID PRIMARY KEY, embedding vector(1536));
CREATE TABLE memories_1024 (id UUID PRIMARY KEY, embedding vector(1024));
```

## Embedding Support

| Adapter | Supported Dimensions |
|---------|---------------------|
| MongoDB | All (as arrays) |
| PostgreSQL | OpenAI (1536d), Ollama (1024d), GAIANET (768d), BGE (384d) |
| SQLite | All (as BLOB) |
| Supabase | Configurable (384d-1536d) |

Source code: [elizaos-plugins](https://github.com/elizaos-plugins)

---

## Transaction & Error Handling

All adapters extend the [`DatabaseAdapter`](/api/classes/DatabaseAdapter) base class which provides built-in transaction support and error handling through the [`CircuitBreaker`](/api/classes/CircuitBreaker) pattern. See [database.ts](https://github.com/elizaos-plugins/core/blob/main/src/database.ts) for implementation details, as well as the [PostgreSQL Adapter Implementation](https://github.com/elizaos-plugins/adapter-postgres/blob/main/src/index.ts) or [SQLite Adapter Implementation](https://github.com/elizaos-plugins/adapter-sqlite/blob/main/src/index.ts) for detailed examples.

```typescript
// Transaction handling
const result = await adapter.withTransaction(async (client) => {
    await client.query("BEGIN");
    // Perform multiple operations
    await client.query("COMMIT");
    return result;
});

// Error handling with circuit breaker
protected async withCircuitBreaker<T>(
    operation: () => Promise<T>,
    context: string
): Promise<T> {
    try {
        return await this.circuitBreaker.execute(operation);
    } catch (error) {
        // Circuit breaker prevents cascading failures
        elizaLogger.error(`Circuit breaker error in ${context}:`, error);
        throw error;
    }
}
```

Implemented features include:
- Automatic rollback on errors
- Circuit breaker pattern to prevent cascading failures ([source](https://github.com/elizaOS/eliza/blob/main/packages/core/src/database/CircuitBreaker.ts))
- Connection pool management
- Error type classification

---

## FAQ

### How do I choose the right adapter?

Select based on your deployment needs. Use MongoDB/PostgreSQL for production, SQLite for development, SQL.js/PGLite for browser environments, and Qdrant/Supabase for vector-focused applications.

### Can I switch adapters later?

Yes, all adapters implement the [`IDatabaseAdapter`](/api/interfaces/IDatabaseAdapter) interface. Data migration between adapters is possible but requires additional steps.

### How are vector embeddings handled?

Each adapter implements vector storage based on its native capabilities - PostgreSQL/Supabase use native vector types, MongoDB uses array fields with indexes, SQLite uses BLOB storage, and Qdrant uses optimized vector stores.

### What about data migration?

Use the adapter's export/import methods defined in the [`DatabaseAdapter`](/api/classes/DatabaseAdapter) base class.

### How do I handle schema updates?

Run migrations using the adapter-specific CLI tools. Each adapter provides its own migration system - check the adapter's README in the [elizaos-plugins](https://github.com/elizaos-plugins) repository.

### How do I fix database connection issues?

Check your connection string format, verify the database exists and is accessible, ensure proper adapter configuration, and consider using environment variables for credentials.

### How do I resolve embedding dimension mismatch errors?

Set USE_OPENAI_EMBEDDING=TRUE in your .env file. Different models use different vector dimensions (e.g., OpenAI uses 1536, some local models use 384). Clear your database when switching embedding models.

### How do I clear/reset my database?

Delete the db.sqlite file in your data directory and restart the agent. For production databases, use proper database management tools for cleanup.

### Which database should I use in production?

PostgreSQL with vector extensions is recommended for production deployments. SQLite works well for development but may not scale as effectively for production loads.

### How do I migrate between different database adapters?

Use the export/import methods provided by the DatabaseAdapter base class. Each adapter implements these methods for data migration, though you may need to handle schema differences manually.

## Further Reading

- [Memory Management](../guides/memory-management.md)
- [State Management](./agents.md)
````

## File: packages/docs/docs/core/evaluators.md
````markdown
---
sidebar_position: 5
---

# 📊 Evaluators

[Evaluators](/api/interfaces/evaluator) are core components that assess and extract information from conversations. Agents use evaluators to automatically process conversations after they happen to help build up their knowledge and understanding over time.


They integrate with the [`AgentRuntime`](/api/classes/AgentRuntime) evaluation system to enable reflection, fact-gathering, and behavioral adaptation and run after each agent action to help maintain contextural awareness. Enabling agents to reflect on their actions and world state is crucial for improving coherence and problem-solving abilities. For example, by reflecting on its performance, an agent can refine its strategies and improve its interactions over time.

---

## How They Work

Evaluators run automatically after each agent action (responses, messages, activities, or API calls) to analyze what happened and update the agent's understanding. They extract important information (like facts about users), track progress on goals, and learn from interactions.

Let's say you're at a party and meet someone new. During the conversation:
- You learn their name is Sarah
- They mention living in Seattle 
- They work as a software engineer

After the conversation, your brain:
- Stores these facts for later
- Updates your understanding of who Sarah is
- Might note "I should connect Sarah with Bob who's also in tech"

This is exactly how evaluators work for agents - they run in the background to extract insights, track progress, and build up the agent's knowledge over time. However there are some limitations, such as evaluators only process current interactions (can't modify past data), they run after actions complete (not during). Therefore evaluators are best for analysis rather than critical operations.

The key thing to remember is: evaluators are your agent's way of learning and growing from each interaction, just like how we naturally process and learn from our conversations.

### Common Uses

- **[Fact Evaluator](https://github.com/elizaOS/eliza/blob/main/packages/plugin-bootstrap/src/evaluators/fact.ts)**: Learns and remembers facts about users
- **[Goal Evaluator](https://raw.githubusercontent.com/elizaOS/eliza/refs/heads/main/packages/plugin-bootstrap/src/evaluators/goal.ts)**: Tracks progress on objectives
- **Trust Evaluator**: Builds understanding of relationships
- **Sentiment Evaluator**: Tracks emotional tone of conversations

---

## Implementation

Here's a basic example of an evaluator implementation:

```typescript
const evaluator = {
    // Should this evaluator run right now?
    validate: async (runtime, message) => {
        // Return true to run, false to skip
        return shouldRunThisTime;
    },

    // What to do when it runs
    handler: async (runtime, message) => {
        // Extract info, update memory, etc
        const newInfo = extractFromMessage(message);
        await storeInMemory(newInfo);
    }
};
```

### Core Interface

```typescript
interface Evaluator {
    name: string;                // Unique identifier
    similes: string[];          // Similar evaluator descriptions
    description: string;        // Purpose and functionality
    validate: (runtime: IAgentRuntime, message: Memory) => Promise<boolean>;
    handler: (runtime: IAgentRuntime, message: Memory) => Promise<any>;
    examples: EvaluatorExample[];
}
```

For full type definitions, see the [`Evaluator`](/api/interfaces/Evaluator) interface documentation.

### Validation Function

The `validate` function is critical for determining when an evaluator should run. For peak performance, proper validation ensures evaluators run only when necessary. For instance, a customer service agent might check if all required user data has been collected and only run if data is still missing.

```typescript
validate: async (runtime: IAgentRuntime, message: Memory) => boolean
```
Determines if evaluator should run for current message. Returns true to execute handler, false to skip. Should be efficient and quick to check.

### Handler Function

The handler function contains the evaluator's code. It is where the logic for analyzing data, extracting information, and triggering actions resides.

```typescript
handler: async (runtime: IAgentRuntime, message: Memory) => any
```
Contains main evaluation logic and runs when validate() returns true. Can access [`runtime`](/api/interfaces/IAgentRuntime) services and [`memory`](/api/interfaces/Memory).


:::tip
**Ensure Evaluators are unique and lightweight**

Avoid complex operations or lengthy computations within the evaluator's handler function and ensure that evaluators have clear and distinct responsibilities not already handled by other components for peak performance.
:::

### Memory Integration
Results are stored using runtime memory managers:

```typescript
// Example storing evaluation results 
const memory = await runtime.memoryManager.addEmbeddingToMemory({
    userId: user?.id,
    content: { text: evaluationResult },
    roomId: roomId,
    embedding: await embed(runtime, evaluationResult)
});

await runtime.memoryManager.createMemory(memory);
```


---

## Fact Evaluator


:::info Deep Dive
For a comprehensive guide on how the fact evaluator system works, including implementation details and best practices, check out our [Fact Evaluator Guide](fact-evaluator.md).
:::

The Fact Evaluator is one of the most powerful built-in evaluators. It processes convos to:
- Extract meaningful facts and opinions about users and the world
- Distinguish between permanent facts, opinions, and status
- Track what information is already known vs new information 
- Build up the agent's understanding over time through embeddings and memory storage

Facts are stored with the following structure:

```typescript
interface Fact {
    claim: string;      // The actual information extracted
    type: "fact" | "opinion" | "status";  // Classification of the information
    in_bio: boolean;    // Whether this info is already in the agent's knowledge
    already_known: boolean;  // Whether this was previously extracted
}
```

#### Example Facts

Here's an example of extracted facts from a conversation:

```
User: I finally finished my marathon training program!
Agent: That's a huge accomplishment! How do you feel about it?
User: I'm really proud of what I achieved. It was tough but worth it.
Agent: What's next for you?
User: I'm actually training for a triathlon now. It's a whole new challenge.
```

```typescript
const extractedFacts = [
    {
        "claim": "User completed marathon training",
        "type": "fact",          // Permanent info / achievement
        "in_bio": false,
        "already_known": false   // Prevents duplicate storage
    },
    {
        "claim": "User feels proud of their achievement",
        "type": "opinion",       // Subjective views or feelings
        "in_bio": false,
        "already_known": false
    },
    {
        "claim": "User is currently training for a triathlon",
        "type": "status",        // Ongoing activity, changeable
        "in_bio": false,
        "already_known": false
    }
];
```


<details>
<summary>View Full Fact Evaluator Implementation</summary>

```typescript
import { composeContext } from "@elizaos/core";
import { generateObjectArray } from "@elizaos/core";
import { MemoryManager } from "@elizaos/core";
import {
    type ActionExample,
    type IAgentRuntime,
    type Memory,
    ModelClass,
    type Evaluator,
} from "@elizaos/core";

export const formatFacts = (facts: Memory[]) => {
    const messageStrings = facts
        .reverse()
        .map((fact: Memory) => fact.content.text);
    const finalMessageStrings = messageStrings.join("\n");
    return finalMessageStrings;
};

const factsTemplate =
    // {{actors}}
    `TASK: Extract Claims from the conversation as an array of claims in JSON format.

# START OF EXAMPLES
These are examples of the expected output of this task:
{{evaluationExamples}}
# END OF EXAMPLES

# INSTRUCTIONS

Extract any claims from the conversation that are not already present in the list of known facts above:
- Try not to include already-known facts. If you think a fact is already known, but you're not sure, respond with already_known: true.
- If the fact is already in the user's description, set in_bio to true
- If we've already extracted this fact, set already_known to true
- Set the claim type to 'status', 'fact' or 'opinion'
- For true facts about the world or the character that do not change, set the claim type to 'fact'
- For facts that are true but change over time, set the claim type to 'status'
- For non-facts, set the type to 'opinion'
- 'opinion' includes non-factual opinions and also includes the character's thoughts, feelings, judgments or recommendations
- Include any factual detail, including where the user lives, works, or goes to school, what they do for a living, their hobbies, and any other relevant information

Recent Messages:
{{recentMessages}}

Response should be a JSON object array inside a JSON markdown block. Correct response format:
\`\`\`json
[
  {"claim": string, "type": enum<fact|opinion|status>, in_bio: boolean, already_known: boolean },
  {"claim": string, "type": enum<fact|opinion|status>, in_bio: boolean, already_known: boolean },
  ...
]
\`\`\``;

async function handler(runtime: IAgentRuntime, message: Memory) {
    const state = await runtime.composeState(message);

    const { agentId, roomId } = state;

    const context = composeContext({
        state,
        template: runtime.character.templates?.factsTemplate || factsTemplate,
    });

    const facts = await generateObjectArray({
        runtime,
        context,
        modelClass: ModelClass.LARGE,
    });

    const factsManager = new MemoryManager({
        runtime,
        tableName: "facts",
    });

    if (!facts) {
        return [];
    }

    // If the fact is known or corrupted, remove it
    const filteredFacts = facts
        .filter((fact) => {
            return (
                !fact.already_known &&
                fact.type === "fact" &&
                !fact.in_bio &&
                fact.claim &&
                fact.claim.trim() !== ""
            );
        })
        .map((fact) => fact.claim);

    for (const fact of filteredFacts) {
        const factMemory = await factsManager.addEmbeddingToMemory({
            userId: agentId!,
            agentId,
            content: { text: fact },
            roomId,
            createdAt: Date.now(),
        });

        await factsManager.createMemory(factMemory, true);

        await new Promise((resolve) => setTimeout(resolve, 250));
    }
    return filteredFacts;
}

export const factEvaluator: Evaluator = {
    name: "GET_FACTS",
    similes: [
        "GET_CLAIMS",
        "EXTRACT_CLAIMS",
        "EXTRACT_FACTS",
        "EXTRACT_CLAIM",
        "EXTRACT_INFORMATION",
    ],
    validate: async (
        runtime: IAgentRuntime,

        message: Memory
    ): Promise<boolean> => {
        const messageCount = (await runtime.messageManager.countMemories(
            message.roomId
        )) as number;

        const reflectionCount = Math.ceil(runtime.getConversationLength() / 2);

        return messageCount % reflectionCount === 0;
    },
    description:
        "Extract factual information about the people in the conversation, the current events in the world, and anything else that might be important to remember.",
    handler,
    examples: [
        {
            context: `Actors in the scene:
{{user1}}: Programmer and moderator of the local story club.
{{user2}}: New member of the club. Likes to write and read.

Facts about the actors:
None`,
            messages: [
                {
                    user: "{{user1}}",
                    content: { text: "So where are you from" },
                },
                {
                    user: "{{user2}}",
                    content: { text: "I'm from the city" },
                },
                {
                    user: "{{user1}}",
                    content: { text: "Which city?" },
                },
                {
                    user: "{{user2}}",
                    content: { text: "Oakland" },
                },
                {
                    user: "{{user1}}",
                    content: {
                        text: "Oh, I've never been there, but I know it's in California",
                    },
                },
            ] as ActionExample[],
            outcome: `{ "claim": "{{user2}} is from Oakland", "type": "fact", "in_bio": false, "already_known": false },`,
        },
        {
            context: `Actors in the scene:
{{user1}}: Athelete and cyclist. Worked out every day for a year to prepare for a marathon.
{{user2}}: Likes to go to the beach and shop.

Facts about the actors:
{{user1}} and {{user2}} are talking about the marathon
{{user1}} and {{user2}} have just started dating`,
            messages: [
                {
                    user: "{{user1}}",
                    content: {
                        text: "I finally completed the marathon this year!",
                    },
                },
                {
                    user: "{{user2}}",
                    content: { text: "Wow! How long did it take?" },
                },
                {
                    user: "{{user1}}",
                    content: { text: "A little over three hours." },
                },
                {
                    user: "{{user1}}",
                    content: { text: "I'm so proud of myself." },
                },
            ] as ActionExample[],
            outcome: `Claims:
json\`\`\`
[
  { "claim": "Alex just completed a marathon in just under 4 hours.", "type": "fact", "in_bio": false, "already_known": false },
  { "claim": "Alex worked out 2 hours a day at the gym for a year.", "type": "fact", "in_bio": true, "already_known": false },
  { "claim": "Alex is really proud of himself.", "type": "opinion", "in_bio": false, "already_known": false }
]
\`\`\`
`,
        },
        {
            context: `Actors in the scene:
{{user1}}: Likes to play poker and go to the park. Friends with Eva.
{{user2}}: Also likes to play poker. Likes to write and read.

Facts about the actors:
Mike and Eva won a regional poker tournament about six months ago
Mike is married to Alex
Eva studied Philosophy before switching to Computer Science`,
            messages: [
                {
                    user: "{{user1}}",
                    content: {
                        text: "Remember when we won the regional poker tournament last spring",
                    },
                },
                {
                    user: "{{user2}}",
                    content: {
                        text: "That was one of the best days of my life",
                    },
                },
                {
                    user: "{{user1}}",
                    content: {
                        text: "It really put our poker club on the map",
                    },
                },
            ] as ActionExample[],
            outcome: `Claims:
json\`\`\`
[
  { "claim": "Mike and Eva won the regional poker tournament last spring", "type": "fact", "in_bio": false, "already_known": true },
  { "claim": "Winning the regional poker tournament put the poker club on the map", "type": "opinion", "in_bio": false, "already_known": false }
]
\`\`\``,
        },
    ],
};
```

</details>
Source: https://github.com/elizaOS/eliza/blob/main/packages/plugin-bootstrap/src/evaluators/fact.ts

## Goal Evaluator

The Goal Evaluator tracks progress on conversation objectives by analyzing messages and updating goal status. Goals are structured like this:

```typescript
interface Goal {
    id: string;
    name: string;
    status: "IN_PROGRESS" | "DONE" | "FAILED";
    objectives: Objective[];
}
```

#### Example Goals

Here's how the goal evaluator processes a conversation:

```typescript
// Initial goal state
const goal = {
    id: "book-club-123",
    name: "Complete reading assignment",
    status: "IN_PROGRESS",
    objectives: [
        { description: "Read chapters 1-3", completed: false },
        { description: "Take chapter notes", completed: false },
        { description: "Share thoughts in book club", completed: false }
    ]
};

// Conversation happens
const conversation = `
User: I finished reading the first three chapters last night
Agent: Great! Did you take any notes while reading?
User: Yes, I made detailed notes about the main characters
Agent: Perfect, we can discuss those in the club meeting
User: I'm looking forward to sharing my thoughts tomorrow
`;

// Goal evaluator updates the goal status
const updatedGoal = {
    id: "book-club-123", 
    name: "Complete reading assignment",
    status: "IN_PROGRESS",                                    // Still in progress
    objectives: [
        { description: "Read chapters 1-3", completed: true }, // Marked complete
        { description: "Take chapter notes", completed: true }, // Marked complete
        { description: "Share thoughts in book club", completed: false } // Still pending
    ]
};

// After the book club meeting, goal would be marked DONE
// If user can't complete objectives, goal could be marked FAILED
```

<details>
<summary>View Full Goal Evaluator Implementation</summary>
```typescript
import { composeContext } from "@elizaos/core";
import { generateText } from "@elizaos/core";
import { getGoals } from "@elizaos/core";
import { parseJsonArrayFromText } from "@elizaos/core";
import {
    type IAgentRuntime,
    type Memory,
    ModelClass,
    type Objective,
    type Goal,
    type State,
    type Evaluator,
} from "@elizaos/core";

const goalsTemplate = `TASK: Update Goal
Analyze the conversation and update the status of the goals based on the new information provided.

# INSTRUCTIONS

- Review the conversation and identify any progress towards the objectives of the current goals.
- Update the objectives if they have been completed or if there is new information about them.
- Update the status of the goal to 'DONE' if all objectives are completed.
- If no progress is made, do not change the status of the goal.

# START OF ACTUAL TASK INFORMATION

{{goals}}
{{recentMessages}}

TASK: Analyze the conversation and update the status of the goals based on the new information provided. Respond with a JSON array of goals to update.
- Each item must include the goal ID, as well as the fields in the goal to update.
- For updating objectives, include the entire objectives array including unchanged fields.
- Only include goals which need to be updated.
- Goal status options are 'IN_PROGRESS', 'DONE' and 'FAILED'. If the goal is active it should always be 'IN_PROGRESS'.
- If the goal has been successfully completed, set status to DONE. If the goal cannot be completed, set status to FAILED.
- If those goal is still in progress, do not include the status field.

Response format should be:
\`\`\`json
[
  {
    "id": <goal uuid>, // required
    "status": "IN_PROGRESS" | "DONE" | "FAILED", // optional
    "objectives": [ // optional
      { "description": "Objective description", "completed": true | false },
      { "description": "Objective description", "completed": true | false }
    ] // NOTE: If updating objectives, include the entire objectives array including unchanged fields.
  }
]
\`\`\``;

async function handler(
    runtime: IAgentRuntime,
    message: Memory,
    state: State | undefined,
    options: { [key: string]: unknown } = { onlyInProgress: true }
): Promise<Goal[]> {
    state = (await runtime.composeState(message)) as State;
    const context = composeContext({
        state,
        template: runtime.character.templates?.goalsTemplate || goalsTemplate,
    });

    // Request generateText from OpenAI to analyze conversation and suggest goal updates
    const response = await generateText({
        runtime,
        context,
        modelClass: ModelClass.LARGE,
    });

    // Parse the JSON response to extract goal updates
    const updates = parseJsonArrayFromText(response);

    // get goals
    const goalsData = await getGoals({
        runtime,
        roomId: message.roomId,
        onlyInProgress: options.onlyInProgress as boolean,
    });

    // Apply the updates to the goals
    const updatedGoals = goalsData
        .map((goal: Goal): Goal => {
            const update = updates?.find((u) => u.id === goal.id);
            if (update) {
                // Merge the update into the existing goal
                return {
                    ...goal,
                    ...update,
                    objectives: goal.objectives.map((objective) => {
                        const updatedObjective = update.objectives?.find(uo => uo.description === objective.description);
                        return updatedObjective ? { ...objective, ...updatedObjective } : objective;
                    }),
                };
            }
            return null; // No update for this goal
        })
        .filter(Boolean);

    // Update goals in the database
    for (const goal of updatedGoals) {
        const id = goal.id;
        // delete id from goal
        if (goal.id) delete goal.id;
        await runtime.databaseAdapter.updateGoal({ ...goal, id });
    }

    return updatedGoals; // Return updated goals for further processing or logging
}

export const goalEvaluator: Evaluator = {
    name: "UPDATE_GOAL",
    similes: [
        "UPDATE_GOALS",
        "EDIT_GOAL",
        "UPDATE_GOAL_STATUS",
        "UPDATE_OBJECTIVES",
    ],
    validate: async (
        runtime: IAgentRuntime,
        message: Memory
    ): Promise<boolean> => {
        // Check if there are active goals that could potentially be updated
        const goals = await getGoals({
            runtime,
            count: 1,
            onlyInProgress: true,
            roomId: message.roomId,
        });
        return goals.length > 0;
    },
    description:
        "Analyze the conversation and update the status of the goals based on the new information provided.",
    handler,
    examples: [
        {
            context: `Actors in the scene:
  {{user1}}: An avid reader and member of a book club.
  {{user2}}: The organizer of the book club.

  Goals:
  - Name: Finish reading "War and Peace"
    id: 12345-67890-12345-67890
    Status: IN_PROGRESS
    Objectives:
      - Read up to chapter 20 by the end of the month
      - Discuss the first part in the next meeting`,

            messages: [
                {
                    user: "{{user1}}",
                    content: {
                        text: "I've just finished chapter 20 of 'War and Peace'",
                    },
                },
                {
                    user: "{{user2}}",
                    content: {
                        text: "Were you able to grasp the complexities of the characters",
                    },
                },
                {
                    user: "{{user1}}",
                    content: {
                        text: "Yep. I've prepared some notes for our discussion",
                    },
                },
            ],

            outcome: `[
        {
          "id": "12345-67890-12345-67890",
          "status": "DONE",
          "objectives": [
            { "description": "Read up to chapter 20 by the end of the month", "completed": true },
            { "description": "Prepare notes for the next discussion", "completed": true }
          ]
        }
      ]`,
        },

        {
            context: `Actors in the scene:
  {{user1}}: A fitness enthusiast working towards a marathon.
  {{user2}}: A personal trainer.

  Goals:
  - Name: Complete a marathon
    id: 23456-78901-23456-78901
    Status: IN_PROGRESS
    Objectives:
      - Increase running distance to 30 miles a week
      - Complete a half-marathon as practice`,

            messages: [
                {
                    user: "{{user1}}",
                    content: { text: "I managed to run 30 miles this week" },
                },
                {
                    user: "{{user2}}",
                    content: {
                        text: "Impressive progress! How do you feel about the half-marathon next month?",
                    },
                },
                {
                    user: "{{user1}}",
                    content: {
                        text: "I feel confident. The training is paying off.",
                    },
                },
            ],

            outcome: `[
        {
          "id": "23456-78901-23456-78901",
          "objectives": [
            { "description": "Increase running distance to 30 miles a week", "completed": true },
            { "description": "Complete a half-marathon as practice", "completed": false }
          ]
        }
      ]`,
        },

        {
            context: `Actors in the scene:
  {{user1}}: A student working on a final year project.
  {{user2}}: The project supervisor.

  Goals:
  - Name: Finish the final year project
    id: 34567-89012-34567-89012
    Status: IN_PROGRESS
    Objectives:
      - Submit the first draft of the thesis
      - Complete the project prototype`,

            messages: [
                {
                    user: "{{user1}}",
                    content: {
                        text: "I've submitted the first draft of my thesis.",
                    },
                },
                {
                    user: "{{user2}}",
                    content: {
                        text: "Well done. How is the prototype coming along?",
                    },
                },
                {
                    user: "{{user1}}",
                    content: {
                        text: "It's almost done. I just need to finalize the testing phase.",
                    },
                },
            ],

            outcome: `[
        {
          "id": "34567-89012-34567-89012",
          "objectives": [
            { "description": "Submit the first draft of the thesis", "completed": true },
            { "description": "Complete the project prototype", "completed": false }
          ]
        }
      ]`,
        },

        {
            context: `Actors in the scene:
        {{user1}}: A project manager working on a software development project.
        {{user2}}: A software developer in the project team.

        Goals:
        - Name: Launch the new software version
          id: 45678-90123-45678-90123
          Status: IN_PROGRESS
          Objectives:
            - Complete the coding for the new features
            - Perform comprehensive testing of the software`,

            messages: [
                {
                    user: "{{user1}}",
                    content: {
                        text: "How's the progress on the new features?",
                    },
                },
                {
                    user: "{{user2}}",
                    content: {
                        text: "We've encountered some unexpected challenges and are currently troubleshooting.",
                    },
                },
                {
                    user: "{{user1}}",
                    content: {
                        text: "Let's move on and cancel the task.",
                    },
                },
            ],

            outcome: `[
        {
          "id": "45678-90123-45678-90123",
          "status": "FAILED"
      ]`,
        },
    ],
};
```
</details>

Source: https://github.com/elizaOS/eliza/blob/main/packages/plugin-bootstrap/src/evaluators/goals.ts

---

## FAQ

### How do evaluators differ from providers?
While [providers](/api/interfaces/Provider) supply data to the agent before responses, evaluators analyze conversations after responses. Providers inform decisions, evaluators learn from outcomes.

### Can evaluators modify agent behavior?
Evaluators can influence future behavior by storing insights in memory, but cannot directly modify agent responses or interrupt ongoing actions.

### How many evaluators can run simultaneously?
There's no hard limit, but each evaluator adds processing overhead. Focus on essential evaluations and use efficient validation to optimize performance.

### Can evaluators communicate with each other?
Evaluators don't directly communicate but can share data through the memory system. One evaluator can read insights stored by another.

### How are evaluation results persisted?
Results are stored using the runtime's memory managers with embeddings for efficient retrieval. See the [`IMemoryManager`](/api/interfaces/IMemoryManager) interface for details.

### What's the difference between similes and examples in evaluators?
Similes provide alternative descriptions of the evaluator's purpose, while examples show concrete scenarios with inputs and expected outcomes. Examples help verify correct implementation.

### Can evaluators be conditionally enabled?
Yes, use the validation function to control when evaluators run. This can be based on message content, user status, or other runtime conditions.
````

## File: packages/docs/docs/core/knowledge.md
````markdown
# RAG Knowledge Documentation

## Overview

The RAG (Retrieval-Augmented Generation) Knowledge feature is a powerful system that enables agents to process, store, and retrieve information from various document types (PDF, Markdown, and text files). This feature enhances the agent's ability to provide contextually relevant responses by leveraging stored knowledge during conversations.

## Directory Structure

```
characters/
└── knowledge/        # Root knowledge directory
    ├── shared/       # Shared knowledge accessible to all agents
    └── {agent-name}/ # Agent-specific knowledge directories
```

## Supported File Types

- PDF files (`.pdf`)
- Markdown files (`.md`)
- Text files (`.txt`)

## Setting Up RAG Knowledge

### 1. Directory Setup

1. Create a `characters/knowledge` directory in your project root if it doesn't exist
2. Create subdirectories for:
   - `shared/`: Documents accessible to all agents
   - `{agent-name}/`: Agent-specific documents (replace `{agent-name}` with your agent's name)

### 2. Configuration

Update your agent's character configuration file with the appropriate knowledge entries:

```json
{
    "knowledge": [
        {
            "directory": "characters/knowledge/shared",
            "shared": true
        },
        {
            "directory": "characters/knowledge/{agent-name}",
            "shared": false
        },
        {
            "path": "characters/knowledge/{agent-name}/specific-file.pdf",
            "shared": false
        }
    ]
}
```

## How It Works

1. **Document Processing**:
   - When documents are added to the knowledge directories, they are automatically processed
   - Documents are split into manageable chunks for better retrieval
   - Each chunk is embedded using the configured embedding model
   - The embeddings and metadata are stored in the database for efficient retrieval

2. **Knowledge Retrieval**:
   - During conversations, relevant knowledge is retrieved based on semantic similarity
   - The system uses a default similarity threshold of 0.85
   - By default, it retrieves the top 5 most relevant matches
   - Both shared and agent-specific knowledge are searched

## Best Practices

1. **Document Organization**:
   - Keep files organized in appropriate directories
   - Use descriptive filenames
   - Break large documents into logical smaller files
   - Include metadata and context in markdown files

2. **Content Management**:
   - Regularly review and update knowledge files
   - Remove outdated or irrelevant documents
   - Ensure documents are in the correct format
   - Verify file permissions are set correctly

3. **Performance Optimization**:
   - Keep individual documents focused on specific topics
   - Break down large documents into smaller, focused chunks
   - Use appropriate file formats for the content type
   - Regular maintenance of the knowledge base

## Troubleshooting

### Common Issues and Solutions

1. **Documents Not Being Retrieved**:
   - Verify the file is in a supported format (PDF, MD, TXT)
   - Check if the file is in the correct directory under `characters/knowledge`
   - Ensure the configuration file correctly references the knowledge directory
   - Verify file permissions

2. **Poor Quality Retrievals**:
   - Break down large documents into smaller, focused files
   - Ensure document content is clear and well-structured
   - Review and clean up any formatting issues in the source documents
   - Check if the query contains too many common words (stop words like "a", "the", "is" are filtered out)

3. **Performance Issues**:
   - Check the size of individual documents
   - Verify the total size of the knowledge base
   - Consider cleaning up unused or redundant documents
   - Monitor embedding processing time for large documents

## Technical Implementation

### Document Processing Flow

The RAG system processes documents through several stages to optimize both storage and retrieval:

1. **Directory Processing**
   - The system scans configured directories in `characters/knowledge/`
   - Files are processed based on their shared/private status and file type

2. **File Processing Pipeline**
   
   a. **Preprocessing**
   - Read the file content
   - Clean and normalize text through preprocessing
   
   b. **Main Document Processing**
   - Generate embeddings for the entire document
   - Store the complete document with:
     - Full text content
     - Document-level embeddings
     - Metadata (file path, type, shared status)
   
   c. **Chunk Processing**
   - Split the preprocessed content into chunks
     - Default chunk size: 512 tokens
     - Overlap between chunks: 20 tokens
   - Process chunks in parallel batches of 10 for efficiency
   - For each chunk:
     - Generate embeddings
     - Store with metadata linking back to the original document
     - Include chunk-specific metadata (chunk index, original document ID)

This multi-level approach enables:
- Broad document-level semantic search
- Fine-grained chunk-level retrieval for specific information
- Efficient parallel processing of large documents
- Maintenance of document context through metadata linking

### Knowledge Processing Flow

The following diagram illustrates how the RAG system processes documents:

```mermaid
graph TB
    subgraph Directory_Processing
        A[Read Files from Directory] --> B[File Content]
    end

    subgraph Preprocessing
        B --> C[Clean & Normalize Text]
    end

    subgraph Document_Processing
        C --> D[Generate Document Embedding]
        D --> E[Store Full Document]
        E --> |Metadata| F[File Path]
        E --> |Metadata| G[File Type]
        E --> |Metadata| H[Shared Status]
    end

    subgraph Chunk_Processing
        C --> I[Split into Chunks]
        I --> |512 tokens| J[Chunk 1]
        I --> |20 token overlap| K[...]
        I --> L[Chunk N]
        
        subgraph Parallel_Processing
            J --> M1[Generate Embedding]
            K --> M2[Generate Embedding]
            L --> M3[Generate Embedding]
        end
        
        subgraph Chunk_Storage
            M1 --> N1[Store Chunk]
            M2 --> N2[Store Chunk]
            M3 --> N3[Store Chunk]
            
            N1 --> |Metadata| O[Original Doc Reference]
            N1 --> |Metadata| P[Chunk Index]
            N2 --> |Metadata| O
            N2 --> |Metadata| P
            N3 --> |Metadata| O
            N3 --> |Metadata| P
        end
    end

    style Directory_Processing fill:#f9f,stroke:#333,stroke-width:2px
    style Preprocessing fill:#bbf,stroke:#333,stroke-width:2px
    style Document_Processing fill:#bfb,stroke:#333,stroke-width:2px
    style Chunk_Processing fill:#fbf,stroke:#333,stroke-width:2px
    style Parallel_Processing fill:#fbb,stroke:#333,stroke-width:2px
    style Chunk_Storage fill:#bff,stroke:#333,stroke-width:2px
```

Key Features:
1. **Parallel Processing**: Chunks are processed in batches of 10 for optimal performance
2. **Dual Storage**: Both full documents and chunks are stored with embeddings
3. **Metadata Linking**: Chunks maintain references to their source documents
4. **Overlapping Chunks**: 20-token overlap ensures context preservation
5. **Configurable Size**: Default chunk size of 512 tokens balances detail and performance

### Processing Parameters

- Chunk Size: 512 tokens
- Chunk Overlap: 20 tokens
- Processing Batch Size: 10 chunks
- Default Similarity Threshold: 0.85
- Default Match Count: 5 results

## Knowledge ID Relationships

The RAG system uses a hierarchical ID structure to maintain relationships between documents and their fragments:

```mermaid
classDiagram
    class Document {
        +UUID id
        +String filePath
        +String fileType
        +Boolean isShared
        +Float32Array embedding
        +String content
    }
    
    class Fragment {
        +UUID id
        +UUID originalId
        +Number chunkIndex
        +String content
        +Float32Array embedding
        +String originalPath
    }

    Document "1" --> "*" Fragment : generates
```

#### ID Generation and Linking

1. **Document ID Generation**
   ```mermaid
   graph LR
       A[File Path] --> B[Hash Function]
       C[Is Shared?] --> B
       B --> D[Document UUID]
       style D fill:#f9f,stroke:#333,stroke-width:2px
   ```
   - Generated using `generateScopedId(path, isShared)`
   - Deterministic: same file path + shared status = same ID
   - Stored as `id` in the knowledge database

2. **Fragment ID Generation**
   ```mermaid
   graph LR
       A[Document UUID] --> B[Fragment ID]
       C[Chunk Index] --> B
       B --> D["fragmentId = `${documentId}-chunk-${index}`"]
       style D fill:#bbf,stroke:#333,stroke-width:2px
   ```
   - Based on parent document's UUID and chunk index
   - Format: `${documentId}-chunk-${index}`
   - Ensures unique identification while maintaining lineage

#### Metadata Structure

```mermaid
graph TB
    subgraph Document_Metadata
        A[Document] --> B[id: UUID]
        A --> C[agentId: UUID]
        A --> D[content: Object]
        D --> E[text: String]
        D --> F[metadata: Object]
        F --> G[source: String]
        F --> H[type: String]
        F --> I[isShared: Boolean]
    end

    subgraph Fragment_Metadata
        J[Fragment] --> K[id: UUID]
        J --> L[agentId: UUID]
        J --> M[content: Object]
        M --> N[text: String]
        M --> O[metadata: Object]
        O --> P[originalId: UUID]
        O --> Q[chunkIndex: Number]
        O --> R[originalPath: String]
        O --> S[isChunk: true]
    end

    A -.-> J
```

#### Key Points

1. **Document IDs**
   - Unique per file path and shared status
   - Used as reference point for all fragments
   - Stored in main knowledge table

2. **Fragment IDs**
   - Always linked to parent document
   - Include chunk index for ordering
   - Maintain complete lineage to source

3. **Querying Relationships**
   - Find all fragments: `SELECT * FROM knowledge WHERE originalId = {documentId}`
   - Get source document: `SELECT * FROM knowledge WHERE id = {fragment.originalId}`
   - List chunks in order: Sort by `chunkIndex`

4. **Metadata Preservation**
   - Documents store file-level metadata
   - Fragments maintain references to source
   - Both contain embeddings for search

This ID system enables:
- Efficient document-fragment relationship tracking
- Quick retrieval of related content
- Maintenance of document hierarchy
- Proper context preservation in search results

## API Reference

### Key Classes and Methods

#### RAGKnowledgeManager

The main class responsible for managing RAG knowledge. Here are the key methods:

##### `createKnowledge(item: RAGKnowledgeItem): Promise<void>`
Adds new knowledge to the database.
- Parameters:
  - `item`: A RAGKnowledgeItem containing:
    - `id`: UUID
    - `agentId`: UUID
    - `content`:
      - `text`: string
      - `metadata`: 
        - `source`: string
        - `type`: "pdf" | "md" | "txt"
        - `isShared`: boolean
    - `embedding`: Float32Array
    - `createdAt`: number

##### `getKnowledge(params): Promise<RAGKnowledgeItem[]>`
Retrieves knowledge based on query or ID.
- Parameters:
  - `query?`: string - Optional search query
  - `id?`: UUID - Optional specific knowledge ID
  - `conversationContext?`: string - Optional conversation context
  - `limit?`: number - Optional result limit
  - `agentId?`: UUID - Optional agent ID filter
- Returns: Array of matching RAGKnowledgeItem objects

##### `searchKnowledge(params): Promise<RAGKnowledgeItem[]>`
Performs semantic search with configurable parameters.
- Parameters:
  - `agentId`: UUID - Agent ID to search within
  - `embedding`: Float32Array | number[] - Vector to search against
  - `match_threshold?`: number - Similarity threshold (default: 0.85)
  - `match_count?`: number - Number of results (default: 5)
  - `searchText?`: string - Optional text to search for
- Returns: Array of matching RAGKnowledgeItem objects

##### `clearKnowledge(shared?: boolean): Promise<void>`
Clears knowledge entries.
- Parameters:
  - `shared?`: boolean - If true, clears shared knowledge as well
- Returns: Promise that resolves when operation completes

##### `processFile(file): Promise<void>`
Processes a new knowledge file.
- Parameters:
  - `file`:
    - `path`: string - File path
    - `content`: string - File contents
    - `type`: "pdf" | "md" | "txt" - File type
    - `isShared?`: boolean - Whether the knowledge is shared
- Returns: Promise that resolves when processing completes

##### `listAllKnowledge(agentId: UUID): Promise<RAGKnowledgeItem[]>`
Lists all knowledge entries for an agent without semantic search.
- Parameters:
  - `agentId`: UUID - Agent ID to list knowledge for
- Returns: Array of all RAGKnowledgeItem entries for the agent

##### `removeKnowledge(id: UUID): Promise<void>`
Removes a specific knowledge entry.
- Parameters:
  - `id`: UUID - ID of the knowledge to remove
- Returns: Promise that resolves when deletion completes

## Security Considerations

1. **Access Control**:
   - Use the `shared` flag appropriately to control document access
   - Keep sensitive information in agent-specific directories
   - Regularly audit knowledge access patterns

2. **Data Privacy**:
   - Do not store sensitive personal information in knowledge files
   - Review documents for potentially sensitive content before adding
   - Implement appropriate backup and recovery procedures

## Future Considerations

1. **Scalability**:
   - Monitor knowledge base size and performance
   - Plan for regular maintenance and cleanup
   - Consider implementing document versioning

2. **Integration**:
   - Document integration points with other systems
   - Plan for potential future file format support
   - Consider implementing knowledge base analytics

## Support and Resources

- Review the implementation in `packages/core/src/ragknowledge.ts`
- Check the issue tracker for known issues and solutions
- Contribute improvements and bug fixes through pull requests
````

## File: packages/docs/docs/core/overview.md
````markdown
---
sidebar_position: 1
---

# Overview


Eliza is a framework for creating AI agents that can interact across multiple platforms.

 **Features**
- **Modular Design**: Plugins and services allow for flexible customization.
- **Knowledge**: Supports both RAG-based and direct knowledge processing.
- **Stateful Interactions**: Maintains context across conversations.
- **Multi-Agent Support**: Supports running multiple agents with distinct configurations.
- **Multi-Platform Support**: Integrates with various clients (e.g., Discord, Telegram).

Eliza consists of these core components:
- **Agents (Runtime)**: AI personalities that interact with users and platforms
- **Actions**: Executable behaviors that agents can perform in response to messages
- **Clients**: Platform connectors for services like Discord, Twitter, and Telegram 
- **Plugins**: Modular extensions that add new features and capabilities
- **Providers**: Services that supply contextual information to agents
- **Evaluators**: Modules that analyze conversations and track agent goals
- **Character Files**: JSON configurations that define agent personalities
- **Memory System**: Database that stores and manages agent information using vector embeddings

Here's an overview of how eliza works from user input to response generation:
![](/img/overview.png)
Source: https://x.com/gelatonetwork/status/1894408632915169618


---

## [Agent Runtime](./agents.md)

**The Brain**

The Runtime (`src/runtime.ts`) acts as the control tower for your AI agents. Think of it as a conductor leading an orchestra - it ensures all parts work together harmoniously. It serves as the central coordination layer for message processing, memory management, state composition, action execution, and integration with AI models and external services.

- **Core Functions**: 
  - Coordinates message processing
  - Manages the agent's lifecycle
  - Handles integration with AI models
  - Orchestrates plugins and services

## [Character Files](./characterfile.md)

**The Personality**

[Character Files](./characterfile.md) (`src/types.ts`) define agent **personalities** and **capabilities** including biographical information, interaction styles, plugin configurations, and platform integrations.

The character file defines who your agent is - like a script for an actor. It includes:

- Biographical information and backstory
- Topics the agent can discuss
- Writing style and tone
- Which AI models to use
- Which plugins to load
- Which platforms to connect to


## [Clients](./clients.md)

**The Interface**

Clients connect your agent to different platforms (Discord, Twitter, Slack, Farcaster, etc.) while maintaining consistent behavior across all interfaces. Each client can handle different types of interactions:
- Chat messages
- Social media posts
- Voice conversations
- Platform-specific features


## [Actions](./actions.md)

**What Agents Can Do**

Actions (`src/actions.ts`) are like tools in a toolbox. They define how agents respond and interact with messages, enabling custom behaviors, external system interactions, media processing, and platform-specific features.

## [Evaluators](./evaluators.md)

**Quality Control**

Evaluators (`src/evaluators.ts`) act like referees, making sure the agent follows rules and guidelines. They monitor conversations and help improve agent responses over time by assessing conversations and maintaining agent knowledge through fact extraction, goal tracking, memory building, and relationship management.

## [Providers](./providers.ts)

**Information Flow**

Providers (`src/providers.ts`) are the agent's eyes and ears, like a newsroom keeping them informed about the world. They supply real-time information to agents by integrating external APIs, managing temporal awareness, and providing system status updates to help agents make better decisions.


## Memory & Knowledge Systems

The framework implements specialized memory systems through:

### Memory Manager

The Memory Manager (`src/memory.ts`) acts like a personal diary and helps agents remember:
- Recent conversations
- Important facts
- User interactions
- Immediate context for current discussions

### Knowledge Systems
Think of this as the agent's library (`src/knowledge.ts`, `src/ragknowledge.ts`), where information is:
- Organized into searchable chunks
- Converted into vector embeddings
- Retrieved based on relevance
- Used to enhance responses

## Data Management
The data layer provides robust storage and caching through:

### Database System

The database (`src/database.ts`) acts as a filing cabinet, storing:
- Conversation histories
- User interactions
- Transaction management
- Vector storage
- Relationship tracking
- Embedded knowledge
- Agent state

See also: [Memory Management](../guides/memory-management.md)

## Cache System

**Performance Optimization**

The Cache System (`src/cache.ts`) creates shortcuts for frequently accessed information, making agents respond faster and more efficiently.


## System Flow

When someone interacts with your agent, the Client receives the message and forwards it to the Runtime which processes it with the characterfile configuration. The Runtime loads relevant memories and knowledge, uses actions and evaluators to determine how to response, gets additional context through providers. Then the Runtime generates a response using the AI model, stores new memories, and sends the response back through the client.


---

## Common Patterns

### Memory Usage (`src/memory.ts`)
```typescript
// Store conversation data
await messageManager.createMemory({
    id: messageId,
    content: { text: "Message content" },
    userId: userId,
    roomId: roomId
});

// Retrieve context
const recentMessages = await messageManager.getMemories({
    roomId: roomId,
    count: 10
});
```

### Action Implementation (`src/actions.ts`)
```typescript
const customAction: Action = {
    name: "CUSTOM_ACTION",
    similes: ["ALTERNATE_NAME"],
    description: "Action description",
    validate: async (runtime, message) => {
        // Validation logic
        return true;
    },
    handler: async (runtime, message) => {
        // Implementation logic
        return true;
    }
};
```

### Provider Integration (`src/providers.ts`)
```typescript
const dataProvider: Provider = {
    get: async (runtime: IAgentRuntime, message: Memory) => {
        // Fetch and format data
        return "Formatted context string";
    }
};
```

---

## FAQ

### What's the difference between Actions, Evaluators, and Providers?

Actions define what an agent can do, Evaluators analyze what happened, and Providers supply information to help make decisions.

### Can I use multiple AI models with one agent?

Yes, agents can be configured to use different models for different tasks (chat, image generation, embeddings) through the modelProvider settings.

### How does memory persistence work?

Memory is stored through database adapters which can use SQLite, PostgreSQL, or other backends, with each type (messages, facts, knowledge) managed separately.

### What's the difference between Lore and Knowledge?

Lore defines the character's background and history, while Knowledge represents factual information the agent can reference and use.

### How do I add custom functionality?

Create plugins that implement the Action, Provider, or Evaluator interfaces and register them with the runtime.

### Do I need to implement all components?

No, each component is optional. Start with basic Actions and add Evaluators and Providers as needed.

### How does RAG integration work?

Documents are chunked, embedded, and stored in the knowledge base for semantic search during conversations via the RAGKnowledgeManager.

### What's the recommended database for production?

PostgreSQL with vector extensions is recommended for production, though SQLite works well for development and testing.
````

## File: packages/docs/docs/core/plugins.md
````markdown
# Plugins

Plugins (or packages) are modular extensions that enhance the capabilities of ElizaOS agents. They provide a flexible way to add new functionality, integrate external services, and customize agent behavior across different platforms.

**Browse the various plugins the eliza dev community made here: [Package Showcase](/showcase)**

[![](/img/plugins.png)](/showcase)
> elizaOS maintains an official package registry at [github.com/elizaos-plugins/registry](https://github.com/elizaos-plugins/registry).

---


### Installation

Eliza now supports dynamic plugin loading directly from the package registry. Here's a couple ways you can add plugins on eliza:

1. Add the plugin to your project's dependencies (`package.json`):

```json
{
  "dependencies": {
    "@elizaos/plugin-solana": "github:elizaos-plugins/plugin-solana",
    "@elizaos/plugin-twitter": "github:elizaos-plugins/plugin-twitter"
  }
}
```

2. Configure the plugin in your character file:

```typescript
{
  "name": "MyAgent",
  "plugins": [
    "@elizaos/plugin-twitter",
    "@elizaos/plugin-example"
  ],
  "settings": {
    "example-plugin": {
      // Plugin-specific configuration
    }
  }
}
```

3. Use the new CLI tool:

You can list available plugins, install new ones, and remove them when needed.  

Go into the eliza directory you cloned and type `npx elizaos plugins` to use it.

```bash
Usage: elizaos plugins [options] [command]

manage elizaOS plugins

Options:
  -h, --help              display help for command

Commands:
  list|l [options]        list available plugins
  add|install <plugin>    add a plugin
  remove|delete <plugin>  remove a plugin
  help [command]          display help for command
```

---

## Architecture

Eliza uses a unified plugin architecture where everything is a plugin - including clients, adapters, actions, evaluators, and services. This approach ensures consistent behavior and better extensibility. Here's how the architecture works:

1. **Plugin Types**: Each plugin can provide one or more of the following:
   - Clients (e.g., Discord, Twitter, WhatsApp integrations)
   - Adapters (e.g., database adapters, caching systems)
   - Actions (custom behavior and responses functionality)
   - Evaluators (analysis, learning, decision-making components)
   - Services (background processes and integrations)
   - Providers (data or functionality providers)

2. **Plugin Interface**: All plugins implement the core Plugin interface:
   ```typescript
   type Plugin = {
       name: string;
       description: string;
       config?: { [key: string]: any };
       actions?: Action[];
       providers?: Provider[];
       evaluators?: Evaluator[];
       services?: Service[];
       clients?: Client[];
       adapters?: Adapter[];
   };
   ```

3. **Independent Repositories**: Each plugin lives in its own repository under the [elizaos-plugins](https://github.com/elizaos-plugins/) organization, allowing:
   - Independent versioning and releases
   - Focused issue tracking and documentation
   - Easier maintenance and contribution
   - Separate CI/CD pipelines

4. **Plugin Structure**: Each plugin repository should follow this structure:
   ```
   plugin-name/
   ├── images/
   │   ├── logo.jpg        # Plugin branding logo
   │   ├── banner.jpg      # Plugin banner image
   ├── src/
   │   ├── index.ts        # Main plugin entry point
   │   ├── actions/        # Plugin-specific actions
   │   ├── clients/        # Client implementations
   │   ├── adapters/       # Adapter implementations
   │   └── types.ts        # Type definitions
   │   └── environment.ts  # runtime.getSetting, zod validation
   ├── package.json        # Plugin dependencies
   └── README.md          # Plugin documentation
   ```

5. **Package Configuration**: Your plugin's `package.json` must include an `agentConfig` section:
   ```json
   {
     "name": "@elizaos/plugin-example",
     "version": "1.0.0",
     "agentConfig": {
       "pluginType": "elizaos:plugin:1.0.0",
       "pluginParameters": {
         "API_KEY": {
           "type": "string",
           "description": "API key for the service"
         }
       }
     }
   }
   ```

6. **Plugin Loading**: Plugins are dynamically loaded at runtime through the `handlePluginImporting` function, which:
   - Imports the plugin module
   - Reads the plugin configuration
   - Validates plugin parameters
   - Registers the plugin's components (clients, adapters, actions, etc.)

7. **Client and Adapter Implementation**: When implementing clients or adapters:

```typescript
   // Client example
   const discordPlugin: Plugin = {
     name: "discord",
     description: "Discord client plugin",
     clients: [DiscordClientInterface]
   };

   // Adapter example
   const postgresPlugin: Plugin = {
     name: "postgres",
     description: "PostgreSQL database adapter",
     adapters: [PostgresDatabaseAdapter]
   };
   
   // Adapter example
   export const browserPlugin = {
    name: "default",
    description: "Pdf",
    services: [PdfService],
    actions: [],
  };
```

### Environment Variables and Secrets

Plugins can access environment variables and secrets in two ways:

1. **Character Configuration**: Through `agent.json.secret` or character settings:
   ```json
   {
     "name": "MyAgent",
     "settings": {
       "secrets": {
         "PLUGIN_API_KEY": "your-api-key",
         "PLUGIN_SECRET": "your-secret"
       }
     }
   }
   ```

2. **Runtime Access**: Plugins can access their configuration through the runtime:
   ```typescript
   class MyPlugin implements Plugin {
     async initialize(runtime: AgentRuntime) {
       const apiKey = runtime.getSetting("PLUGIN_API_KEY");
       const secret = runtime.getSetting("PLUGIN_SECRET");
     }
   }
   ```

The `getSetting` method follows this precedence:
1. Character settings secrets
2. Character settings
3. Global settings

---

### Pull Request Requirements

When submitting a plugin to the [elizaOS Registry](https://github.com/elizaos-plugins/registry), your PR must include:

1. **Working Demo Evidence:**
   - Screenshots or video demonstrations of the plugin working with ElizaOS
   - Test results showing successful integration
   - Example agent configuration using your plugin
   - Documentation of any specific setup requirements

2. **Integration Testing:**
   - Proof of successful dynamic loading with ElizaOS
   - Test cases covering main functionality
   - Error handling demonstrations
   - Performance metrics (if applicable)

3. **Configuration Examples:**
   ```json
   {
     "name": "MyAgent",
     "plugins": ["@elizaos/your-plugin"],
     "settings": {
       "your-plugin": {
         // Your plugin's configuration
       }
     }
   }
   ```

4. **Quality Checklist:**
   - [ ] Plugin follows the standard structure
   - [ ] All required branding assets are included
   - [ ] Documentation is complete and clear
   - [ ] GitHub topics are properly set
   - [ ] Tests are passing
   - [ ] Demo evidence is provided

Visit the [Elizaos Plugin Development Guide]([https://github.com/elizaos-plugins/plugin-image](https://github.com/elizaOS/eliza/blob/main/docs/docs/packages/plugins.md) for detailed information on creating new plugins.

### Plugin Branding and Images

To maintain a consistent and professional appearance across the ElizaOS ecosystem, we recommend including the following assets in your plugin repository:

1. **Required Images:**
   - `logo.png` (400x400px) - Your plugin's square logo
   - `banner.png` (1280x640px) - A banner image for your plugin
   - `screenshot.png` - At least one screenshot demonstrating your plugin's functionality

2. **Image Location:**
   ```
   plugin-name/
   ├── assets/
   │   ├── logo.png
   │   ├── banner.png
   │   └── screenshots/
   │       ├── screenshot1.png
   │       └── screenshot2.png
   ```
   
3. **Image Guidelines:**
   - Use clear, high-resolution images
   - Keep file sizes optimized (< 500KB for logos, < 1MB for banners)
   - [Image example](https://github.com/elizaos-plugins/client-twitter/blob/main/images/banner.jpg)
   - Include alt text for accessibility

---

## Using Your Custom Plugins
Plugins that are not in the official registry for ElizaOS can be used as well. Here's how:

### Installation

1. Upload the custom plugin to the packages folder:

```
packages/
├─plugin-example/
├── package.json
├── tsconfig.json
├── src/
│   ├── index.ts        # Main plugin entry
│   ├── actions/        # Custom actions
│   ├── providers/      # Data providers
│   ├── types.ts        # Type definitions
│   └── environment.ts  # Configuration
├── README.md
└── LICENSE
```

2. Add the custom plugin to your project's dependencies in the agent's package.json:

```json
{
  "dependencies": {
    "@elizaos/plugin-example": "workspace:*"
  }
}
```

3. Import the custom plugin to your agent's character.json

```json
  "plugins": [
    "@elizaos/plugin-example",
  ],
```

## FAQ

### What exactly is a plugin in ElizaOS?

A plugin is a modular extension that adds new capabilities to ElizaOS agents, such as API integrations, custom actions, or platform connections. Plugins allow you to expand agent functionality and share reusable components with other developers.

### When should I create a plugin versus using existing ones?

Create a plugin when you need custom functionality not available in existing plugins, want to integrate with external services, or plan to share reusable agent capabilities with the community.

### What are the main types of plugin components?

Actions handle specific tasks, Providers supply data, Evaluators analyze responses, Services run background processes, Clients manage platform connections, and Adapters handle storage solutions.

### How do I test a plugin during development?

Use the mock client with `pnpm mock-eliza --characters=./characters/test.character.json` for rapid testing, then progress to platform-specific testing like web interface or Twitter integration.

### Why isn't my plugin being recognized?

Most commonly this occurs due to missing dependencies, incorrect registration in your character file, or build configuration issues. Ensure you've run `pnpm build` and properly imported the plugin.

### Can I monetize my plugin?

Yes, plugins can be monetized through the ElizaOS marketplace or by offering premium features/API access, making them an effective distribution mechanism for software products.

### How do I debug plugin issues?

Enable debug logging, use the mock client for isolated testing, and check the runtime logs for detailed error messages about plugin initialization and execution.

### What's the difference between Actions and Services?

Actions handle specific agent responses or behaviors, while Services provide ongoing background functionality or external API integrations that multiple actions might use.

## Additional Resources

- [ElizaOS Registry](https://github.com/elizaos-plugins/registry)
- [Example Plugins](https://github.com/elizaos-plugins)
````

## File: packages/docs/docs/core/providers.md
````markdown
# 🔌 Providers

[Providers](/packages/core/src/providers.ts) are the sources of information for the agent. They provide data or state while acting as the agent's "senses", injecting real-time information into the agent's context. They serve as the eyes, ears, and other sensory inputs that allow the agent to perceive and interact with its environment, like a bridge between the agent and various external systems such as market data, wallet information, sentiment analysis, and temporal context. Anything that the agent knows is either coming from like the built-in context or from a provider. For more info, see the [providers API page](/api/interfaces/provider).

Here's an example of how providers work within ElizaOS:

- A news provider could fetch and format news.
- A computer terminal provider in a game could feed the agent information when the player is near a terminal.
- A wallet provider can provide the agent with the current assets in a wallet.
- A time provider injects the current date and time into the context.

---

## Overview

A provider's primary purpose is to supply dynamic contextual information that integrates with the agent's runtime. They format information for conversation templates and maintain consistent data access. For example:

- **Function:** Providers run during or before an action is executed.
- **Purpose:** They allow for fetching information from other APIs or services to provide different context or ways for an action to be performed.
- **Example:** Before a "Mars rover action" is executed, a provider could fetch information from another API. This fetched information can then be used to enrich the context of the Mars rover action.

The provider interface is defined in [types.ts](/packages/core/src/types.ts):

```typescript
interface Provider {
    get: (
        runtime: IAgentRuntime, // Which agent is calling the provider
        message: Memory,        // Last message received 
        state?: State          // Current conversation state
    ) => Promise<string>;      // Returns info to inject into context
}
```

The `get` function takes:
- `runtime`: The agent instance calling the provider
- `message`: The last message received 
- `state`: Current conversation state (optional)

It returns a string that gets injected into the agent's context. The function can return null if there is no reason to validate.


---

## Examples

ElizaOS providers typically fall into these categories, with examples from the ecosystem:

### System & Integration
- **Time Provider**: Injects current date/time for temporal awareness
- **Giphy Provider**: Provides GIF responses using Giphy API
- **GitBook Provider**: Supplies documentation context from GitBook
- **Topics Provider**: Caches and serves Allora Network topic information

### Blockchain & DeFi
- **Wallet Provider**: Portfolio data from Zerion, balances and prices
- **DePIN Provider**: Network metrics via DePINScan API
- **Chain Providers**: Data from Abstract, Fuel, ICP, EVM networks
- **Market Provider**: Token data from DexScreener, Birdeye APIs

### Knowledge & Data
- **DKG Provider**: OriginTrail decentralized knowledge integration
- **News Provider**: Current events via NewsAPI
- **Trust Provider**: Calculates and injects trust scores

Visit the [ElizaOS Plugin Registry](https://github.com/elizaos-plugins/registry) for a complete list of available plugins and providers.

### Time Provider
[Source: packages/plugin-bootstrap/src/providers/time.ts](/packages/plugin-bootstrap/src/providers/time.ts)

Provides temporal awareness by injecting current date/time information:

```typescript
const timeProvider: Provider = {
    get: async (_runtime: IAgentRuntime, _message: Memory) => {
        const currentDate = new Date();
        const options = {
            timeZone: "UTC",
            dateStyle: "full" as const,
            timeStyle: "long" as const
        };
        const humanReadable = new Intl.DateTimeFormat("en-US", options)
            .format(currentDate);
        return `The current date and time is ${humanReadable}. Please use this as your reference for any time-based operations or responses.`;
    }
};
```

### Facts Provider 
[Source: packages/plugin-bootstrap/src/providers/facts.ts](/packages/plugin-bootstrap/src/providers/facts.ts)

Manages and serves conversation facts and knowledge:

```typescript
const factsProvider: Provider = {
    get: async (runtime: IAgentRuntime, message: Memory, state?: State) => {
        // Get recent messages
        const recentMessagesData = state?.recentMessagesData?.slice(-10);
        const recentMessages = formatMessages({
            messages: recentMessagesData,
            actors: state?.actorsData
        });

        // Generate embedding for semantic search
        const embedding = await embed(runtime, recentMessages);
        
        const memoryManager = new MemoryManager({
            runtime,
            tableName: "facts"
        });

        // Retrieve relevant facts
        const facts = await memoryManager.getMemories({
            roomId: message.roomId,
            count: 10,
            agentId: runtime.agentId
        });

        if (facts.length === 0) return "";

        const formattedFacts = formatFacts(facts);
        return `Key facts that ${runtime.character.name} knows:\n${formattedFacts}`;
    }
};
```

### Boredom Provider
[Source: packages/plugin-bootstrap/src/providers/boredom.ts](/packages/plugin-bootstrap/src/providers/boredom.ts)

Manages conversation dynamics and engagement by calculating a "boredom score". The provider helps agents maintain appropriate conversation engagement levels by analyzing recent messages (last 15 minutes) and tracking conversational dynamics through keywords and pattern detection that then generates status messages reflecting interaction quality.

#### Scoring Mechanisms

**Increases Boredom**:
- Excessive punctuation
- Negative or dismissive language
- Repetitive conversation patterns

**Decreases Boredom**:
- Substantive discussion topics
- Engaging questions
- Research-related keywords

```typescript
// Sample scoring logic
if (interestWords.some((word) => messageText.includes(word))) {
    boredomScore -= 1;
}
```

---

## FAQ

### What's a good caching strategy for providers?
Cache expensive operations with an appropriate TTL based on data freshness requirements - for example, the Topics Provider uses 30-minute caching.

### How should providers handle missing data?
Return an empty string for missing or invalid data rather than null or undefined.

### What's the best way to format provider output?
Keep context strings concise and consistently formatted, using clear templates when possible.

### When should I use a provider vs a service?
Use a provider when you need to inject information into the agent's context, and a service when the functionality doesn't need to be part of the conversation.

### Can providers access service functionality?
Yes, providers can use services through the runtime. For example, a wallet provider might use a blockchain service to fetch data.

### How should providers handle failures?
Providers should handle failures gracefully and return an empty string or implement retries for external API calls. Never throw errors that would break the agent's context composition.

### Can providers maintain state?
While providers can maintain internal state, it's better to use the runtime's state management facilities for persistence.

---

## Further Reading

- [Provider Implementation](/packages/core/src/providers.ts)
- [Types Reference](/packages/core/src/types.ts)
- [Runtime Integration](/packages/core/src/runtime.ts)
````

## File: packages/docs/docs/guides/configuration.md
````markdown
---
sidebar_position: 9
---

# ⚙️ Configuration Guide

This guide covers how to configure Eliza for different use cases and environments. We'll walk through all available configuration options and best practices.

## Environment Configuration

### Basic Setup

The first step is creating your environment configuration file:

```bash
cp .env.example .env
```

Then edit the `.env` file to add your specific configuration values.

---


## Character Configuration

Character files define your agent's personality and behavior. Create them in the `characters/` directory:

```json
{
    "name": "AgentName",
    "clients": ["discord", "twitter"],
    "modelProvider": "openrouter",
    "settings": {
        "model": "openai/gpt-4o",
        "temperature": 0.7,
        "maxTokens": 2000,
        "secrets": {
            "OPENAI_API_KEY": "character-specific-key",
            "DISCORD_TOKEN": "bot-specific-token"
        }
    }
}
```

### Secrets for Multiple Characters

If you don't want to have secrets in your character files because you would
like to utilize source control for collaborative development on multiple
characters, then you can put all character secrets in `.env` by prepending
`CHARACTER.NAME.` before the key name and value. For example:

```bash
# C3PO
CHARACTER.C3PO.DISCORD_APPLICATION_ID=abc
CHARACTER.C3PO.DISCORD_API_TOKEN=xyz

# DOBBY
CHARACTER.DOBBY.DISCORD_APPLICATION_ID=123
CHARACTER.DOBBY.DISCORD_API_TOKEN=369
```

---

## Custom Actions

### Adding Custom Actions

1. Create a `custom_actions` directory
2. Add your action files there
3. Configure in `elizaConfig.yaml`:

```yaml
actions:
    - name: myCustomAction
      path: ./custom_actions/myAction.ts
```

See the [actions](/docs/core/actions) page for more info.

---

## Advanced Configuration

### Cloudflare AI Gateway Integration

Eliza supports routing API calls through [Cloudflare AI Gateway](https://developers.cloudflare.com/ai-gateway/), which provides several benefits:

- Detailed analytics and monitoring of message traffic and response times
- Cost optimization through request caching and usage tracking across providers
- Improved latency through Cloudflare's global network
- Comprehensive visibility into message content and token usage

When enabled, Eliza will automatically route requests through your Cloudflare AI Gateway endpoint. If the gateway configuration is incomplete or disabled, Eliza will fall back to direct API calls.

### Logging

```bash
DEFAULT_LOG_LEVEL=info  # Options: debug, info, warn, error
LOG_JSON_FORMAT=false   # Set to true for JSON formatted logs
```

### Performance Settings

Fine-tune runtime behavior:

```typescript
const settings = {
    // Performance
    MAX_CONCURRENT_REQUESTS: 5,
    REQUEST_TIMEOUT: 30000,

    // Memory
    MEMORY_TTL: 3600,
    MAX_MEMORY_ITEMS: 1000,
};
```

---


## Environment Variables Reference

<details>
<summary>Click to expand .env.example file</summary>

```bash
# Eliza Environment Variables - Compact Reference

## SERVER & DATABASE
CACHE_STORE=database # Options: database|redis|filesystem
CACHE_DIR=./data/cache # For filesystem cache
REDIS_URL= # Redis connection string
PGLITE_DATA_DIR= # ../pgLite/ or memory://
SERVER_URL=http://localhost # Base URL
SERVER_PORT=3000 # Port number
SUPABASE_URL= # Supabase URL
SUPABASE_ANON_KEY= # Supabase key
MONGODB_CONNECTION_STRING= # MongoDB connection
MONGODB_DATABASE= # Default: elizaAgent
REMOTE_CHARACTER_URLS= # Comma-separated URLs
USE_CHARACTER_STORAGE=false # Store characters in data/character
DEFAULT_LOG_LEVEL=info # Log level
LOG_JSON_FORMAT=false # JSON format for logs

## CLIENT INTEGRATIONS
# BitMind
BITMIND=true # Enable BitMind
BITMIND_API_TOKEN= # API token

# Discord
DISCORD_APPLICATION_ID= # App ID
DISCORD_API_TOKEN= # Bot token
DISCORD_VOICE_CHANNEL_ID= # Voice channel

# Devin
DEVIN_API_TOKEN= # API token

# Gelato
GELATO_RELAY_API_KEY= # API key

# Farcaster
FARCASTER_FID= # FID for account
FARCASTER_NEYNAR_API_KEY= # API key
FARCASTER_NEYNAR_SIGNER_UUID= # Signer UUID
FARCASTER_DRY_RUN=false # Run without publishing
FARCASTER_POLL_INTERVAL=120 # Check interval (sec)

# Telegram
TELEGRAM_BOT_TOKEN= # Bot token
TELEGRAM_ACCOUNT_PHONE= # Phone number
TELEGRAM_ACCOUNT_APP_ID= # App API ID
TELEGRAM_ACCOUNT_APP_HASH= # App API hash
TELEGRAM_ACCOUNT_DEVICE_MODEL= # Device model
TELEGRAM_ACCOUNT_SYSTEM_VERSION= # System version

# Twitter/X
TWITTER_DRY_RUN=false # Simulate without posting
TWITTER_USERNAME= # Account username
TWITTER_PASSWORD= # Account password
TWITTER_EMAIL= # Account email
TWITTER_2FA_SECRET= # 2FA secret
TWITTER_COOKIES_AUTH_TOKEN= # Auth token
TWITTER_COOKIES_CT0= # Cookie CT0
TWITTER_COOKIES_GUEST_ID= # Guest ID cookie
TWITTER_POLL_INTERVAL=120 # Check interval (sec)
TWITTER_SEARCH_ENABLE=FALSE # Enable timeline search
TWITTER_TARGET_USERS= # Usernames to interact with
TWITTER_RETRY_LIMIT= # Max retry attempts
TWITTER_SPACES_ENABLE=false # Enable Spaces
ENABLE_TWITTER_POST_GENERATION=true # Auto tweet generation
POST_INTERVAL_MIN= # Min post interval (min), default: 90
POST_INTERVAL_MAX= # Max post interval (min), default: 180
POST_IMMEDIATELY= # Post immediately, default: false
ACTION_INTERVAL= # Action processing interval (min), default: 5
ENABLE_ACTION_PROCESSING=false # Enable action processing
MAX_ACTIONS_PROCESSING=1 # Max actions per cycle
ACTION_TIMELINE_TYPE=foryou # Timeline type: foryou|following
TWITTER_APPROVAL_DISCORD_CHANNEL_ID= # Discord channel ID
TWITTER_APPROVAL_DISCORD_BOT_TOKEN= # Discord bot token
TWITTER_APPROVAL_ENABLED= # Enable approval, default: false
TWITTER_APPROVAL_CHECK_INTERVAL=60000 # Check interval (ms)

# WhatsApp
WHATSAPP_ACCESS_TOKEN= # Access token
WHATSAPP_PHONE_NUMBER_ID= # Phone number ID
WHATSAPP_BUSINESS_ACCOUNT_ID= # Business Account ID
WHATSAPP_WEBHOOK_VERIFY_TOKEN= # Webhook token
WHATSAPP_API_VERSION=v17.0 # API version

# Alexa
ALEXA_SKILL_ID= # Skill ID
ALEXA_CLIENT_ID= # OAuth2 Client ID
ALEXA_CLIENT_SECRET= # OAuth2 Client Secret

# SimsAI
SIMSAI_API_KEY= # API key
SIMSAI_AGENT_ID= # Agent ID
SIMSAI_USERNAME= # Username
SIMSAI_DRY_RUN= # Test without API calls

# Direct Client
EXPRESS_MAX_PAYLOAD= # Max payload, default: 100kb

# Instagram
INSTAGRAM_DRY_RUN=false # Simulate without posting
INSTAGRAM_USERNAME= # Username
INSTAGRAM_PASSWORD= # Password
INSTAGRAM_APP_ID= # App ID (required)
INSTAGRAM_APP_SECRET= # App Secret (required)
INSTAGRAM_BUSINESS_ACCOUNT_ID= # Business Account ID
INSTAGRAM_POST_INTERVAL_MIN=60 # Min interval (min)
INSTAGRAM_POST_INTERVAL_MAX=120 # Max interval (min)
INSTAGRAM_ENABLE_ACTION_PROCESSING=false # Enable actions
INSTAGRAM_ACTION_INTERVAL=5 # Action interval (min)
INSTAGRAM_MAX_ACTIONS=1 # Max actions per cycle

## MODEL PROVIDERS
# OpenAI
OPENAI_API_KEY= # API key (sk-*)
OPENAI_API_URL= # API endpoint, default: https://api.openai.com/v1
SMALL_OPENAI_MODEL= # Default: gpt-4o-mini
MEDIUM_OPENAI_MODEL= # Default: gpt-4o
LARGE_OPENAI_MODEL= # Default: gpt-4o
EMBEDDING_OPENAI_MODEL= # Default: text-embedding-3-small
IMAGE_OPENAI_MODEL= # Default: dall-e-3
USE_OPENAI_EMBEDDING= # TRUE for OpenAI embeddings
ENABLE_OPEN_AI_COMMUNITY_PLUGIN=false # Enable community plugin
OPENAI_DEFAULT_MODEL= # Default model
OPENAI_MAX_TOKENS= # Max tokens
OPENAI_TEMPERATURE= # Temperature

# Atoma SDK
ATOMASDK_BEARER_AUTH= # Bearer token
ATOMA_API_URL= # Default: https://api.atoma.network/v1
SMALL_ATOMA_MODEL= # Default: meta-llama/Llama-3.3-70B-Instruct
MEDIUM_ATOMA_MODEL= # Default: meta-llama/Llama-3.3-70B-Instruct
LARGE_ATOMA_MODEL= # Default: meta-llama/Llama-3.3-70B-Instruct

# Eternal AI
ETERNALAI_URL= # Service URL
ETERNALAI_MODEL= # Default: NousResearch/Hermes-3-Llama-3.1-70B-FP8
ETERNALAI_CHAIN_ID=8453 # Default: 8453
ETERNALAI_RPC_URL= # RPC URL
ETERNALAI_AGENT_CONTRACT_ADDRESS= # Contract address
ETERNALAI_AGENT_ID= # Agent ID
ETERNALAI_API_KEY= # API key
ETERNALAI_LOG=false # Enable logging

# Hyperbolic
HYPERBOLIC_API_KEY= # API key
HYPERBOLIC_MODEL= # Model name
IMAGE_HYPERBOLIC_MODEL= # Default: FLUX.1-dev
SMALL_HYPERBOLIC_MODEL= # Default: meta-llama/Llama-3.2-3B-Instruct
MEDIUM_HYPERBOLIC_MODEL= # Default: meta-llama/Meta-Llama-3.1-70B-Instruct
LARGE_HYPERBOLIC_MODEL= # Default: meta-llama/Meta-Llama-3.1-405-Instruct
HYPERBOLIC_ENV=production # Environment
HYPERBOLIC_GRANULAR_LOG=true # Granular logging
HYPERBOLIC_SPASH=true # Show splash
HYPERBOLIC_LOG_LEVEL=debug # Log level

# Infera
INFERA_API_KEY= # API key
INFERA_MODEL= # Default: llama3.2:latest
INFERA_SERVER_URL= # Default: https://api.infera.org/
SMALL_INFERA_MODEL= # Recommended: llama3.2:latest
MEDIUM_INFERA_MODEL= # Recommended: mistral-nemo:latest
LARGE_INFERA_MODEL= # Recommended: mistral-small:latest

# Venice
VENICE_API_KEY= # API key
SMALL_VENICE_MODEL= # Default: llama-3.3-70b
MEDIUM_VENICE_MODEL= # Default: llama-3.3-70b
LARGE_VENICE_MODEL= # Default: llama-3.1-405b
IMAGE_VENICE_MODEL= # Default: fluently-xl

# Nineteen.ai
NINETEEN_AI_API_KEY= # API key
SMALL_NINETEEN_AI_MODEL= # Default: unsloth/Llama-3.2-3B-Instruct
MEDIUM_NINETEEN_AI_MODEL= # Default: unsloth/Meta-Llama-3.1-8B-Instruct
LARGE_NINETEEN_AI_MODEL= # Default: hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4
IMAGE_NINETEEN_AI_MODE= # Default: dataautogpt3/ProteusV0.4-Lightning

# Akash Chat API
AKASH_CHAT_API_KEY= # API key
SMALL_AKASH_CHAT_API_MODEL= # Default: Meta-Llama-3-2-3B-Instruct
MEDIUM_AKASH_CHAT_API_MODEL= # Default: Meta-Llama-3-3-70B-Instruct
LARGE_AKASH_CHAT_API_MODEL= # Default: Meta-Llama-3-1-405B-Instruct-FP8

# Livepeer
LIVEPEER_GATEWAY_URL=https://dream-gateway.livepeer.cloud # Gateway URL
IMAGE_LIVEPEER_MODEL= # Default: ByteDance/SDXL-Lightning
SMALL_LIVEPEER_MODEL= # Default: meta-llama/Meta-Llama-3.1-8B-Instruct
MEDIUM_LIVEPEER_MODEL= # Default: meta-llama/Meta-Llama-3.1-8B-Instruct
LARGE_LIVEPEER_MODEL= # Default: meta-llama/Meta-Llama-3.1-8B-Instruct

# Speech & Transcription
ELEVENLABS_XI_API_KEY= # ElevenLabs API key
ELEVENLABS_MODEL_ID=eleven_multilingual_v2 # Model ID
ELEVENLABS_VOICE_ID=21m00Tcm4TlvDq8ikWAM # Voice ID
ELEVENLABS_VOICE_STABILITY=0.5 # Stability
ELEVENLABS_VOICE_SIMILARITY_BOOST=0.9 # Similarity boost
ELEVENLABS_VOICE_STYLE=0.66 # Style value
ELEVENLABS_VOICE_USE_SPEAKER_BOOST=false # Speaker boost
ELEVENLABS_OPTIMIZE_STREAMING_LATENCY=4 # Latency level
ELEVENLABS_OUTPUT_FORMAT=pcm_16000 # Output format
TRANSCRIPTION_PROVIDER= # Default: local, options: openai|deepgram|local
DEEPGRAM_API_KEY= # Deepgram API key

# OpenRouter
OPENROUTER_API_KEY= # API key
OPENROUTER_MODEL= # Default: uses hermes 70b/405b
SMALL_OPENROUTER_MODEL= # Small model
MEDIUM_OPENROUTER_MODEL= # Medium model
LARGE_OPENROUTER_MODEL= # Large model

# REDPILL
REDPILL_API_KEY= # API key
REDPILL_MODEL= # Model name
SMALL_REDPILL_MODEL= # Default: gpt-4o-mini
MEDIUM_REDPILL_MODEL= # Default: gpt-4o
LARGE_REDPILL_MODEL= # Default: gpt-4o

# Grok
GROK_API_KEY= # API key
SMALL_GROK_MODEL= # Default: grok-2-1212
MEDIUM_GROK_MODEL= # Default: grok-2-1212
LARGE_GROK_MODEL= # Default: grok-2-1212
EMBEDDING_GROK_MODEL= # Default: grok-2-1212

# Ollama
OLLAMA_SERVER_URL= # Default: localhost:11434
OLLAMA_MODEL= # Model name
USE_OLLAMA_EMBEDDING= # TRUE for Ollama embeddings
OLLAMA_EMBEDDING_MODEL= # Default: mxbai-embed-large
SMALL_OLLAMA_MODEL= # Default: llama3.2
MEDIUM_OLLAMA_MODEL= # Default: hermes3
LARGE_OLLAMA_MODEL= # Default: hermes3:70b

# Google
GOOGLE_MODEL= # Model name
SMALL_GOOGLE_MODEL= # Default: gemini-1.5-flash-latest
MEDIUM_GOOGLE_MODEL= # Default: gemini-1.5-flash-latest
LARGE_GOOGLE_MODEL= # Default: gemini-1.5-pro-latest
EMBEDDING_GOOGLE_MODEL= # Default: text-embedding-004
GOOGLE_GENERATIVE_AI_API_KEY= # Gemini API key

# Mistral
MISTRAL_MODEL= # Model name
SMALL_MISTRAL_MODEL= # Default: mistral-small-latest
MEDIUM_MISTRAL_MODEL= # Default: mistral-large-latest
LARGE_MISTRAL_MODEL= # Default: mistral-large-latest

# Groq
GROQ_API_KEY= # API key (gsk_*)
SMALL_GROQ_MODEL= # Default: llama-3.1-8b-instant
MEDIUM_GROQ_MODEL= # Default: llama-3.3-70b-versatile
LARGE_GROQ_MODEL= # Default: llama-3.2-90b-vision-preview
EMBEDDING_GROQ_MODEL= # Default: llama-3.1-8b-instant

# LlamaLocal
LLAMALOCAL_PATH= # Default: current directory

# NanoGPT
SMALL_NANOGPT_MODEL= # Default: gpt-4o-mini
MEDIUM_NANOGPT_MODEL= # Default: gpt-4o
LARGE_NANOGPT_MODEL= # Default: gpt-4o
NANOGPT_API_KEY= # API key

# Anthropic
ANTHROPIC_API_KEY= # API key
ANTHROPIC_API_URL= # API URL
SMALL_ANTHROPIC_MODEL= # Default: claude-3-haiku-20240307
MEDIUM_ANTHROPIC_MODEL= # Default: claude-3-5-sonnet-20241022
LARGE_ANTHROPIC_MODEL= # Default: claude-3-5-sonnet-20241022

# Heurist
HEURIST_API_KEY= # API key
SMALL_HEURIST_MODEL= # Default: meta-llama/llama-3-70b-instruct
MEDIUM_HEURIST_MODEL= # Default: meta-llama/llama-3-70b-instruct
LARGE_HEURIST_MODEL= # Default: meta-llama/llama-3.3-70b-instruct
HEURIST_IMAGE_MODEL= # Default: FLUX.1-dev
HEURIST_EMBEDDING_MODEL= # Default: BAAI/bge-large-en-v1.5
USE_HEURIST_EMBEDDING= # TRUE for Heurist embeddings

# Gaianet
GAIANET_MODEL= # Model name
GAIANET_SERVER_URL= # Server URL
SMALL_GAIANET_MODEL= # Default: llama3b
SMALL_GAIANET_SERVER_URL= # Default: https://llama3b.gaia.domains/v1
MEDIUM_GAIANET_MODEL= # Default: llama
MEDIUM_GAIANET_SERVER_URL= # Default: https://llama8b.gaia.domains/v1
LARGE_GAIANET_MODEL= # Default: qwen72b
LARGE_GAIANET_SERVER_URL= # Default: https://qwen72b.gaia.domains/v1
GAIANET_EMBEDDING_MODEL= # Embedding model
USE_GAIANET_EMBEDDING= # TRUE for Gaianet embeddings

# Volcengine
VOLENGINE_API_URL= # Default: https://open.volcengineapi.com/api/v3/
VOLENGINE_MODEL= # Model name
SMALL_VOLENGINE_MODEL= # Default: doubao-lite-128k
MEDIUM_VOLENGINE_MODEL= # Default: doubao-pro-128k
LARGE_VOLENGINE_MODEL= # Default: doubao-pro-256k
VOLENGINE_EMBEDDING_MODEL= # Default: doubao-embedding

# DeepSeek
DEEPSEEK_API_KEY= # API key
DEEPSEEK_API_URL= # Default: https://api.deepseek.com
SMALL_DEEPSEEK_MODEL= # Default: deepseek-chat
MEDIUM_DEEPSEEK_MODEL= # Default: deepseek-chat
LARGE_DEEPSEEK_MODEL= # Default: deepseek-chat

# fal.ai
FAL_API_KEY= # API key
FAL_AI_LORA_PATH= # LoRA models path

# LetzAI
LETZAI_API_KEY= # API key
LETZAI_MODELS= # Models list (e.g., @modelname1, @modelname2)

# Galadriel
GALADRIEL_API_KEY= # API key (gal-*)
SMALL_GALADRIEL_MODEL= # Default: gpt-4o-mini
MEDIUM_GALADRIEL_MODEL= # Default: gpt-4o
LARGE_GALADRIEL_MODEL= # Default: gpt-4o
GALADRIEL_FINE_TUNE_API_KEY= # OpenAI key for fine-tuned models

# LM Studio
LMSTUDIO_SERVER_URL= # Default: http://localhost:1234/v1
LMSTUDIO_MODEL= # Model name
SMALL_LMSTUDIO_MODEL= # Default: hermes-3-llama-3.1-8b
MEDIUM_LMSTUDIO_MODEL= # Default: hermes-3-llama-3.1-8b
LARGE_LMSTUDIO_MODEL= # Default: hermes-3-llama-3.1-8b

# Secret AI
SECRET_AI_API_KEY= # API key
SECRET_AI_URL= # Default: https://ai1.scrtlabs.com:21434
SMALL_SECRET_AI_MODEL= # Default: deepseek-r1:70b
MEDIUM_SECRET_AI_MODEL= # Default: deepseek-r1:70b
LARGE_SECRET_AI_MODEL= # Default: deepseek-r1:70b

# NEAR AI
NEARAI_API_URL= # Default: https://api.near.ai/v1
NEARAI_API_KEY= # API key
NEARAI_MODEL= # Model name
SMALL_NEARAI_MODEL= # Default: fireworks::accounts/fireworks/models/llama-v3p2-3b-instruct
MEDIUM_NEARAI_MODEL= # Default: fireworks::accounts/fireworks/models/llama-v3p1-70b-instruct
LARGE_NEARAI_MODEL= # Default: fireworks::accounts/fireworks/models/llama-v3p1-405b-instruct
IMAGE_NEARAI_MODEL= # Default: fireworks::accounts/fireworks/models/playground-v2-5-1024px-aesthetic

# Other API Keys
ALI_BAILIAN_API_KEY= # Ali Bailian API key
TOGETHER_API_KEY= # Together API key

## CRYPTO PLUGINS
# Market Data APIs
COINMARKETCAP_API_KEY= # CoinMarketCap API key
ZERION_API_KEY= # Zerion API key
COINGECKO_API_KEY= # CoinGecko API key (free)
COINGECKO_PRO_API_KEY= # CoinGecko Pro API key
MORALIS_API_KEY= # Moralis API key
CHAINBASE_API_KEY= # Chainbase API key (demo for free tier)
BIRDEYE_API_KEY= # Birdeye API key

# EVM Chains
EVM_PRIVATE_KEY= # Private key (with 0x prefix)
EVM_PROVIDER_URL= # RPC provider URL
ALCHEMY_HTTP_TRANSPORT_URL= # Alchemy HTTP URL
ZERO_EX_API_KEY= # 0x API key

# Zilliqa
ZILLIQA_PRIVATE_KEY= # Private key
ZILLIQA_PROVIDER_URL= # Provider URL

# Avalanche
AVALANCHE_PRIVATE_KEY= # Private key
AVALANCHE_PUBLIC_KEY= # Public key

# Arthera
ARTHERA_PRIVATE_KEY= # Private key

# Solana
SOLANA_PRIVATE_KEY= # Private key
SOLANA_PUBLIC_KEY= # Public key
SOLANA_CLUSTER= # Options: devnet|testnet|mainnet-beta, default: devnet
SOLANA_ADMIN_PRIVATE_KEY= # Admin private key for NFT verification
SOLANA_ADMIN_PUBLIC_KEY= # Admin public key for NFT verification
SOLANA_VERIFY_TOKEN= # Verification API token
SOL_ADDRESS=So11111111111111111111111111111111111111112 # SOL token address
SLIPPAGE=1 # Slippage percentage
BASE_MINT=So11111111111111111111111111111111111111112 # Base token address
SOLANA_RPC_URL=https://api.mainnet-beta.solana.com # RPC URL
HELIUS_API_KEY= # Helius API key

# Injective
INJECTIVE_PRIVATE_KEY= # Private key
INJECTIVE_PUBLIC_KEY= # Public key
INJECTIVE_NETWORK= # Network setting

# Legacy Wallet (deprecated)
WALLET_PRIVATE_KEY= # Private key
WALLET_PUBLIC_KEY= # Public key

# Abstract
ABSTRACT_ADDRESS= # Address
ABSTRACT_PRIVATE_KEY= # Private key
ABSTRACT_RPC_URL=https://api.testnet.abs.xyz # RPC URL

# Starknet
STARKNET_ADDRESS= # Address
STARKNET_PRIVATE_KEY= # Private key
STARKNET_RPC_URL=https://rpc.starknet-testnet.lava.build # RPC URL

# Lens Network
LENS_ADDRESS= # Address
LENS_PRIVATE_KEY= # Private key

# Viction
VICTION_ADDRESS= # Address
VICTION_PRIVATE_KEY= # Private key
VICTION_RPC_URL= # RPC URL

# Form Chain
FORM_PRIVATE_KEY= # Character account private key
FORM_TESTNET=true # true=Testnet, false=Mainnet

# Coinbase
COINBASE_COMMERCE_KEY= # Commerce key
COINBASE_API_KEY= # API key
COINBASE_PRIVATE_KEY= # Private key
COINBASE_GENERATED_WALLET_ID= # Generated wallet ID
COINBASE_GENERATED_WALLET_HEX_SEED= # Wallet hex seed
COINBASE_NOTIFICATION_URI= # Webhook URI

# Coinbase AgentKit
CDP_API_KEY_NAME= # API key name
CDP_API_KEY_PRIVATE_KEY= # Private key
CDP_AGENT_KIT_NETWORK=base-sepolia # Default: base-sepolia

# Charity
IS_CHARITABLE=false # Enable charity donations
CHARITY_ADDRESS_BASE= # Base network address
CHARITY_ADDRESS_SOL= # Solana address
CHARITY_ADDRESS_ETH= # Ethereum address
CHARITY_ADDRESS_ARB= # Arbitrum address
CHARITY_ADDRESS_POL= # Polygon address

# Thirdweb
THIRDWEB_SECRET_KEY= # Secret key

# Conflux
CONFLUX_CORE_PRIVATE_KEY= # Core private key
CONFLUX_CORE_SPACE_RPC_URL= # Core RPC URL
CONFLUX_ESPACE_PRIVATE_KEY= # eSpace private key
CONFLUX_ESPACE_RPC_URL= # eSpace RPC URL
CONFLUX_MEME_CONTRACT_ADDRESS= # Meme contract address

# Mind Network
MIND_HOT_WALLET_PRIVATE_KEY= # Hot wallet private key
MIND_COLD_WALLET_ADDRESS= # Cold wallet address

# ZeroG
ZEROG_INDEXER_RPC= # Indexer RPC
ZEROG_EVM_RPC= # EVM RPC
ZEROG_PRIVATE_KEY= # Private key
ZEROG_FLOW_ADDRESS= # Flow address

# IQ6900
IQ_WALLET_ADDRESS= # Wallet address
IQSOlRPC= # Solana RPC

# Squid Router
SQUID_SDK_URL=https://apiplus.squidrouter.com # Default SDK URL
SQUID_INTEGRATOR_ID= # Integrator ID
SQUID_EVM_ADDRESS= # EVM address
SQUID_EVM_PRIVATE_KEY= # EVM private key
SQUID_API_THROTTLE_INTERVAL=1000 # Throttle interval (ms)

# TEE Configuration
TEE_MODE=OFF # Options: LOCAL|DOCKER|PRODUCTION|OFF
WALLET_SECRET_SALT= # Salt for wallet secrets
TEE_LOG_DB_PATH= # Default: ./data/tee_log.sqlite
VLOG= # Enable TEE Verifiable Log if "true"
ENABLE_TEE_LOG=false # Enable TEE logging (TEE mode only)
TEE_MARLIN= # Set "yes" to enable Marlin plugin
TEE_MARLIN_ATTESTATION_ENDPOINT= # Default: http://127.0.0.1:1350

# Flow Blockchain
FLOW_ADDRESS= # Flow address
FLOW_PRIVATE_KEY= # Private key for SHA3-256 + P256 ECDSA
FLOW_NETWORK= # Default: mainnet
FLOW_ENDPOINT_URL= # Default: https://mainnet.onflow.org

# Internet Computer Protocol
INTERNET_COMPUTER_PRIVATE_KEY= # ICP private key
INTERNET_COMPUTER_ADDRESS= # ICP address

# Cloudflare AI
CLOUDFLARE_GW_ENABLED= # Enable Cloudflare AI Gateway
CLOUDFLARE_AI_ACCOUNT_ID= # Account ID
CLOUDFLARE_AI_GATEWAY_ID= # Gateway ID

# Aptos
APTOS_PRIVATE_KEY= # Private key
APTOS_NETWORK= # Options: mainnet|testnet

# MultiversX
MVX_PRIVATE_KEY= # Private key
MVX_NETWORK= # Options: mainnet|devnet|testnet
ACCESS_TOKEN_MANAGEMENT_TO=everyone # Limit token management

# NEAR
NEAR_WALLET_SECRET_KEY= # Secret key
NEAR_WALLET_PUBLIC_KEY= # Public key
NEAR_ADDRESS= # Address
NEAR_SLIPPAGE=1 # Slippage percentage
NEAR_RPC_URL=https://near-testnet.lava.build # RPC URL
NEAR_NETWORK=testnet # Options: testnet|mainnet

# ZKsync Era
ZKSYNC_ADDRESS= # Address
ZKSYNC_PRIVATE_KEY= # Private key

# HoldStation
HOLDSTATION_PRIVATE_KEY= # Private key

# Avail DA
AVAIL_ADDRESS= # Address
AVAIL_SEED= # Seed
AVAIL_APP_ID=0 # App ID
AVAIL_RPC_URL=wss://avail-turing.public.blastapi.io/ # Default RPC URL

# TON
TON_PRIVATE_KEY= # Mnemonic joined with empty string
TON_RPC_URL= # RPC URL
TON_RPC_API_KEY= # RPC API key
TON_NFT_IMAGES_FOLDER= # NFT images folder
TON_NFT_METADATA_FOLDER= # NFT metadata folder
PINATA_API_KEY= # Pinata API key
PINATA_API_SECRET= # Pinata API secret
PINATA_JWT= # Pinata JWT

# Sui
SUI_PRIVATE_KEY= # Private key/mnemonic
SUI_NETWORK= # Options: mainnet|testnet|devnet|localnet

# Mina
MINA_PRIVATE_KEY= # Mnemonic seed phrase
MINA_NETWORK=devnet # Options: mainnet|testnet|devnet|localnet

# Story
STORY_PRIVATE_KEY= # Private key
STORY_API_BASE_URL= # API base URL
STORY_API_KEY= # API key

# Cosmos
COSMOS_RECOVERY_PHRASE= # 12-word recovery phrase
COSMOS_AVAILABLE_CHAINS= # Chain list (comma-separated)

# Cronos zkEVM
CRONOSZKEVM_ADDRESS= # Address
CRONOSZKEVM_PRIVATE_KEY= # Private key

# Fuel Ecosystem
FUEL_WALLET_PRIVATE_KEY= # Private key

# Spheron
SPHERON_PRIVATE_KEY= # Private key
SPHERON_PROVIDER_PROXY_URL= # Provider proxy URL
SPHERON_WALLET_ADDRESS= # Wallet address

# Stargaze
STARGAZE_ENDPOINT= # GraphQL endpoint

# GenLayer
GENLAYER_PRIVATE_KEY= # Private key (0x format)

# BNB Chain
BNB_PRIVATE_KEY= # Private key
BNB_PUBLIC_KEY= # Public key
BSC_PROVIDER_URL= # BNB Smart Chain RPC URL
OPBNB_PROVIDER_URL= # OPBNB RPC URL

# Allora
ALLORA_API_KEY= # API key (UP-* format)
ALLORA_CHAIN_SLUG= # Options: mainnet|testnet, default: testnet

# B2 Network
B2_PRIVATE_KEY= # Private key

# Opacity zkTLS
OPACITY_TEAM_ID=f309ac8ae8a9a14a7e62cd1a521b1c5f # Team ID
OPACITY_CLOUDFLARE_NAME=eigen-test # Cloudflare name
OPACITY_PROVER_URL=https://opacity-ai-zktls-demo.vercel.app # Prover URL

# SEI Network
SEI_PRIVATE_KEY= # Private key
SEI_NETWORK= # Options: mainnet|testnet|devnet
SEI_RPC_URL= # Custom RPC URL

# Omniflix
OMNIFLIX_API_URL= # https://rest.omniflix.network
OMNIFLIX_MNEMONIC= # 12/24-word mnemonic
OMNIFLIX_RPC_ENDPOINT= # https://rpc.omniflix.network
OMNIFLIX_PRIVATE_KEY= # Private key

# Hyperliquid
HYPERLIQUID_PRIVATE_KEY= # Private key
HYPERLIQUID_TESTNET= # true/false, default: false

# Lit Protocol
FUNDING_PRIVATE_KEY= # Funding private key
EVM_RPC_URL= # RPC URL

# EthStorage DA
ETHSTORAGE_PRIVATE_KEY= # Private key
ETHSTORAGE_ADDRESS=0x64003adbdf3014f7E38FC6BE752EB047b95da89A # Address
ETHSTORAGE_RPC_URL=https://rpc.beta.testnet.l2.quarkchain.io:8545 # RPC URL

# DCAP
DCAP_EVM_PRIVATE_KEY= # Private key
DCAP_MODE= # Options: OFF|PLUGIN-SGX|PLUGIN-TEE|MOCK

# QuickIntel
QUICKINTEL_API_KEY= # Token security analysis API key

# News API
NEWS_API_KEY= # From https://newsapi.org/

# BTCFUN
BTCFUN_API_URL= # Default: https://api-testnet-new.btc.fun
BTC_PRIVATE_KEY_WIF= # BTC private key in WIF format
BTC_ADDRESS= # BTC address
BTC_MINT_CAP=10000 # Maximum mint amount
BTC_MINT_DEADLINE=864000 # Deadline in seconds
BTC_FUNDRAISING_CAP=100 # Maximum fundraising amount

# Trikon
TRIKON_WALLET_ADDRESS= # Valid 64-char hex with 0x prefix
TRIKON_INITIAL_BALANCE= # Optional, default: 0

# Arbitrage
ARBITRAGE_ETHEREUM_WS_URL= # Ethereum WebSocket URL
ARBITRAGE_EVM_PROVIDER_URL= # Ethereum RPC URL
ARBITRAGE_EVM_PRIVATE_KEY= # Private key for transactions
FLASHBOTS_RELAY_SIGNING_KEY= # Flashbots signing key
BUNDLE_EXECUTOR_ADDRESS= # Bundle executor contract address

# DESK Exchange
DESK_EXCHANGE_PRIVATE_KEY= # Private key
DESK_EXCHANGE_NETWORK= # mainnet or testnet

# Compass
COMPASS_WALLET_PRIVATE_KEY= # Private key
COMPASS_ARBITRUM_RPC_URL= # Arbitrum RPC URL
COMPASS_ETHEREUM_RPC_URL= # Ethereum RPC URL
COMPASS_BASE_RPC_URL= # Base RPC URL

# d.a.t.a
DATA_API_KEY= # API key
DATA_AUTH_TOKEN= # Auth token

# NKN
NKN_CLIENT_PRIVATE_KEY= # Required client private key
NKN_CLIENT_ID= # Optional client ID

# Router Nitro EVM
ROUTER_NITRO_EVM_ADDRESS= # Address
ROUTER_NITRO_EVM_PRIVATE_KEY= # Private key

# OriginTrail DKG
DKG_ENVIRONMENT= # Options: development|testnet|mainnet
DKG_HOSTNAME= # Hostname
DKG_PORT=8900 # Port
DKG_PUBLIC_KEY= # Public key
DKG_PRIVATE_KEY= # Private key
DKG_BLOCKCHAIN_NAME= # Chain configs

# Initia
INITIA_PRIVATE_KEY= # Wallet private key
INITIA_NODE_URL= # Node URL, default: testnet
INITIA_CHAIN_ID=initia-test # Chain ID, default: testnet

# NVIDIA
NVIDIA_NIM_ENV=production # Environment
NVIDIA_NIM_SPASH=false # Show splash
NVIDIA_NIM_API_KEY= # NIM API key
NVIDIA_NGC_API_KEY= # NGC API key
NVIDIA_NIM_MAX_RETRIES=3 # Max retries
NVIDIA_NIM_RETRY_DELAY=1000 # Retry delay (ms)
NVIDIA_NIM_TIMEOUT=5000 # Timeout (ms)
NVIDIA_GRANULAR_LOG=true # Granular logging
NVIDIA_LOG_LEVEL=debug # Log level
NVIDIA_OFFTOPIC_SYSTEM= # Off-topic system
NVIDIA_OFFTOPIC_USER= # Off-topic user
NVIDIA_NIM_BASE_VISION_URL=https://ai.api.nvidia.com/v1/vlm # Vision URL
NVIDIA_COSMOS_MODEL=nvidia/cosmos-nemotron-34b # Model name
NVIDIA_COSMOS_INVOKE_URL=https://ai.api.nvidia.com/v1/vlm/nvidia/cosmos-nemotron-34b # Invoke URL
NVIDIA_COSMOS_ASSET_URL=https://api.nvcf.nvidia.com/v2/nvcf/assets # Asset URL
NVIDIA_COSMOS_MAX_TOKENS=1000 # Max tokens

# Email
EMAIL_OUTGOING_SERVICE=smtp # Options: smtp|gmail
EMAIL_OUTGOING_HOST=smtp.example.com # SMTP host
EMAIL_OUTGOING_PORT=465 # Default: 465 (secure), 587 (TLS)
EMAIL_OUTGOING_USER= # Username
EMAIL_OUTGOING_PASS= # Password/app password
EMAIL_INCOMING_SERVICE=imap # Service type
EMAIL_INCOMING_HOST=imap.example.com # IMAP host
EMAIL_INCOMING_PORT=993 # Default port for secure IMAP
EMAIL_INCOMING_USER= # Username
EMAIL_INCOMING_PASS= # Password

# Email Automation
RESEND_API_KEY= # Resend API key
DEFAULT_TO_EMAIL= # Default recipient
DEFAULT_FROM_EMAIL= # Default sender
EMAIL_AUTOMATION_ENABLED=false # Enable AI detection
EMAIL_EVALUATION_PROMPT= # Custom detection criteria

# ANKR
ANKR_ENV=production # Environment
ANKR_WALLET= # Wallet
ANKR_MAX_RETRIES=3 # Max retries
ANKR_RETRY_DELAY=1000 # Retry delay (ms)
ANKR_TIMEOUT=5000 # Timeout (ms)
ANKR_GRANULAR_LOG=true # Granular logging
ANKR_LOG_LEVEL=debug # Log level
ANKR_RUNTIME_CHECK_MODE=false # Check mode
ANKR_SPASH=true # Show splash

# Quai Network
QUAI_PRIVATE_KEY= # Private key
QUAI_RPC_URL=https://rpc.quai.network # RPC URL

# Tokenizer
TOKENIZER_MODEL= # Tokenizer model
TOKENIZER_TYPE= # Options: tiktoken|auto, default: tiktoken

# AWS Services
AWS_ACCESS_KEY_ID= # Access key ID
AWS_SECRET_ACCESS_KEY= # Secret access key
AWS_REGION= # AWS region
AWS_S3_BUCKET= # S3 bucket name
AWS_S3_UPLOAD_PATH= # S3 upload path
AWS_S3_ENDPOINT= # S3 endpoint
AWS_S3_SSL_ENABLED= # Enable SSL
AWS_S3_FORCE_PATH_STYLE= # Force path style

# Deva
DEVA_API_KEY= # API key from deva.me/settings/apps
DEVA_API_BASE_URL=https://api.deva.me # Default URL

# Verifiable Inference
VERIFIABLE_INFERENCE_ENABLED=false # Enable verification
VERIFIABLE_INFERENCE_PROVIDER=opacity # Provider option

# Qdrant
QDRANT_URL= # Qdrant instance URL
QDRANT_KEY= # API key
QDRANT_PORT=443 # Port (443 cloud, 6333 local)
QDRANT_VECTOR_SIZE=1536 # Vector size

# Autonome
AUTONOME_JWT_TOKEN= # JWT token
AUTONOME_RPC=https://wizard-bff-rpc.alt.technology/v1/bff/aaa/apps # RPC URL

# Akash Network
AKASH_ENV=mainnet # Environment
AKASH_NET=https://raw.githubusercontent.com/ovrclk/net/master/mainnet # Network
RPC_ENDPOINT=https://rpc.akashnet.net:443 # RPC endpoint
AKASH_GAS_PRICES=0.025uakt # Gas prices
AKASH_GAS_ADJUSTMENT=1.5 # Gas adjustment
AKASH_KEYRING_BACKEND=os # Keyring backend
AKASH_FROM=default # From account
AKASH_FEES=20000uakt # Fees
AKASH_DEPOSIT=500000uakt # Deposit
AKASH_MNEMONIC= # Mnemonic
AKASH_WALLET_ADDRESS= # Wallet address
AKASH_PRICING_API_URL=https://console-api.akash.network/v1/pricing # Pricing API
AKASH_DEFAULT_CPU=1000 # Default CPU
AKASH_DEFAULT_MEMORY=1000000000 # Default memory
AKASH_DEFAULT_STORAGE=1000000000 # Default storage
AKASH_SDL=example.sdl.yml # SDL file
AKASH_CLOSE_DEP=closeAll # Close deployment
AKASH_CLOSE_DSEQ=19729929 # Close DSEQ
AKASH_PROVIDER_INFO=akash1ccktptfkvdc67msasmesuy5m7gpc76z75kukpz # Provider info
AKASH_DEP_STATUS=dseq # Deployment status
AKASH_DEP_DSEQ=19729929 # Deployment DSEQ
AKASH_GAS_OPERATION=close # Gas operation
AKASH_GAS_DSEQ=19729929 # Gas DSEQ
AKASH_MANIFEST_MODE=auto # Manifest mode
AKASH_MANIFEST_PATH= # Manifest path
AKASH_MANIFEST_VALIDATION_LEVEL=strict # Validation level

# Pyth
PYTH_NETWORK_ENV=mainnet # Network environment
PYTH_MAINNET_HERMES_URL=https://hermes.pyth.network # Mainnet Hermes URL
PYTH_MAINNET_WSS_URL=wss://hermes.pyth.network/ws # Mainnet WSS URL
PYTH_MAINNET_PYTHNET_URL=https://pythnet.rpcpool.com # Mainnet Pythnet URL
PYTH_MAINNET_CONTRACT_REGISTRY=https://pyth.network/developers/price-feed-ids # Registry
PYTH_MAINNET_PROGRAM_KEY= # Program key
PYTH_TESTNET_HERMES_URL=https://hermes.pyth.network # Testnet Hermes URL
PYTH_TESTNET_WSS_URL=wss://hermes.pyth.network/ws # Testnet WSS URL
PYTH_TESTNET_PYTHNET_URL=https://pythnet.rpcpool.com # Testnet Pythnet URL
PYTH_TESTNET_CONTRACT_REGISTRY=https://pyth.network/developers/price-feed-ids#testnet # Registry
PYTH_TESTNET_PROGRAM_KEY= # Program key
PYTH_MAX_RETRIES=3 # Max retries
PYTH_RETRY_DELAY=1000 # Retry delay (ms)
PYTH_TIMEOUT=5000 # Timeout (ms)
PYTH_GRANULAR_LOG=true # Granular logging
PYTH_LOG_LEVEL=debug # Log level for debugging
PYTH_LOG_LEVEL=info # Log level for production
PYTH_ENABLE_PRICE_STREAMING=true # Enable price streaming
PYTH_MAX_PRICE_STREAMS=2 # Max price streams
PYTH_TEST_ID01=0xe62df6c8b4a85fe1a67db44dc12de5db330f7ac66b72dc658afedf0f4a415b43 # Test ID
PYTH_TEST_ID02=0xff61491a931112ddf1bd8147cd1b641375f79f5825126d665480874634fd0ace # Test ID

# Misc Plugins
INTIFACE_WEBSOCKET_URL=ws://localhost:12345 # Intiface WebSocket URL
GIPHY_API_KEY= # API key from giphy
OPEN_WEATHER_API_KEY= # OpenWeather API key
PASSPORT_API_KEY= # Gitcoin Passport key
PASSPORT_SCORER= # Scorer number
TAVILY_API_KEY= # Web search API key
ECHOCHAMBERS_API_URL=http://127.0.0.1:3333 # API URL
ECHOCHAMBERS_API_KEY=testingkey0011 # API key
ECHOCHAMBERS_USERNAME=eliza # Username
ECHOCHAMBERS_ROOMS=general # Comma-separated room list
ECHOCHAMBERS_POLL_INTERVAL=60 # Poll interval (sec)
ECHOCHAMBERS_MAX_MESSAGES=10 # Max messages
ECHOCHAMBERS_CONVERSATION_STARTER_INTERVAL=300 # Check interval (sec)
ECHOCHAMBERS_QUIET_PERIOD=900 # Quiet period (sec)
SUNO_API_KEY= # Suno AI music generation
UDIO_AUTH_TOKEN= # Udio AI music generation
FOOTBALL_API_KEY= # Football-Data.org API key
IMGFLIP_USERNAME= # Imgflip username
IMGFLIP_PASSWORD= # Imgflip password
RUNTIME_CHECK_MODE=false # Runtime check mode
```
</details>

---

## FAQ

### How do I configure different model providers?
Set `modelProvider` in your character.json and add corresponding API keys in `.env` or character secrets. Supports Anthropic, OpenAI, DeepSeek, and others.

### How do I adjust the temperature setting in my character file?
The temperature setting controls response randomness and can be configured in your character's JSON file:

```json
{
    "modelProvider": "openrouter",
    "temperature": 0.7,
    "settings": {
        "model": "openai/gpt-4o-mini"
        "maxInputTokens": 200000,
        "maxOutputTokens": 8192
    }
}
```
Increase temperature for more creative responses, decrease for more consistent outputs.

### I'm getting an authentication error ("No auth credentials found"). What should I do?
Check these common issues:
1. Verify API keys in your .env file
2. Ensure keys are properly formatted (OpenAI keys start with `sk-`, Groq with `gsk_`, etc.)
3. Check logs for specific authentication errors
4. Try restarting the application after updating credentials
5. For character-specific providers, ensure they have access to the needed keys

### How do I debug when my agent isn't responding?
1. Enable debug logging: `DEBUG=eliza:*` in your .env file
2. Check database for saved messages
3. Verify model provider connectivity
4. Review logs for error messages

### How do I control my agent's behavior across platforms?
Configure platform-specific settings in `.env` (like `TWITTER_TARGET_USERS`) and adjust response templates in your character file.
````

## File: packages/docs/docs/intro.md
````markdown
---
sidebar_position: 1
---

# Introduction to Eliza

![](/img/eliza_banner.jpg)
_As seen powering [@DegenSpartanAI](https://x.com/degenspartanai) and [@aixvc_agent](https://x.com/aixvc_agent)_

## What is Eliza?

Eliza is a powerful multi-agent simulation framework designed to create, deploy, and manage autonomous AI agents. Built with TypeScript, it provides a flexible and extensible platform for developing intelligent agents that can interact across multiple platforms while maintaining consistent personalities and knowledge.

- [Technical Report (Whitepaper)](https://arxiv.org/pdf/2501.06781)
- [Examples (Awesome Eliza)](https://github.com/elizaos/awesome-eliza)

## Key Features

- **Platform Integration**: Clients for Discord, X (Twitter), Telegram, and many others
- **Flexible Model Support**: Deepseek, Ollama, Grok, OpenAI, Anthropic, Gemini, LLama, etc.
- **Character System**: Create diverse agents using [characterfiles](https://github.com/elizaOS/characterfile)
- **Multi-Agent Architecture**: Manage multiple unique AI personalities simultaneously
- **Memory Management**: Easily ingest and interact with documents using RAG
- **Media Processing**: PDF, URLs, Audio transcription, Video processing, Image analysis, Conversation summarization
- **Technical Foundation**:
    - 100% TypeScript implementation
    - Modular architecture
    - Highly extensible action and plugin system
    - Custom client support
    - Comprehensive API

## Use Cases

Eliza can be used to create:

- **AI Assistants**: Customer support agents, Community moderators, Personal assistants
- **Social Media Personas**: Automated content creators, Brand representatives, Influencers
- **Knowledge Workers**: Research assistants, Content analysts, Document processors
- **Interactive Characters**: Role-playing characters, Educational tutors, Entertainment bots

## Architecture

![](/img/eliza-architecture.jpg)
Source: https://x.com/0xCygaar/status/1874575841763770492

The characterfile contains everything about the agent's personality, backstory, knowledge, and topics to talk about, as well as which clients / models / and plugins to load. The database is where an agent stores relevant info for generating responses, including previous tweets, interactions, and embeddings. Without a db, agent's wouldn't be able to give good responses.

Then we have the "runtime", which you can think of as the core agent logic. It's effectively the coordination layer of the agent or the brain, calling the necessary modules and external services to generate responses and take actions. Within the runtime is the LLM, which processes various inputs and generates responses or action items for the agent to take. Devs can declare which LLM provider to use in the characterfile. The runtime also handles the registration of plugins, which are called when a user input asks it take an action, such as transferring ETH on Abstract or doing a web search.

Eliza supports a variety of clients including `Discord`, `Twitter`, `Slack`, `Farcaster`, and others. The client is basically where the agent will live and interact with users. Agents can run on multiple clients at once. Clients can have modules to handle different interactions, such as responding to tweets, or even participating in Twitter spaces.

---

## Getting Started

For a more detailed guide, check out our [Quickstart Guide](./quickstart.md) to begin your journey with Eliza.

### Prerequisites

- [Python 2.7+](https://www.python.org/downloads/)
- [Node.js 23+](https://docs.npmjs.com/downloading-and-installing-node-js-and-npm)
- [pnpm](https://pnpm.io/installation)

> **Note for Windows Users:** [WSL 2](https://learn.microsoft.com/en-us/windows/wsl/install-manual) is required.

The start script provides an automated way to set up and run Eliza:

### Automated Start

```bash
git clone https://github.com/elizaos/eliza-starter.git
cd eliza-starter
cp .env.example .env
pnpm i && pnpm build && pnpm start
```

OR

```bash
git clone https://github.com/elizaos/eliza
cd eliza
sh scripts/start.sh
```

For detailed instructions on using the start script, including character management and troubleshooting, see our [Quickstart Guide](./quickstart).

> **Note**: The start script handles all dependencies, environment setup, and character management automatically.

---

## Community and Support

Eliza is backed by an active community of developers and users:

- [**Open Source**](https://github.com/elizaos/eliza): Contribute to the project on GitHub
- [**Examples**](https://github.com/elizaos/characters): Ready-to-use character templates and implementations
- [**Support**](https://discord.gg/elizaos): Active community for troubleshooting and discussion

Join us in building the future of autonomous AI agents with Eliza!

## Next Steps

- [Create Your First Agent](../quickstart)
- [Understand Core Concepts](../core/agents)
````

## File: packages/docs/docs/quickstart.md
````markdown
---
sidebar_position: 2
---

# Quickstart Guide

## Prerequisites

Before getting started with Eliza, ensure you have:

- [Node.js 23+](https://docs.npmjs.com/downloading-and-installing-node-js-and-npm) (using [nvm](https://github.com/nvm-sh/nvm?tab=readme-ov-file#installing-and-updating) is recommended)
- [pnpm 9+](https://pnpm.io/installation)
- Git for version control
- A code editor ([VS Code](https://code.visualstudio.com/), [Cursor](https://cursor.com/) or [VSCodium](https://vscodium.com) recommended)
- Python (mainly for installing NPM)
- (Optional) FFmpeg (for audio/video handling)
- (Optional) [CUDA Toolkit](https://developer.nvidia.com/cuda-toolkit) (for GPU acceleration)

> On Windows? See here before continuing to make life easier: [WSL setup guide](/docs/guides/wsl)

---

## Automated Installation

1. Use https://github.com/elizaOS/eliza-starter

```bash
git clone git@github.com:elizaos/eliza-starter.git
cd eliza-starter
cp .env.example .env
pnpm i && pnpm build && pnpm start
```

2. Use the [start script](https://howieduhzit.best/start-sh/)

```bash
git clone git@github.com:elizaOS/eliza.git
cd eliza

# usage start.sh [-v|--verbose] [--skip-nvm]
./scripts/start.sh
```


3. Using Docker

Prerequisites:
- A Linux-based server (Ubuntu/Debian recommended)
- Git installed
- [Docker](https://docs.docker.com/get-started/get-docker/)

```bash
git clone git@github.com:elizaOS/eliza.git
cd eliza
docker-compose build
docker-compose up
```

> Note: If you get permission issues run the docker-compose commands with sudo or add yourself to the docker group

<details>
<summary>Troubleshooting</summary>
#### Common Error
```bash
- "characters not found": Check working directory
- `./scripts/start.sh -v` Run with logging
- Check console output
- [Open an issue](https://github.com/elizaOS/eliza/issues)
```

#### Permission Issues
```
sudo chmod +x scripts/start.sh  # Linux/macOS
Set-ExecutionPolicy RemoteSigned -Scope CurrentUser  # Windows
```

#### Package Issues
> Note: Always verify scripts before running it
```
## Linux
sudo apt update

## MacOS
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"
brew update

## Windows
# Run as admin
```

#### Node.js Issues
- Ensure Node.js 23.3.0 is installed
- Use `node -v` to check version
- Consider using [nvm](https://github.com/nvm-sh/nvm) to manage Node versions
- Use `--skip-nvm` for system Node
- Check PATH configuration

If you see Sharp-related errors, try this:

```bash
pnpm install --include=optional sharp
```

If you see errors about better-sqlite3, try `pnpm rebuild better-sqlite3` or go into `node_modules/better-sqlite3` and run `pnpm i`

You can also add a postinstall script in your `package.json` if you want to automate this:
```json
scripts: {
    "postinstall": "npm rebuild better-sqlite3"
}
```

pnpm may be bundled with a different node version, ignoring nvm. If this is the case, try:

```bash
pnpm env use --global 23.3.0
```

#### Docker issues

Some tips on cleaning your working directory before rebuilding:
- List all docker images: `sudo docker images`
- Reomove all Docker images: `docker rmi -f $(docker images -aq)`
- Remove all build cache: `docker builder prune -a -f`
- Verify cleanup: `docker system df`
</details>

---

## Manual Installation

After installing the prerequisites, clone the repository and enter the directory:

```bash
git clone git@github.com:elizaOS/eliza.git
cd eliza
```

:::tip
If you're planning on doing development, we suggest using the code on the develop branch:
```bash
git checkout develop
```

From the main repo you can also download [sample character files](https://github.com/elizaos/characters) this way:
```bash
git submodule update --init
```
:::

Install the dependencies

```bash
pnpm install
```

> **Note:** you may need to use --no-frozen-lockfile if it gives a message about the frozen lock file being out of date.

Compile the typescript:

```bash
pnpm build
```

---

## Start the Agent

[Character files](./core/characterfile.md) are where you can configure your agent's personality, lore, and capabilities via plugins. Inform eliza which character you want to run:

```bash
pnpm start --character="characters/deep-thought.character.json"
```

You can load multiple characters with a comma-separated list:

```bash
pnpm start --characters="characters/deep-thought.character.json,characters/sbf.character.json"
```

By default the agent will be accessible via the terminal and REST API.

#### Chat Client

If you're using the main [eliza repo](https://github.com/elizaos/eliza) and want to use the chat client, open a new terminal window and run the client's http server:

```bash
pnpm start:client
```

Once the client is running, you'll see a message like this:

```
➜  Local:   http://localhost:5173/
```

Simply click the link or open your browser to `http://localhost:5173/`. You'll see the chat interface connect to the system, and you can begin interacting with your character.

---

## Additional Configuration

You can load plugins or additional client support with your character file to unlock more capabilities for your agent. 

### Add Plugins and Clients

Here's how to import and register plugins in your character file:

```typescript
{
    "name": "Eliza",
    "clients": ["telegram"],
    // ... other config options
    "plugins": ["@elizaos/plugin-image"],
}
```

There are two ways to get a list of available plugins:

1. Web Interface

Go https://elizaos.github.io/registry/ or the [Showcase](/showcase) and search for plugins

2. CLI Interface

```bash
$ npx elizaos plugins list
```

Here's a sample list of plugins you can check out!

| plugin name | Description |
| ----------- | ----------- |
| [`@elizaos/plugin-llama`](https://github.com/elizaos-plugins/plugin-llama) | Run LLM models on your local machine
| [`@elizaos/client-twitter`](https://github.com/elizaos-plugins/client-twitter) | Twitter bot integration
| [`@elizaos/client-discord`](https://github.com/elizaos-plugins/client-discord) | Discord bot integration
| [`@elizaos/client-telegram`](https://github.com/elizaos-plugins/client-telegram) | Telegram integration
| [`@elizaos/plugin-image`](https://github.com/elizaos-plugins/plugin-image) | Image processing and analysis
| [`@elizaos/plugin-video`](https://github.com/elizaos-plugins/plugin-video) | Video processing capabilities
| [`@elizaos/plugin-browser`](https://github.com/elizaos-plugins/plugin-browser) | Web scraping capabilities
| [`@elizaos/plugin-pdf`](https://github.com/elizaos-plugins/plugin-pdf) | PDF processing



### Configure Environment

There are two ways to configure elizaOS

### Option 1: Default .env file

Copying the `.example.env` file and editing is the simpler option especially if you plan to just host one agent:

```bash
cp .env.example .env
nano .env
```

### Option 2: Secrets in the character file

This option allows you finer grain control over which character uses what resources and is required if you want multiple agents but using different keys. For example:


```typescript
{
  "name": "eliza",
  // ... other config options
  "settings": {
    "secrets": {
      "DISCORD_APPLICATION_ID": "1234",
      "DISCORD_API_TOKEN": "xxxx",
      "OPENAI_API_KEY": "sk-proj-xxxxxxxxx-..."
    }
  }
```

Watch the commas to make sure it's valid json! Here's a few more config tips:

<details>
<summary>Discord Bot Setup</summary>

1. Create a new application at [Discord Developer Portal](https://discord.com/developers/applications)
2. Create a bot and get your token
3. Add bot to your server using OAuth2 URL generator
4. Set `DISCORD_API_TOKEN` and `DISCORD_APPLICATION_ID` in your `.env`
</details>

<details>
<summary>Twitter Integration</summary>

Add to your `.env`:

```bash
TWITTER_USERNAME=  # Account username
TWITTER_PASSWORD=  # Account password
TWITTER_EMAIL=    # Account email
TWITTER_2FA_SECRET=    # In order to avoid X preventing the login, it is better to activate 2fa in the target account, copy the 2fa secret and paste it here
```

**Important:** Log in to the [Twitter Developer Portal](https://developer.twitter.com) and enable the "Automated" label for your account to avoid being flagged as inauthentic.
</details>

<details>
<summary>Telegram Bot</summary>

1. Create a bot
2. Add your bot token to `.env`:

```bash
TELEGRAM_BOT_TOKEN=your_token_here
```
</details>




### GPU Acceleration

If you have a Nvidia GPU you can enable CUDA support. First ensure CUDA Toolkit, cuDNN, and cuBLAS are first installed, then: `npx --no node-llama-cpp source download --gpu cuda`



---

## FAQ

### What's the difference between eliza and eliza-starter?
Eliza-starter is a lightweight version for simpler setups, while the main eliza repository includes all advanced features and a web client.

### How do I fix build/installation issues?
Use Node v23.3.0, run `pnpm clean`, then `pnpm install --no-frozen-lockfile`, followed by `pnpm build`. If issues persist, checkout the latest stable tag.

### What are the minimum system requirements?
8GB RAM recommended for build process. For deployment, a t2.large instance on AWS with 20GB storage running Ubuntu is the minimum tested configuration.

### How do I fix "Exit Status 1" errors?
If you see `triggerUncaughtException` errors, try:
1. Add dependencies to workspace root
2. Add dependencies to specific packages
3. Clean and rebuild

## Next Steps

Once you have your agent running, explore:

1. 🤖 [Understand Agents](./core/agents.md)
2. 📝 [Create Custom Characters](./core/characterfile.md)
3. ⚡ [Add Custom Actions](./core/actions.md)
4. 🔧 [Advanced Configuration](./guides/configuration.md)

Join the [Discord community](https://discord.gg/elizaOS) for support and to share what you're building!
````

## File: .env.example
````
# OpenAI Configuration
OPENAI_API_KEY=

# Anthropic Configuration
ANTHROPIC_API_KEY=

# Fill these out if you want to use Discord
DISCORD_APPLICATION_ID=
DISCORD_API_TOKEN=

# Fill these out if you want to use Postgres
POSTGRES_URL=

# Fill these out if you want to use Telegram
TELEGRAM_BOT_TOKEN=

# Fill these out if you want to use Twitter
TWITTER_USERNAME=
TWITTER_PASSWORD=
TWITTER_EMAIL=

# Fill these out if you want to use EVM
EVM_PRIVATE_KEY=
EVM_CHAINS=mainnet,sepolia,base,arbitrum,polygon
EVM_PROVIDER_URL=

# Fill these out if you want to use Solana
SOLANA_PUBLIC_KEY=
SOLANA_PRIVATE_KEY=
BIRDEYE_API_KEY=

# Local AI Configuration
USE_LOCAL_AI=
USE_STUDIOLM_TEXT_MODELS=
USE_OLLAMA_TEXT_MODELS=

# Ollama Configuration
OLLAMA_SERVER_URL=
OLLAMA_MODEL=
USE_OLLAMA_EMBEDDING=
OLLAMA_EMBEDDING_MODEL=
SMALL_OLLAMA_MODEL=
MEDIUM_OLLAMA_MODEL=
LARGE_OLLAMA_MODEL=

# StudioLM Configuration
STUDIOLM_SERVER_URL=
STUDIOLM_SMALL_MODEL=
STUDIOLM_MEDIUM_MODEL=
STUDIOLM_EMBEDDING_MODEL=

# Settings for The Org

COMMUNITY_MANAGER_DISCORD_APPLICATION_ID=
COMMUNITY_MANAGER_DISCORD_API_TOKEN=

SOCIAL_MEDIA_MANAGER_DISCORD_APPLICATION_ID=
SOCIAL_MEDIA_MANAGER_DISCORD_API_TOKEN=

LIAISON_DISCORD_APPLICATION_ID=
LIAISON_DISCORD_API_TOKEN=

PROJECT_MANAGER_DISCORD_APPLICATION_ID=
PROJECT_MANAGER_DISCORD_API_TOKEN=

DEV_REL_DISCORD_APPLICATION_ID=
DEV_REL_DISCORD_API_TOKEN=

INVESTMENT_MANAGER_DISCORD_APPLICATION_ID=
INVESTMENT_MANAGER_DISCORD_API_TOKEN=

# Settings for Investment Manager plugins
BIRDEYE_API_KEY=
JUPITER_API_KEY=
HELIUS_API_KEY=
COINMARKETCAP_API_KEY=
ZEROEX_API_KEY=
COINGECKO_API_KEY=
````

## File: package.json
````json
{
  "name": "eliza",
  "scripts": {
    "preinstall": "npx only-allow bun",
    "start": "cd ./packages/the-org && bun run start",
    "start:debug": "LOG_LEVEL=debug elizaos start",
    "start:app": "turbo run start --filter=./packages/app",
    "dev": "turbo run dev --filter=./packages/the-org",
    "build:core": "turbo run build --filter=@elizaos/core --no-cache",
    "build": "bun run build:core && turbo run build --filter=@elizaos/plugin-* --filter=@elizaos/client --no-cache && turbo run build --filter=!@elizaos/core --filter=!@elizaos/plugin-* --filter=!@elizaos/docs --no-cache",
    "clean": "rm -rf dist .turbo node_modules .turbo-tsconfig.json tsconfig.tsbuildinfo bun.lock* && turbo run clean --filter=./packages/*",
    "lint": "turbo run lint --filter=./packages/*",
    "release": "bun run build && bun lint && lerna publish --no-private --force-publish && bun lint",
    "release:alpha": "lerna publish prerelease --preid alpha --dist-tag alpha --no-private --force-publish --loglevel verbose",
    "migrate": "turbo run migrate --filter=./packages/plugin-sql --force",
    "migrate:generate": "turbo run migrate:generate --filter=./packages/plugin-sql",
    "docker:build": "bash ./scripts/docker.sh build",
    "docker:run": "bash ./scripts/docker.sh run",
    "docker:bash": "bash ./scripts/docker.sh bash",
    "docker:start": "bash ./scripts/docker.sh start",
    "docker": "bun docker:build && bun docker:run && bun docker:bash",
    "test": "turbo run test --concurrency 20 --filter=!./packages/plugin-starter --filter=!./packages/project-starter --filter=!./packages/the-org --filter=!./packages/docs --filter=!./packages/plugin-video-understanding",
    "test:app": "turbo run test --concurrency 20 --filter=./packages/app"
  },
  "devDependencies": {
    "@biomejs/biome": "^1.9.4",
    "@types/bun": "latest",
    "@types/node": "^22.13.10",
    "@vitest/eslint-plugin": "1.0.1",
    "bun": "1.2.2",
    "concurrently": "9.1.0",
    "cross-env": "7.0.3",
    "husky": "9.1.7",
    "lerna": "8.1.4",
    "only-allow": "^1.2.1",
    "sharp": "0.33.5",
    "turbo": "^2.4.4",
    "typedoc": "0.27.9",
    "typescript": "5.8.2",
    "vite": "5.4.12",
    "vitest": "3.0.5",
    "@types/uuid": "^9.0.8",
    "tsup": "8.4.0"
  },
  "bun": {
    "overrides": {
      "cookie": "0.7.0",
      "bs58": "5.0.0",
      "secp256k1": "5.0.1",
      "minipass": "7.1.2",
      "form-data": "4.0.2",
      "eslint": "9.22.0",
      "react": "19.0.0",
      "react-dom": "19.0.0",
      "got": "12.6.1"
    }
  },
  "engines": {
    "node": "23.3.0"
  },
  "dependencies": {
    "@anthropic-ai/sdk": "^0.39.0",
    "@babel/generator": "^7.26.9",
    "vittest": "^1.0.2",
    "zod": "3.24.1"
  },
  "packageManager": "bun@1.2.2",
  "workspaces": [
    "packages/*"
  ],
  "module": "index.ts",
  "type": "module",
  "resolutions": {
    "@nrwl/devkit": "19.8.13",
    "@nrwl/tao": "19.8.13",
    "zod": "3.24.1",
    "eslint": "9.22.0",
    "react": "19.0.0",
    "react-dom": "19.0.0",
    "vitest": "3.0.5",
    "@metaplex-foundation/umi": "0.9.2",
    "typedoc-plugin-markdown": "4.2.10",
    "buffer": "6.0.3",
    "@solana/spl-token": "0.4.9",
    "solana-bankrun": "0.3.1",
    "got": "12.6.1",
    "form-data": "4.0.2"
  },
  "trustedDependencies": [
    "@biomejs/biome",
    "@elizaos/plugin-browser",
    "@elizaos/plugin-pdf",
    "@elizaos/plugin-storage-s3",
    "@elizaos/plugin-video-understanding",
    "@swc/core",
    "better-sqlite3",
    "bigint-buffer",
    "bufferutil",
    "bun",
    "canvas",
    "core-js",
    "core-js-pure",
    "cpu-features",
    "es5-ext",
    "esbuild",
    "node-llama-cpp",
    "nx",
    "onnxruntime-node",
    "protobufjs",
    "sharp",
    "ssh2",
    "utf-8-validate"
  ]
}
````

## File: README.md
````markdown
# Eliza 🤖

<div align="center">
  <img src="./docs/static/img/eliza_banner.jpg" alt="Eliza Banner" width="100%" />
</div>

<div align="center">

📑 [Technical Report](https://arxiv.org/pdf/2501.06781) |  📖 [Documentation](https://elizaos.github.io/eliza/) | 🎯 [Examples](https://github.com/thejoven/awesome-eliza)

</div>

## 🌍 README Translations

[中文说明](packages/docs/i18n/readme/README_CN.md) | [日本語の説明](packages/docs/i18n/readme/README_JA.md) | [한국어 설명](packages/docs/i18n/readme/README_KOR.md) | [Persian](packages/docs/i18n/readme/README_FA.md) | [Français](packages/docs/i18n/readme/README_FR.md) | [Português](packages/docs/i18n/readme/README_PTBR.md) | [Türkçe](packages/docs/i18n/readme/README_TR.md) | [Русский](packages/docs/i18n/readme/README_RU.md) | [Español](packages/docs/i18n/readme/README_ES.md) | [Italiano](packages/docs/i18n/readme/README_IT.md) | [ไทย](packages/docs/i18n/readme/README_TH.md) | [Deutsch](packages/docs/i18n/readme/README_DE.md) | [Tiếng Việt](packages/docs/i18n/readme/README_VI.md) | [עִברִית](packages/docs/i18n/readme/README_HE.md) | [Tagalog](packages/docs/i18n/readme/README_TG.md) | [Polski](packages/docs/i18n/readme/README_PL.md) | [Arabic](packages/docs/i18n/readme/README_AR.md) | [Hungarian](packages/docs/i18n/readme/README_HU.md) | [Srpski](packages/docs/i18n/readme/README_RS.md) | [Română](packages/docs/i18n/readme/README_RO.md) | [Nederlands](packages/docs/i18n/readme/README_NL.md) | [Ελληνικά](packages/docs/i18n/readme/README_GR.md)

## 🚩 Overview

<div align="center">
  <img src="./docs/static/img/eliza_diagram.png" alt="Eliza Diagram" width="100%" />
</div>

## ✨ Features

- 🛠️ Full-featured Discord, X (Twitter) and Telegram connectors
- 🔗 Support for every model (Llama, Grok, OpenAI, Anthropic, Gemini, etc.)
- 👥 Multi-agent and room support
- 📚 Easily ingest and interact with your documents
- 💾 Retrievable memory and document store
- 🚀 Highly extensible - create your own actions and clients
- 📦 Just works!

## Video Tutorials

[AI Agent Dev School](https://www.youtube.com/watch?v=ArptLpQiKfI&list=PLx5pnFXdPTRzWla0RaOxALTSTnVq53fKL)

## 🎯 Use Cases

- 🤖 Chatbots
- 🕵️ Autonomous Agents
- 📈 Business Process Handling
- 🎮 Video Game NPCs
- 🧠 Trading

## 🚀 Quick Start

### Prerequisites

- [Python 2.7+](https://www.python.org/downloads/)
- [Node.js 23+](https://docs.npmjs.com/downloading-and-installing-node-js-and-npm)
- [bun](https://bun.sh)

> **Note for Windows Users:** [WSL 2](https://learn.microsoft.com/en-us/windows/wsl/install-manual) is required.

### Use the Starter (Recommended)

```bash
git clone https://github.com/elizaos/eliza-starter.git
cd eliza-starter
cp .env.example .env
bun i && bun run build && bun start
```

### Manually Start Eliza (Only recommended if you know what you are doing)

#### Checkout the latest release

```bash
# Clone the repository
git clone https://github.com/elizaos/eliza.git

# This project iterates fast, so we recommend checking out the latest release
git checkout $(git describe --tags --abbrev=0)
# If the above doesn't checkout the latest release, this should work:
# git checkout $(git describe --tags `git rev-list --tags --max-count=1`)
```

#### Edit the .env file

Copy .env.example to .env and fill in the appropriate values.

```
cp .env.example .env
```

Note: .env is optional. If you're planning to run multiple distinct agents, you can pass secrets through the character JSON

#### Start Eliza

Important! We now use Bun. If you are using npm, you will need to install Bun:
https://bun.sh/docs/installation

```bash
bun install
bun run build # npm will work too
bun start # npm will work too
```

### Interact via Browser

Once the agent is running, you should see the message to run "bun start:client" at the end.

Open another terminal, move to the same directory, run the command below, then follow the URL to chat with your agent.

```bash
bun start:client
```

Then read the [Documentation](https://elizaos.github.io/eliza/) to learn how to customize your Eliza.

---

### Automatically Start Eliza

The start script provides an automated way to set up and run Eliza:

```bash
sh scripts/start.sh
```

For detailed instructions on using the start script, including character management and troubleshooting, see our [Start Script Guide](./docs/docs/guides/start-script.md).

> **Note**: The start script handles all dependencies, environment setup, and character management automatically.

---

### Modify Character

1. Open `packages/core/src/defaultCharacter.ts` to modify the default character. Uncomment and edit.

2. To load custom characters:
    - Use `bun start --characters="path/to/your/character.json"`
    - Multiple character files can be loaded simultaneously
3. Connect with X (Twitter)
    - change `"clients": []` to `"clients": ["twitter"]` in the character file to connect with X

---

#### Additional Requirements

You may need to install Sharp. If you see an error when starting up, try installing it with the following command:

```
bun install --include=optional sharp
```
---

### Deploy Eliza in one click 

Use [Fleek](https://fleek.xyz/eliza/) to deploy Eliza in one click. This opens Eliza to non-developers and provides the following options to build your agent:
1. Start with a template
2. Build characterfile from scratch
3. Upload pre-made characterfile

Click [here](https://fleek.xyz/eliza/) to get started!

---

### Community & contact

- [GitHub Issues](https://github.com/elizaos/eliza/issues). Best for: bugs you encounter using Eliza, and feature proposals.
- [Discord](https://discord.gg/ai16z). Best for: sharing your applications and hanging out with the community.

## Citation

We now have a [paper](https://arxiv.org/pdf/2501.06781) you can cite for the Eliza OS:
```bibtex
@article{walters2025eliza,
  title={Eliza: A Web3 friendly AI Agent Operating System},
  author={Walters, Shaw and Gao, Sam and Nerd, Shakker and Da, Feng and Williams, Warren and Meng, Ting-Chien and Han, Hunter and He, Frank and Zhang, Allen and Wu, Ming and others},
  journal={arXiv preprint arXiv:2501.06781},
  year={2025}
}
```

## Contributors

<a href="https://github.com/elizaos/eliza/graphs/contributors">
  <img src="https://contrib.rocks/image?repo=elizaos/eliza" alt="Eliza project contributors" />
</a>


## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=elizaos/eliza&type=Date)](https://star-history.com/#elizaos/eliza&Date)
````


# Instruction
# ElizaOS Developer Context

This file contains the core technical aspects of ElizaOS, focusing on its architecture, implementation, and developer-facing components. The codebase is organized as a monorepo with several key packages:

## Key Components

1. **Core Package**: The foundation of ElizaOS with the agent runtime, entity management, actions, and database interactions
2. **CLI Package**: Command-line interface for managing agents, projects, and development tasks
3. **Client Package**: Frontend interface components and API interactions
4. **SQL/Database**: Database adapters and schema management
5. **Autodoc**: Documentation generation tools

## Technical Goals

When analyzing this codebase:

- Focus on the architecture and relationships between components
- Identify core abstractions and design patterns
- Understand the runtime execution flow
- Analyze how agents, actions, and providers work together
- Look for opportunities to improve code organization and performance
- Consider modular extension points and plugin architecture

## Output Guidance

- When suggesting improvements, focus on technical aspects like code structure, performance optimizations, and architectural changes
- Include specific code examples when proposing changes
- Consider backwards compatibility and migration paths for any proposed changes
- Highlight innovative technical approaches used in the system
- When asked about implementation details, provide comprehensive technical explanations
