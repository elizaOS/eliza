#!/usr/bin/env bun
/**
 * Standalone test script for embed processing
 * Tests against a real Farcaster cast: https://farcaster.xyz/darrylyeo/0x1872c6d4
 * 
 * Run with: bun run scripts/test-embed-processing.ts
 */

import { NeynarAPIClient } from '@neynar/nodejs-sdk';
import { EmbedManager, isEmbedUrl, isEmbedCast } from '../src/managers/embedManager';
import type { IAgentRuntime } from '@elizaos/core';

// Test cast URL - Neynar can lookup by URL directly
const TEST_CAST_URL = 'https://warpcast.com/darrylyeo/0x1872c6d4';

// Check if we should use real vision model
const USE_REAL_VISION = process.env.USE_REAL_VISION === 'true';
const OPENAI_API_KEY = process.env.OPENAI_API_KEY;

// Create a mock or real runtime for testing
function createMockRuntime(): IAgentRuntime {
  return {
    agentId: 'test-agent-id',
    logger: {
      debug: (obj: any, msg?: string) => console.log('[DEBUG]', msg || '', typeof obj === 'object' ? JSON.stringify(obj) : obj),
      info: (obj: any, msg?: string) => console.log('[INFO]', msg || '', typeof obj === 'object' ? JSON.stringify(obj) : obj),
      warn: (obj: any, msg?: string) => console.warn('[WARN]', msg || '', typeof obj === 'object' ? JSON.stringify(obj) : obj),
      error: (obj: any, msg?: string) => console.error('[ERROR]', msg || '', typeof obj === 'object' ? JSON.stringify(obj) : obj),
    },
    useModel: async (modelType: string, input: any) => {
      const url = typeof input === 'string' ? input : input?.url;
      
      // Use real OpenAI Vision if configured
      if (USE_REAL_VISION && OPENAI_API_KEY && (modelType === 'IMAGE_DESCRIPTION' || modelType === 'image_description')) {
        console.log(`[REAL] Calling OpenAI Vision for: ${url}`);
        try {
          const response = await fetch('https://api.openai.com/v1/chat/completions', {
            method: 'POST',
            headers: {
              'Content-Type': 'application/json',
              'Authorization': `Bearer ${OPENAI_API_KEY}`,
            },
            body: JSON.stringify({
              model: 'gpt-4o-mini',
              messages: [
                {
                  role: 'user',
                  content: [
                    { type: 'text', text: 'Describe this image concisely. Provide a title and description. Format: Title: [title]\nDescription: [description]' },
                    { type: 'image_url', image_url: { url } },
                  ],
                },
              ],
              max_tokens: 300,
            }),
          });
          
          const data = await response.json() as any;
          const content = data.choices?.[0]?.message?.content || '';
          
          // Parse response
          const titleMatch = content.match(/Title:\s*(.+?)(?:\n|$)/i);
          const descMatch = content.match(/Description:\s*(.+)/is);
          
          return {
            title: titleMatch?.[1]?.trim() || 'Image',
            description: descMatch?.[1]?.trim() || content.trim(),
          };
        } catch (error) {
          console.error('[REAL] Vision API error:', error);
          // Fall through to mock
        }
      }
      
      // Mock image description response
      console.log(`[MOCK] useModel called with ${modelType}`);
      if (modelType === 'IMAGE_DESCRIPTION' || modelType === 'image_description') {
        console.log(`[MOCK] Describing image: ${url}`);
        return {
          title: 'Image from Cast',
          description: `This is a mock description for the image. In production, this would be generated by a vision model analyzing the image at ${url}`,
        };
      }
      return null;
    },
  } as unknown as IAgentRuntime;
}

async function main() {
  console.log('üöÄ Embed Processing Test');
  console.log('========================\n');

  // Get API key from environment
  const apiKey = process.env.FARCASTER_NEYNAR_API_KEY || process.env.NEYNAR_API_KEY;
  
  if (!apiKey) {
    console.error('‚ùå Error: No NEYNAR_API_KEY found in environment');
    console.log('\nPlease set FARCASTER_NEYNAR_API_KEY or NEYNAR_API_KEY environment variable');
    console.log('Example: NEYNAR_API_KEY=your-key bun run scripts/test-embed-processing.ts');
    process.exit(1);
  }

  console.log('‚úÖ API key found');
  
  if (USE_REAL_VISION && OPENAI_API_KEY) {
    console.log('ü§ñ Using REAL OpenAI Vision (gpt-4o-mini)\n');
  } else {
    console.log('üé≠ Using MOCK vision (set USE_REAL_VISION=true and OPENAI_API_KEY to use real)\n');
  }

  // Initialize clients
  const neynarClient = new NeynarAPIClient({ apiKey });
  const mockRuntime = createMockRuntime();
  const embedManager = new EmbedManager(mockRuntime);

  try {
    console.log(`üì° Fetching cast by URL...`);
    console.log(`   URL: ${TEST_CAST_URL}\n`);
    
    // Fetch the cast from Neynar using URL lookup
    const response = await neynarClient.lookupCastByHashOrUrl({
      identifier: TEST_CAST_URL,
      type: 'url',
    });

    const cast = response.cast;
    
    console.log('üìã Cast Details:');
    console.log('‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ');
    console.log(`   Author: @${cast.author.username} (FID: ${cast.author.fid})`);
    console.log(`   Display Name: ${cast.author.display_name}`);
    console.log(`   Text: "${cast.text}"`);
    console.log(`   Hash: ${cast.hash}`);
    console.log(`   Timestamp: ${cast.timestamp}`);
    console.log(`   Reactions: ${cast.reactions?.likes_count || 0} likes, ${cast.reactions?.recasts_count || 0} recasts`);
    console.log(`   Replies: ${cast.replies?.count || 0}`);
    console.log(`   Embeds count: ${cast.embeds?.length || 0}`);

    // Check if cast has embeds
    if (!cast.embeds || cast.embeds.length === 0) {
      console.log('\n‚ö†Ô∏è  Cast has no embeds to process');
      return;
    }

    console.log('\nüîç Raw Embeds from Neynar API:');
    console.log('‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ');
    
    cast.embeds.forEach((embed, index) => {
      console.log(`\n   Embed #${index + 1}:`);
      
      if (isEmbedUrl(embed)) {
        console.log(`   üìé Type: URL Embed`);
        console.log(`   üîó URL: ${embed.url}`);
        
        if (embed.metadata) {
          console.log(`   üìÑ Status: ${embed.metadata._status}`);
          console.log(`   üì¶ Content-Type: ${embed.metadata.content_type || 'unknown'}`);
          console.log(`   üìè Content-Length: ${embed.metadata.content_length || 'unknown'} bytes`);
          
          if (embed.metadata.image) {
            console.log(`   üñºÔ∏è  Image Dimensions: ${embed.metadata.image.width_px || '?'}x${embed.metadata.image.height_px || '?'} px`);
          }
          
          if (embed.metadata.video) {
            console.log(`   üé¨ Video Duration: ${embed.metadata.video.duration_s || '?'}s`);
            if (embed.metadata.video.stream) {
              console.log(`   üì∫ Video Streams: ${embed.metadata.video.stream.length}`);
            }
          }
          
          if (embed.metadata.html) {
            console.log(`   üåê HTML Metadata:`);
            console.log(`      Title: ${embed.metadata.html.ogTitle || 'none'}`);
            console.log(`      Site: ${embed.metadata.html.ogSiteName || 'none'}`);
            console.log(`      Description: ${embed.metadata.html.ogDescription?.substring(0, 80) || 'none'}${(embed.metadata.html.ogDescription?.length || 0) > 80 ? '...' : ''}`);
          }
          
          if (embed.metadata.frame) {
            console.log(`   üéØ Frame: ${embed.metadata.frame.title || 'untitled'}`);
            console.log(`      Version: ${embed.metadata.frame.version || 'unknown'}`);
          }
        } else {
          console.log(`   ‚ö†Ô∏è  No metadata available`);
        }
      } else if (isEmbedCast(embed)) {
        console.log(`   üí¨ Type: Embedded Cast (Quote)`);
        console.log(`   üîñ Quoted Hash: ${embed.cast?.hash}`);
        console.log(`   üë§ Quoted Author: @${embed.cast?.author?.username}`);
        console.log(`   üìù Quoted Text: "${embed.cast?.text?.substring(0, 80)}${(embed.cast?.text?.length || 0) > 80 ? '...' : ''}"`);
      } else {
        console.log(`   ‚ùì Type: Unknown`);
        console.log(`   Raw:`, JSON.stringify(embed, null, 2));
      }
    });

    // Process embeds with EmbedManager
    console.log('\n\nüîÑ Processing embeds with EmbedManager...');
    console.log('‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ');
    
    const processedMedia = await embedManager.processEmbeds(cast.embeds);

    console.log(`\n‚úÖ Successfully processed ${processedMedia.length} media item(s):\n`);
    
    processedMedia.forEach((media, index) => {
      console.log(`   Media #${index + 1}:`);
      console.log(`   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ`);
      console.log(`   ID: ${media.id}`);
      console.log(`   URL: ${media.url}`);
      console.log(`   Title: ${media.title}`);
      console.log(`   Source: ${media.source}`);
      console.log(`   Description: ${media.description?.substring(0, 120)}${(media.description?.length || 0) > 120 ? '...' : ''}`);
      if (media.text && media.text !== media.description) {
        console.log(`   Text: ${media.text?.substring(0, 120)}${(media.text?.length || 0) > 120 ? '...' : ''}`);
      }
      console.log('');
    });

    // Summary
    console.log('\nüìä Summary:');
    console.log('‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ');
    console.log(`   Total embeds in cast: ${cast.embeds.length}`);
    console.log(`   Successfully processed: ${processedMedia.length}`);
    
    const embedTypes = processedMedia.reduce((acc, m) => {
      const type = m.source || 'unknown';
      acc[type] = (acc[type] || 0) + 1;
      return acc;
    }, {} as Record<string, number>);
    
    console.log(`   By type:`, embedTypes);
    
    console.log('\n‚úÖ Test completed successfully!');

  } catch (error) {
    console.error('\n‚ùå Error:', error);
    process.exit(1);
  }
}

main();

