Eliza has limited ability to plan actions and call them one-by-one, but it's hard for them to pass state to each other. They don't plan particularly well, and it's not nearly as useful as it could be.

One approach would be to create a workflow and consider something like Naten. We have a Naten workflow creator. We could do something like wrap all of our actions and providers in Naten nodes, which are kinds of inputs and outputs. We could also enable services to have inputs and outputs, especially with different service types, which could be standardized. Plugins could also provide those or have those obviously wrapped if they defined what the input and output schema would be.

Another approach is to augment our existing action processing and planning system in the bootstrap so that we can do this much more effectively.

One thing that we could do is, instead of just having actions happen one-by-one, we could have them return states, which they can then pass to the next action through the processActions function. And then they can have a previous actions input into the state. So that if we want actions which are able to take previous actions and the output of previous actions, they can then route them.

However, it's pretty clear that we might need a DAG for some things, and other things could be handled entirely just by providers which provide information and can then be selected dynamically. And actions which can output in evaluators, like that's kinda the thinking. And actions don't have to be individual tool calls, they can be whole workflows that do detailed information. We also have the ability to create new actions on the fly, create new workflows. Create new plug-ins. So we should consider exactly how we want to best handle this.

We can make the strategy plugin handle its own actions to strategize. Then it can use a large model to intelligently build and validate a strategy and call the actions one-by-one. It could even take the outputs of the actions and pipe them into the next actions. If we wanted to add that context or add a provider, we could also add a previous action state provider, which we can then just add the action state into. That's probably the easiest way since that doesn't need to be dynamic.

Yeah, I like that. Let's create a previous action state provider, and then every action can add to that. Now, by just returning, if the actions return state, that will get added to the pile of returned state. We'll need to define what an action state return looks like, and for backwards compatibility, it should be nullable. If it returns nothing, the action returns no state, but we should probably have a warning in that case that the action did not return anything, so no state was added.

State provider can then be accessed by other actions if they want because the actions can return something similar to a provider, which is a combination of data and text.

The strategy plugin can allow us to run a more complex strategy with validation, or we could just think about the main response handler doing that. Typically, we've been doing the response handler with a smaller, less intelligent model, and I think for planning we probably want the most intelligent model. We need to think about our plan and how we're going to do it.

I think that we could probably also think of the plan as being the thing that initiates the autocoder, and the auto-nation is like "well, if this is something we can do with the Natan workflow, then we can go try to do that and see if we can compose that with confidence." If it's something we can do with the auto-coder, we can do that. If it's something we can just do with the actions we have, then we'll do that, of course.

The other thing that we can probably do with the auto-coder and add is: the ability to individually create actions, providers, evaluators, and services and then load them at runtime so that they're running. We could also probably consider creating event handlers and registering event handlers at runtime as well if we'd like, so we can add triggers and stuff like that.

So actionably, let's think about what we need to do: - We should have actions able to return an object which will go into Provider state. - We should add a previous ActionResult provider which will show the previous states of any actions that had run in this current run, any information that needed to be injected down. - We will review how we're doing action planning and make sure that we are successfully action planning and chaining actions. - We need to add message examples which demonstrate how actions can be chained realistically. We need both real and imagined actions in our examples so that we don't bias but we can indicate how this can work. In many of our default plug-in actions, we might need to consider having multiple actions in our action example responses or multiple different actions planned in a row for those message examples.

We will also augment the strategy plugin and add detailed tests for that, Ensuring that we can call the auto-coder to create a new plugin, action, service, or provider. We can call the natin to create a provider or action workflow. We can just call the available actions that we have and chain them to get our output. Or we can determine that what the user is asking for is not possible currently. The strategy action should also check our registry through the plugin manager to ensure that if maybe we could solve this problem with another available plugin that we don't have installed, so we should also delineate between the installed available stuff and the stuff that we could go get. Then we can return to the user, "Hey, based on which of these possible strategies is best for you to execute your goal, if we're confident we can just move on to the next step of that and start doing it. If we're not confident we can ask for feedback."

We need to create a lot of different approaches here: - Different things that we're asking for different scenarios (edge cases, failure cases, success cases) - nearly impossible stuff (extremely simple stuff) We need to make sure that our strategy planner and our action planning in the core are able to account for all of the different conditions for all of the different requirements/requests that users have correctly and smoothly. By setting all of this up with tests, we can start to improve and benchmark it over time by making sure the agent is able to do more and more stuff, and we can start to identify what went wrong or what we needed in order to improve what we have.

Okay again, so actionably, one, review the action handling and let's make sure that we have sufficient tests to test planning of actions. Two, we should have actions able to return an object which will go into Provider state. - We should add a previous ActionResult provider which will show the previous states of any actions that had run in this current run, any information that needed to be injected down. - We will review how we're doing action planning and make sure that we are successfully action planning and chaining actions. - We need to add message examples which demonstrate how actions can be chained realistically. We need both real and imagined actions in our examples so that we don't bias but we can indicate how this can work.

Autonomous agents that can flexibly pass data around from anywhere to anywhere - from one action to another or one state to the next. This is really complicated, so we really need to go through our core, identify the code, look at all the different pathways and how the code actually works, and then see what do we need to do to enable this flexible autonomous agent.

Let's build a PhD-level report identifying the limitations of ELIZA OS today and then how we get to the autonomous agent that is truly superintelligent, flexible, AGI-level capability. We'll get down to actual real implementation plan step-by-step: - The primitives that we need - anything that we're missing and we need to build - All of the dependencies that we need to make sure are in place - All of this high-level stuff that enables this We need to go file-by-file like what needs to be implemented, change added, test-by-test like what we need to test for, scenario-by-scenario like what scenarios we want to account for and build tests to ensure actually work. Then end state like what do we want this thing to actually work look like and do. Like what needs to really be modified. So give me a detailed PhD thesis level report that should be at least five pages containing all of this information in extreme detail so that a professional high-end a PhD level computer science major an engineer could implement this system successfully.
