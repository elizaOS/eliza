{
  "total_tasks": 8,
  "total_trials": 8,
  "passed_tasks": 7,
  "failed_tasks": 1,
  "overall_success_rate": 0.875,
  "overall_tool_accuracy": 0.4166666666666667,
  "overall_policy_compliance": 1.0,
  "overall_response_quality": 0.40377143398096776,
  "average_duration_ms": 33783.37198495865,
  "pass_k_metrics": {
    "1": {
      "k": 1,
      "pass_rate": 0.875,
      "trials_passed": 7
    },
    "2": {
      "k": 2,
      "pass_rate": 0.0,
      "trials_passed": 0
    },
    "4": {
      "k": 4,
      "pass_rate": 0.0,
      "trials_passed": 0
    },
    "8": {
      "k": 8,
      "pass_rate": 0.0,
      "trials_passed": 0
    }
  },
  "overall_metrics": {
    "total_tokens": 0,
    "average_tokens_per_task": 0.0,
    "average_turns_per_task": 1.875,
    "average_tool_calls_per_task": 0.875,
    "total_duration_seconds": 270.2712149620056,
    "memory_peak_mb": 12.621877670288086,
    "memory_average_mb": 12.399750709533691
  },
  "comparison_to_leaderboard": {
    "best_comparable_model": "gemini-3-pro",
    "difference_from_best": -0.03200000000000003,
    "comparison_details": {
      "gemini-3-pro": -0.03200000000000003,
      "claude-3.7-sonnet": 0.06299999999999994,
      "kimi-k2": 0.132,
      "o3": 0.136,
      "o4-mini": 0.15700000000000003,
      "gpt-4o": 0.39,
      "gpt-4-turbo": 0.454,
      "claude-3-opus": 0.363,
      "llama-3.1-70b": 0.493
    }
  },
  "summary": {
    "status": "success",
    "key_findings": [
      "Strong overall performance on Tau-bench tasks"
    ],
    "strengths": [
      "High task completion rate",
      "Strong policy compliance",
      "Strong performance in retail domain"
    ],
    "weaknesses": [
      "Tool selection needs improvement"
    ],
    "recommendations": [
      "Improve parameter extraction from context"
    ],
    "timestamp": "2026-01-12T00:21:38.849573"
  }
}