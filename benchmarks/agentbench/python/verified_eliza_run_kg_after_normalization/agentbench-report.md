# AgentBench Evaluation Results - ElizaOS Python

## Executive Summary

- **Status**: NEEDS_IMPROVEMENT
- **Overall Success Rate**: 0.0%
- **Total Tasks**: 1 (0 passed, 1 failed)
- **Average Duration**: 10215ms per task

### Key Findings

- ElizaOS agent capabilities need significant improvement
- Needs improvement in: knowledge_graph
- Note: baseline scores are published AgentBench results; comparisons are reference-only unless you run the official AgentBench task set.

### Recommendations

- Enhance knowledge_graph environment handling capabilities

## Environment Breakdown

| Environment | Success Rate | Tasks | Avg Steps | Avg Duration |
|-------------|-------------|-------|-----------|--------------|
| knowledge_graph | 0.0% | 1 | 10.0 | 10215ms |

## Comparison with Published Baselines

### vs GPT-4

| Environment | ElizaOS | GPT-4 | Difference |
|-------------|---------|-------|------------|
| knowledge_graph | 0.0% | 58.4% | -58.4% |

### vs GPT-3.5

| Environment | ElizaOS | GPT-3.5 | Difference |
|-------------|---------|---------|------------|
| knowledge_graph | 0.0% | 16.4% | -16.4% |

## Resource Usage

- **Peak Memory**: 3.9MB
- **Average Memory**: 3.9MB
- **Average Tokens per Task**: 0

---
*Generated on 2026-01-12T00:56:41.734067*
*Benchmark: AgentBench (ICLR 2024)*
*Framework: ElizaOS Python*
