# AgentBench Evaluation Results - ElizaOS Python

## Executive Summary

- **Status**: STRONG
- **Overall Success Rate**: 100.0%
- **Total Tasks**: 1 (1 passed, 0 failed)
- **Average Duration**: 7298ms per task

### Key Findings

- ElizaOS demonstrates strong agent capabilities across tested environments
- Strong performance in: knowledge_graph
- Higher success rate than published GPT-4 baseline (reference) in: knowledge_graph
- Note: baseline scores are published AgentBench results; comparisons are reference-only unless you run the official AgentBench task set.

### Recommendations


## Environment Breakdown

| Environment | Success Rate | Tasks | Avg Steps | Avg Duration |
|-------------|-------------|-------|-----------|--------------|
| knowledge_graph | 100.0% | 1 | 6.0 | 7298ms |

## Comparison with Published Baselines

### vs GPT-4

| Environment | ElizaOS | GPT-4 | Difference |
|-------------|---------|-------|------------|
| knowledge_graph | 100.0% | 58.4% | +41.6% |

### vs GPT-3.5

| Environment | ElizaOS | GPT-3.5 | Difference |
|-------------|---------|---------|------------|
| knowledge_graph | 100.0% | 16.4% | +83.6% |

## Resource Usage

- **Peak Memory**: 3.9MB
- **Average Memory**: 3.8MB
- **Average Tokens per Task**: 0

---
*Generated on 2026-01-12T00:59:04.466350*
*Benchmark: AgentBench (ICLR 2024)*
*Framework: ElizaOS Python*
