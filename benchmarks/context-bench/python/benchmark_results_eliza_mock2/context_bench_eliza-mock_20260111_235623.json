{
  "overall_accuracy": 0.9166666666666666,
  "total_tasks": 12,
  "passed_tasks": 11,
  "failed_tasks": 1,
  "avg_semantic_similarity": 0.9224137931034483,
  "lost_in_middle_score": 0.25,
  "context_degradation_rate": -0.08333333333333331,
  "avg_latency_ms": 0.7321834564208984,
  "total_duration_ms": 37.74595260620117,
  "position_heatmap": [
    [
      1.0,
      1.0
    ],
    [
      0.5,
      1.0
    ],
    [
      1.0,
      1.0
    ]
  ],
  "position_heatmap_lengths": [
    1024,
    4096
  ],
  "position_heatmap_positions": [
    "start",
    "middle",
    "end"
  ],
  "position_accuracies": {
    "start": {
      "accuracy": 1.0,
      "total_tasks": 4
    },
    "middle": {
      "accuracy": 0.75,
      "total_tasks": 4
    },
    "end": {
      "accuracy": 1.0,
      "total_tasks": 4
    }
  },
  "length_accuracies": {
    "1024": {
      "accuracy": 0.8333333333333334,
      "total_tasks": 6
    },
    "4096": {
      "accuracy": 1.0,
      "total_tasks": 6
    }
  },
  "multi_hop_success_rates": {},
  "comparison_to_leaderboard": {
    "gpt-4-turbo": {
      "overall_diff": 0.006666666666666599,
      "lost_in_middle_diff": -0.13,
      "niah_4k_diff": 0.020000000000000018
    },
    "gpt-4o": {
      "overall_diff": -0.023333333333333317,
      "lost_in_middle_diff": -0.16999999999999998,
      "niah_4k_diff": 0.010000000000000009
    },
    "claude-3-opus": {
      "overall_diff": -0.033333333333333326,
      "lost_in_middle_diff": -0.2,
      "niah_4k_diff": 0.010000000000000009
    },
    "claude-3-sonnet": {
      "overall_diff": 0.036666666666666625,
      "lost_in_middle_diff": -0.1,
      "niah_4k_diff": 0.020000000000000018
    },
    "llama-3.1-70b": {
      "overall_diff": 0.11666666666666659,
      "lost_in_middle_diff": -0.03,
      "niah_4k_diff": 0.050000000000000044
    },
    "mistral-large": {
      "overall_diff": 0.15666666666666662,
      "lost_in_middle_diff": 0.0,
      "niah_4k_diff": 0.06000000000000005
    }
  },
  "summary": {
    "status": "excellent",
    "overall_accuracy": "91.7%",
    "findings": [
      "Good overall retrieval accuracy (85-95%)",
      "Significant 'lost in middle' effect detected (25.0% drop)",
      "Performance within 10% of Claude-3-Opus (-3.3%)"
    ],
    "recommendations": [
      "Consider chunking strategies or retrieval augmentation for middle content"
    ]
  },
  "metadata": {
    "timestamp": "2026-01-11T23:56:23.416934",
    "seed": 42,
    "total_duration_ms": 37.74595260620117
  }
}