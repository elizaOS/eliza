{
  "overall_accuracy": 0.3923076923076923,
  "total_tasks": 130,
  "passed_tasks": 51,
  "failed_tasks": 79,
  "avg_semantic_similarity": 0.5307505405804223,
  "lost_in_middle_score": 0.0,
  "context_degradation_rate": 0.009615384615384609,
  "avg_latency_ms": 2.709654661325308,
  "total_duration_ms": 2435.1489543914795,
  "position_heatmap": [
    [
      0.5,
      0.75,
      0.25,
      0.5,
      0.5
    ],
    [
      0.5,
      0.75,
      0.75,
      0.25,
      0.5
    ],
    [
      0.25,
      0.25,
      1.0,
      0.75,
      0.5
    ],
    [
      0.75,
      0.25,
      0.5,
      0.25,
      0.75
    ],
    [
      0.75,
      0.5,
      0.25,
      0.5,
      0.25
    ],
    [
      0.0,
      0.0,
      0.0,
      0.0,
      0.0
    ]
  ],
  "position_heatmap_lengths": [
    1024,
    2048,
    4096,
    8192,
    16384
  ],
  "position_heatmap_positions": [
    "start",
    "early",
    "middle",
    "late",
    "end",
    "random"
  ],
  "position_accuracies": {
    "start": {
      "accuracy": 0.5,
      "total_tasks": 20
    },
    "early": {
      "accuracy": 0.55,
      "total_tasks": 20
    },
    "middle": {
      "accuracy": 0.55,
      "total_tasks": 20
    },
    "late": {
      "accuracy": 0.5,
      "total_tasks": 20
    },
    "end": {
      "accuracy": 0.45,
      "total_tasks": 20
    },
    "random": {
      "accuracy": 0.0,
      "total_tasks": 30
    }
  },
  "length_accuracies": {
    "1024": {
      "accuracy": 0.4230769230769231,
      "total_tasks": 26
    },
    "2048": {
      "accuracy": 0.38461538461538464,
      "total_tasks": 26
    },
    "4096": {
      "accuracy": 0.4230769230769231,
      "total_tasks": 26
    },
    "8192": {
      "accuracy": 0.34615384615384615,
      "total_tasks": 26
    },
    "16384": {
      "accuracy": 0.38461538461538464,
      "total_tasks": 26
    }
  },
  "multi_hop_success_rates": {
    "2": 0.0,
    "3": 0.0
  },
  "comparison_to_leaderboard": {
    "gpt-4-turbo": {
      "overall_diff": -0.5176923076923077,
      "lost_in_middle_diff": 0.12,
      "niah_4k_diff": -0.5569230769230769,
      "niah_8k_diff": -0.6238461538461538,
      "niah_16k_diff": -0.5653846153846154,
      "multi_hop_2_diff": -0.88,
      "multi_hop_3_diff": -0.72
    },
    "gpt-4o": {
      "overall_diff": -0.5476923076923077,
      "lost_in_middle_diff": 0.08,
      "niah_4k_diff": -0.5669230769230769,
      "niah_8k_diff": -0.6338461538461538,
      "niah_16k_diff": -0.5853846153846154,
      "multi_hop_2_diff": -0.91,
      "multi_hop_3_diff": -0.78
    },
    "claude-3-opus": {
      "overall_diff": -0.5576923076923077,
      "lost_in_middle_diff": 0.05,
      "niah_4k_diff": -0.5669230769230769,
      "niah_8k_diff": -0.6338461538461538,
      "niah_16k_diff": -0.5853846153846154,
      "multi_hop_2_diff": -0.92,
      "multi_hop_3_diff": -0.81
    },
    "claude-3-sonnet": {
      "overall_diff": -0.4876923076923077,
      "lost_in_middle_diff": 0.15,
      "niah_4k_diff": -0.5569230769230769,
      "niah_8k_diff": -0.6138461538461538,
      "niah_16k_diff": -0.5553846153846154,
      "multi_hop_2_diff": -0.85,
      "multi_hop_3_diff": -0.68
    },
    "llama-3.1-70b": {
      "overall_diff": -0.40769230769230774,
      "lost_in_middle_diff": 0.22,
      "niah_4k_diff": -0.5269230769230768,
      "niah_8k_diff": -0.5738461538461539,
      "niah_16k_diff": -0.49538461538461537,
      "multi_hop_2_diff": -0.78,
      "multi_hop_3_diff": -0.55
    },
    "mistral-large": {
      "overall_diff": -0.3676923076923077,
      "lost_in_middle_diff": 0.25,
      "niah_4k_diff": -0.5169230769230768,
      "niah_8k_diff": -0.5538461538461539,
      "niah_16k_diff": -0.46538461538461534,
      "multi_hop_2_diff": -0.75,
      "multi_hop_3_diff": -0.52
    }
  },
  "summary": {
    "status": "needs_improvement",
    "overall_accuracy": "39.2%",
    "findings": [
      "Low retrieval accuracy (<70%)",
      "Struggles with 2-hop reasoning (0.0% success)",
      "Struggles with 3-hop reasoning (0.0% success)",
      "Performance below Claude-3-Opus (-55.8%)"
    ],
    "recommendations": [
      "Consider using a model with better context handling",
      "Consider chain-of-thought prompting for 2+ hop questions",
      "Consider chain-of-thought prompting for 3+ hop questions"
    ]
  },
  "metadata": {
    "timestamp": "2026-01-12T00:34:05.433775",
    "seed": 42,
    "total_duration_ms": 2435.1489543914795
  }
}