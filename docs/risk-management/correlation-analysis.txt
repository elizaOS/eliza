# Correlation Analysis

## Introduction

Correlation analysis is the hidden compass of DeFi portfolio construction, revealing which assets will sink together when markets turn violent and which might provide genuine diversification benefits. In traditional finance, correlations between assets are relatively stable; in DeFi, they're as volatile as the assets themselves, shifting dramatically during market stress when diversification is needed most. Understanding correlation dynamics enables sophisticated portfolio construction that can weather both the bull market euphoria and bear market bloodbaths that define crypto cycles. For Levva's strategies, correlation analysis determines optimal asset allocation across Diversified DeFi Yield approaches and guides risk management for Custom strategies.

## Key Concepts, Ideas, and Formulas

### Statistical Foundation

**Pearson Correlation Coefficient:**
```
ρ(X,Y) = Cov(X,Y) / (σ_X × σ_Y)
```

**Sample Correlation:**
```
r = Σ((x_i - x̄)(y_i - ȳ)) / √(Σ(x_i - x̄)² × Σ(y_i - ȳ)²)
```

**Rolling Correlation (Time-Varying):**
```python
def rolling_correlation(returns1, returns2, window=30):
    return returns1.rolling(window).corr(returns2)
```

### DeFi-Specific Correlation Models

**Regime-Dependent Correlation:**
```python
def regime_correlation(returns1, returns2, volatility_threshold=0.02):
    combined_returns = pd.concat([returns1, returns2], axis=1)
    combined_vol = combined_returns.rolling(7).std().mean(axis=1)
    
    high_vol_mask = combined_vol > volatility_threshold
    low_vol_mask = ~high_vol_mask
    
    return {
        'low_volatility': returns1[low_vol_mask].corr(returns2[low_vol_mask]),
        'high_volatility': returns1[high_vol_mask].corr(returns2[high_vol_mask])
    }
```

**Exponentially Weighted Moving Average (EWMA) Correlation:**
```python
def ewma_correlation(returns1, returns2, lambda_decay=0.94):
    # More recent observations get higher weights
    weights = np.array([(1-lambda_decay) * lambda_decay**i 
                       for i in range(len(returns1))][::-1])
    weights = weights / weights.sum()
    
    mean1 = np.average(returns1, weights=weights)
    mean2 = np.average(returns2, weights=weights)
    
    cov = np.average((returns1 - mean1) * (returns2 - mean2), weights=weights)
    var1 = np.average((returns1 - mean1)**2, weights=weights)
    var2 = np.average((returns2 - mean2)**2, weights=weights)
    
    return cov / np.sqrt(var1 * var2)
```

### Advanced Correlation Metrics

**Tail Correlation (Copula-Based):**
```python
def tail_correlation(returns1, returns2, quantile=0.05):
    # Correlation during extreme negative events
    threshold1 = returns1.quantile(quantile)
    threshold2 = returns2.quantile(quantile)
    
    extreme_mask = (returns1 <= threshold1) | (returns2 <= threshold2)
    
    if extreme_mask.sum() > 10:  # Ensure sufficient observations
        return returns1[extreme_mask].corr(returns2[extreme_mask])
    else:
        return np.nan
```

**Dynamic Conditional Correlation (DCC):**
```python
from arch import arch_model

def dcc_correlation(returns1, returns2):
    # Fit GARCH models to each series
    garch1 = arch_model(returns1, vol='Garch', p=1, q=1)
    garch2 = arch_model(returns2, vol='Garch', p=1, q=1)
    
    res1 = garch1.fit(disp='off')
    res2 = garch2.fit(disp='off')
    
    # Standardized residuals
    std_resid1 = res1.resid / res1.conditional_volatility
    std_resid2 = res2.resid / res2.conditional_volatility
    
    # DCC model (simplified implementation)
    return calculate_dcc(std_resid1, std_resid2)
```

## Examples and Applications

### Scenario 1: Diversified DeFi Yield Portfolio

**Assets Under Analysis:**
- Aave USDC lending
- Lido stETH staking  
- Curve 3pool LP
- Compound DAI lending

**Correlation Matrix Analysis:**
```python
import pandas as pd
import numpy as np

# Historical daily returns (example data)
returns_data = {
    'aave_usdc': [0.0001, 0.0002, -0.0001, 0.0003, ...],
    'lido_steth': [0.002, -0.005, 0.008, -0.003, ...],
    'curve_3pool': [0.0005, 0.0001, -0.0002, 0.0004, ...],
    'compound_dai': [0.0001, 0.0001, -0.0001, 0.0002, ...]
}

df = pd.DataFrame(returns_data)
correlation_matrix = df.corr()

print("Correlation Matrix:")
print(correlation_matrix.round(3))

# Expected output:
#              aave_usdc  lido_steth  curve_3pool  compound_dai
# aave_usdc         1.000       0.15        0.85         0.92
# lido_steth        0.150       1.00        0.20         0.18
# curve_3pool       0.850       0.20        1.00         0.78
# compound_dai      0.920       0.18        0.78         1.00
```

**Portfolio Diversification Analysis:**
```python
def portfolio_diversification_score(correlation_matrix, weights):
    n = len(weights)
    portfolio_variance = 0
    
    for i in range(n):
        for j in range(n):
            portfolio_variance += weights[i] * weights[j] * correlation_matrix.iloc[i, j]
    
    # Diversification ratio
    weighted_avg_correlation = (portfolio_variance - sum(weights**2)) / (1 - sum(weights**2))
    diversification_score = 1 - weighted_avg_correlation
    
    return diversification_score

weights = np.array([0.4, 0.3, 0.2, 0.1])  # Portfolio allocation
div_score = portfolio_diversification_score(correlation_matrix, weights)
print(f"Diversification Score: {div_score:.3f}")  # Higher is better
```

### Scenario 2: Custom Strategy Risk Assessment

**High-Volatility Asset Correlations:**
- ETH/BTC perpetual funding rates
- Uniswap V3 LP positions  
- Governance token farming
- Cross-chain arbitrage

**Stress Period Analysis:**
```python
def stress_correlation_analysis(returns_df, stress_periods):
    results = {}
    
    for period_name, (start_date, end_date) in stress_periods.items():
        period_data = returns_df.loc[start_date:end_date]
        
        if len(period_data) > 5:  # Minimum observations
            period_corr = period_data.corr()
            avg_correlation = period_corr.values[np.triu_indices_from(period_corr.values, k=1)].mean()
            results[period_name] = {
                'avg_correlation': avg_correlation,
                'max_correlation': period_corr.values.max(),
                'correlation_matrix': period_corr
            }
    
    return results

# Define stress periods
stress_periods = {
    'covid_crash': ('2020-03-01', '2020-03-31'),
    'terra_collapse': ('2022-05-01', '2022-05-31'),
    'ftx_collapse': ('2022-11-01', '2022-11-30'),
    'silicon_valley_bank': ('2023-03-01', '2023-03-31')
}

stress_analysis = stress_correlation_analysis(returns_df, stress_periods)
```

### Scenario 3: Cross-Chain Correlation Mapping

**Multi-Chain Asset Analysis:**
```python
def cross_chain_correlation_analysis():
    chains = ['ethereum', 'arbitrum', 'polygon', 'optimism']
    protocols = ['aave', 'compound', 'uniswap']
    
    correlation_map = {}
    
    for protocol in protocols:
        protocol_correlations = {}
        
        for chain1 in chains:
            for chain2 in chains:
                if chain1 != chain2:
                    # Fetch returns data for protocol on both chains
                    returns1 = get_protocol_returns(protocol, chain1)
                    returns2 = get_protocol_returns(protocol, chain2)
                    
                    correlation = returns1.corr(returns2)
                    protocol_correlations[f"{chain1}_{chain2}"] = correlation
        
        correlation_map[protocol] = protocol_correlations
    
    return correlation_map

# Expected insights:
# - Ethereum-Arbitrum correlations: 0.85-0.95 (high)
# - Ethereum-Polygon correlations: 0.70-0.85 (medium-high)  
# - Cross-protocol correlations: 0.60-0.80 (medium)
```

### Scenario 4: Temporal Correlation Evolution

**Time-Varying Correlation Analysis:**
```python
def correlation_regime_detection(returns1, returns2, window=60):
    rolling_corr = returns1.rolling(window).corr(returns2)
    rolling_vol = (returns1.rolling(window).std() + returns2.rolling(window).std()) / 2
    
    # Identify correlation regimes
    high_corr_threshold = rolling_corr.quantile(0.75)
    low_corr_threshold = rolling_corr.quantile(0.25)
    
    regimes = pd.Series(index=rolling_corr.index, dtype='object')
    regimes[rolling_corr >= high_corr_threshold] = 'high_correlation'
    regimes[rolling_corr <= low_corr_threshold] = 'low_correlation'
    regimes[(rolling_corr > low_corr_threshold) & (rolling_corr < high_corr_threshold)] = 'medium_correlation'
    
    return {
        'rolling_correlation': rolling_corr,
        'regimes': regimes,
        'regime_stats': regimes.value_counts()
    }
```

## Risks and Mitigations

### Correlation Risk Categories

**Correlation Surge Risk:**
- **Definition**: Previously uncorrelated assets becoming highly correlated during stress
- **Example**: DeFi tokens correlating 0.95+ during March 2020 crash
- **Impact**: Diversification benefits disappear when needed most

**False Diversification Risk:**
- **Definition**: Assuming static correlations for dynamic relationships
- **Example**: LST tokens appearing uncorrelated during bull markets but converging during liquidation events
- **Impact**: Portfolio concentration higher than expected

**Regime Change Risk:**
- **Definition**: Correlation structures shifting permanently due to market evolution
- **Example**: Introduction of new asset classes changing existing correlations
- **Impact**: Historical correlation analysis becomes irrelevant

### Risk Mitigation Strategies

**Dynamic Correlation Monitoring:**
```python
class CorrelationMonitor:
    def __init__(self, assets, lookback_window=30):
        self.assets = assets
        self.window = lookback_window
        self.correlation_history = []
        
    def update_correlations(self, new_returns):
        current_corr = new_returns.rolling(self.window).corr()
        self.correlation_history.append(current_corr)
        
        # Alert if correlations spike above threshold
        avg_correlation = self.get_average_correlation(current_corr)
        if avg_correlation > 0.8:
            return "HIGH_CORRELATION_ALERT"
        
        return "NORMAL"
    
    def get_average_correlation(self, corr_matrix):
        values = corr_matrix.values
        upper_triangle = values[np.triu_indices_from(values, k=1)]
        return np.mean(upper_triangle)
```

**Correlation-Adjusted Position Sizing:**
```python
def correlation_adjusted_weights(expected_returns, correlation_matrix, risk_aversion=3):
    n_assets = len(expected_returns)
    
    # Adjust correlation matrix for stress scenarios
    stress_adjusted_corr = correlation_matrix * 1.5  # Assume 50% correlation increase
    stress_adjusted_corr = np.clip(stress_adjusted_corr, -1, 1)
    
    # Convert correlation to covariance (assuming unit variance for simplicity)
    covariance_matrix = stress_adjusted_corr
    
    # Optimize portfolio weights
    inv_cov = np.linalg.inv(covariance_matrix)
    ones = np.ones((n_assets, 1))
    
    # Minimum variance portfolio
    mv_weights = (inv_cov @ ones) / (ones.T @ inv_cov @ ones)
    
    return mv_weights.flatten()
```

**Diversification Stress Testing:**
```python
def diversification_stress_test(portfolio_weights, correlation_matrix, stress_scenarios):
    results = {}
    
    for scenario_name, correlation_multiplier in stress_scenarios.items():
        # Apply stress to correlations
        stressed_corr = correlation_matrix * correlation_multiplier
        stressed_corr = np.clip(stressed_corr, -1, 1)
        
        # Calculate portfolio variance under stress
        portfolio_variance = portfolio_weights.T @ stressed_corr @ portfolio_weights
        
        # Calculate diversification ratio
        individual_variance = np.sum(portfolio_weights**2)
        diversification_ratio = portfolio_variance / individual_variance
        
        results[scenario_name] = {
            'portfolio_variance': portfolio_variance,
            'diversification_ratio': diversification_ratio,
            'effective_assets': 1 / diversification_ratio
        }
    
    return results

# Example stress scenarios
stress_scenarios = {
    'mild_stress': 1.2,      # 20% correlation increase
    'moderate_stress': 1.5,   # 50% correlation increase  
    'severe_stress': 2.0,     # 100% correlation increase
    'crisis': 3.0            # 200% correlation increase
}
```

## Unconventional Wisdom and Insights

### The Correlation Smile Effect

**Discovery**: DeFi asset correlations exhibit a "smile" pattern based on return magnitude:

```python
def correlation_smile_analysis(returns1, returns2, return_buckets=5):
    combined_returns = pd.concat([returns1, returns2], axis=1)
    combined_magnitude = combined_returns.abs().sum(axis=1)
    
    # Create return magnitude buckets
    bucket_labels = pd.qcut(combined_magnitude, return_buckets, labels=False)
    
    correlations_by_bucket = {}
    for bucket in range(return_buckets):
        bucket_mask = bucket_labels == bucket
        if bucket_mask.sum() > 10:
            bucket_corr = returns1[bucket_mask].corr(returns2[bucket_mask])
            correlations_by_bucket[bucket] = bucket_corr
    
    return correlations_by_bucket

# Typical pattern: Low correlation for small moves, high correlation for large moves
```

**Insight**: Correlations are highest when you need diversification most (during large market moves).

### The Liquidity-Correlation Feedback Loop

**Discovery**: Correlation increases as liquidity decreases, creating reflexive spirals:

```python
def liquidity_correlation_feedback(returns_data, volume_data):
    # Calculate rolling correlations and liquidity
    rolling_corr = returns_data.rolling(30).corr()
    rolling_liquidity = volume_data.rolling(30).mean()
    
    # Analyze relationship
    corr_liquidity_relationship = rolling_corr.corrwith(1/rolling_liquidity)
    
    return corr_liquidity_relationship

# Expected: Negative correlation between liquidity and asset correlations
```

**Strategic Implication**: Monitor liquidity conditions as correlation predictor.

### The Protocol Fork Correlation Decay

**Empirical Finding**: Forked protocols start with high correlation but decay predictably:

```python
def fork_correlation_decay(original_returns, fork_returns, fork_date):
    post_fork_data = original_returns[fork_date:].corr(fork_returns[fork_date:])
    
    # Days since fork
    days_since_fork = (post_fork_data.index - fork_date).days
    
    # Exponential decay model
    from scipy.optimize import curve_fit
    
    def decay_function(x, a, b):
        return a * np.exp(-b * x)
    
    popt, _ = curve_fit(decay_function, days_since_fork, post_fork_data.values)
    
    return popt  # Returns decay parameters
```

**Insight**: Fork correlations decay with half-life of ~90 days.

### The Cross-Asset Momentum Correlation

**Discovery**: Correlation itself exhibits momentum:

```python
def correlation_momentum(returns1, returns2, short_window=7, long_window=30):
    short_corr = returns1.rolling(short_window).corr(returns2)
    long_corr = returns1.rolling(long_window).corr(returns2)
    
    correlation_momentum = short_corr - long_corr
    
    # Predict next period correlation based on momentum
    correlation_signal = np.where(correlation_momentum > 0, "INCREASING", "DECREASING")
    
    return correlation_signal
```

**Strategy**: Adjust position sizing based on correlation momentum trends.

### The Whale Transaction Correlation Spike

**Insight**: Large transactions create temporary correlation spikes across protocols:

```python
def whale_impact_correlation(returns_data, transaction_data, whale_threshold=1e6):
    whale_transactions = transaction_data[transaction_data['value'] > whale_threshold]
    
    correlation_impact = {}
    for _, whale_tx in whale_transactions.iterrows():
        tx_date = whale_tx['timestamp']
        
        # Calculate correlation 24h before and after
        pre_correlation = returns_data.loc[tx_date-pd.Timedelta('1D'):tx_date].corr()
        post_correlation = returns_data.loc[tx_date:tx_date+pd.Timedelta('1D')].corr()
        
        correlation_change = post_correlation - pre_correlation
        correlation_impact[tx_date] = correlation_change.values.mean()
    
    return correlation_impact
```

### The Gas Price Correlation Amplifier

**Unconventional Insight**: High gas prices increase correlations by reducing arbitrage:

```python
def gas_correlation_relationship(returns_data, gas_prices):
    high_gas_periods = gas_prices > gas_prices.quantile(0.8)
    low_gas_periods = gas_prices < gas_prices.quantile(0.2)
    
    high_gas_correlations = returns_data[high_gas_periods].corr()
    low_gas_correlations = returns_data[low_gas_periods].corr()
    
    gas_correlation_effect = high_gas_correlations - low_gas_correlations
    
    return gas_correlation_effect
```

**Strategic Application**: Expect higher correlations during network congestion.

## Further Links and Knowledge Base

### Statistical Software and Libraries

**Python Libraries:**
```python
# Core correlation analysis
import pandas as pd
import numpy as np
from scipy import stats
from scipy.stats import pearsonr, spearmanr

# Advanced modeling
from statsmodels.tsa.vector_ar.vecm import coint_johansen
from arch import arch_model  # GARCH and DCC models
from sklearn.covariance import LedoitWolf, OAS

# Visualization
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.graph_objects as go
```

**R Packages (for advanced econometric analysis):**
```r
# Correlation modeling
library(corrplot)
library(PerformanceAnalytics)
library(rmgarch)  # DCC-GARCH models

# Copula analysis
library(VineCopula)
library(copula)

# Time series analysis
library(vars)  # Vector autoregression
library(urca)  # Unit root and cointegration tests
```

### Academic Research

**Foundational Papers:**
- **"Dynamic Conditional Correlation"** (Engle, 2002)
- **"Asymmetric Correlations of Equity Portfolios"** (Longin & Solnik, 2001)
- **"Conditional Correlation Analysis of Financial Markets"** (Boyer et al., 1999)

**DeFi-Specific Research:**
- **"Cryptocurrency Market Correlations and Portfolio Diversification"** (Borri, 2019)
- **"DeFi Risks and Correlation Structures"** (Harvey et al., 2021)
- **"Stablecoin Correlations During Market Stress"** (Lyons & Viswanath, 2020)

### Professional Analytics Platforms

**Market Data Providers:**
- **CoinMetrics**: Professional-grade correlation analytics
- **Messari**: Detailed correlation tracking across protocols
- **Glassnode**: On-chain correlation analysis
- **Kaiko**: High-frequency correlation modeling

**Research Platforms:**
- **Delphi Digital**: Institutional correlation research
- **Coin Bureau**: Correlation-based portfolio strategies
- **IntoTheBlock**: ML-based correlation prediction
- **Nansen**: Whale transaction correlation analysis

### Practical Implementation Tools

**Portfolio Management:**
```python
# Modern Portfolio Theory with correlations
from pypfopt import EfficientFrontier, risk_models, expected_returns
from pypfopt.discrete_allocation import DiscreteAllocation

def build_correlation_aware_portfolio(price_data):
    # Calculate expected returns and risk model
    mu = expected_returns.mean_historical_return(price_data)
    S = risk_models.CovarianceShrinkage(price_data).ledoit_wolf()
    
    # Optimize portfolio
    ef = EfficientFrontier(mu, S)
    weights = ef.max_sharpe()
    
    return ef.clean_weights()
```

**Real-Time Monitoring:**
```python
# Correlation monitoring system
class RealTimeCorrelationMonitor:
    def __init__(self, assets, alert_threshold=0.8):
        self.assets = assets
        self.threshold = alert_threshold
        self.correlation_history = []
    
    def update(self, new_price_data):
        current_corr = new_price_data.pct_change().corr()
        self.correlation_history.append(current_corr)
        
        # Check for correlation spikes
        avg_corr = self._get_average_correlation(current_corr)
        
        if avg_corr > self.threshold:
            self._send_alert(f"High correlation detected: {avg_corr:.3f}")
    
    def _get_average_correlation(self, corr_matrix):
        mask = np.triu(np.ones_like(corr_matrix), k=1).astype(bool)
        return corr_matrix.values[mask].mean()
```

### Levva Integration Framework

**Strategy-Specific Correlation Targets:**

| Strategy Type | Target Max Correlation | Monitoring Frequency | Alert Threshold |
|---------------|----------------------|-------------------|----------------|
| Ultra-Safe | 0.6 | Daily | 0.7 |
| Safe | 0.7 | Daily | 0.8 |
| Brave | 0.8 | 6-hourly | 0.85 |
| Custom | 0.9 | Hourly | 0.95 |

**Automated Correlation Management:**
```python
class LevvaCorrelationManager:
    def __init__(self, strategy_type):
        self.thresholds = {
            'ultra_safe': 0.6,
            'safe': 0.7,
            'brave': 0.8,
            'custom': 0.9
        }
        self.max_correlation = self.thresholds[strategy_type]
    
    def assess_portfolio_correlation(self, returns_data):
        correlation_matrix = returns_data.corr()
        max_correlation = correlation_matrix.values.max()
        
        if max_correlation > self.max_correlation:
            return {
                'action': 'REBALANCE_REQUIRED',
                'current_correlation': max_correlation,
                'target_correlation': self.max_correlation
            }
        else:
            return {'action': 'MAINTAIN_ALLOCATION'}
```

### Related Knowledge Base Files
- `position-sizing.md` - Using correlation analysis for optimal position sizing
- `portfolio-theory.md` - Modern portfolio theory with correlation constraints
- `impermanent-loss-explained.md` - Asset correlation impact on IL
- `yield-farming-basics.md` - Correlation considerations in yield strategy selection